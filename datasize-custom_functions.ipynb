{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "458da887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time as time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a94a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36303df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa92a465",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418eaec",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc9ac27c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multicore Loading Time = 0.428438663482666\n",
      "32474\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "all_text = pd.read_csv('data/all_text.csv', index_col=0, dtype='string')\n",
    "e = time.time()\n",
    "print(\"Multicore Loading Time = {}\".format(e-s))\n",
    "\n",
    "print(len(all_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0132a993",
   "metadata": {},
   "source": [
    "## Strip Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ae3c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-9459b6015ca1>:6: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace('+','')\n",
      "<ipython-input-30-9459b6015ca1>:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace('+','')\n",
      "<ipython-input-30-9459b6015ca1>:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace('(', ' ')\n",
      "<ipython-input-30-9459b6015ca1>:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace(')', ' ')\n",
      "<ipython-input-30-9459b6015ca1>:22: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace('{', ' ')\n",
      "<ipython-input-30-9459b6015ca1>:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace('}', ' ')\n",
      "<ipython-input-30-9459b6015ca1>:24: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace('[', ' ')\n",
      "<ipython-input-30-9459b6015ca1>:25: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  all_text['text']=all_text['text'].str.replace(']', ' ')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "all_text = all_text.applymap(lambda x:x.lower() if type(x) == str else x) #reduce all to lowercase\n",
    "#all_text['text'] = re.sub(\"[^\\x20-\\x7E]\", \"\", all_text['text']) #remove nonsense characters\n",
    "all_text['text']=all_text['text'].str.replace(',','')\n",
    "all_text['text']=all_text['text'].str.replace('+','')\n",
    "all_text['text']=all_text['text'].str.replace('-',' ')\n",
    "all_text['text']=all_text['text'].str.replace('+','')\n",
    "all_text['text']=all_text['text'].str.replace('(', ' ')\n",
    "all_text['text']=all_text['text'].str.replace(')', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('  ', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('<b>', '')\n",
    "all_text['text']=all_text['text'].str.replace('</b>', '')\n",
    "all_text['text']=all_text['text'].str.replace('<i>', '')\n",
    "all_text['text']=all_text['text'].str.replace('</i>', '')\n",
    "all_text['text']=all_text['text'].str.replace('<sub>', '')\n",
    "all_text['text']=all_text['text'].str.replace('</sub>', '')\n",
    "all_text['text']=all_text['text'].str.replace('<sup>', '')\n",
    "all_text['text']=all_text['text'].str.replace('</sup>', '')\n",
    "all_text['text']=all_text['text'].str.replace('<', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('>', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('{', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('}', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('[', ' ')\n",
    "all_text['text']=all_text['text'].str.replace(']', ' ')\n",
    "all_text['text']=all_text['text'].str.replace('â', '')\n",
    "all_text['text']=all_text['text'].str.replace('€', '')\n",
    "all_text['text']=all_text['text'].str.replace('‰', '')\n",
    "all_text['text']=all_text['text'].str.replace('ï', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6095529c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144887</th>\n",
       "      <td>neuro fuzzy system for prostate cancer diagnosis. to develop a neuro fuzzy system to predict the presence of prostate cancer. neuro fuzzy systems harness the power of two paradigms: fuzzy logic and artificial neural networks. we compared the predictive accuracy of our neuro fuzzy system with that obtained by total prostate specific antigen tpsa and percent free psa %fpsa .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116530</th>\n",
       "      <td>human gait recognition via deterministic learning. recognition of temporal/dynamical patterns is among the most difficult pattern recognition tasks. human gait recognition is a typical difficulty in the area of dynamical pattern recognition. it classifies and identifies individuals by their time varying gait signature data. recently a new dynamical pattern recognition method based on deterministic learning theory was presented in which a time varying dynamical pattern can be effectively represented in a time invariant manner and can be rapidly recognized. in this paper we present a new model based approach for human gait recognition via the aforementioned method specifically for recognizing people by gait. the approach consists of two phases: a training learning phase and a test recognition phase. in the training phase side silhouette lower limb joint angles and angular velocities are selected as gait features. a five link biped model for human gait locomotion is employed to demonstrate that functions containing joint angle and angular velocity state vectors characterize the gait system dynamics. due to the quasi periodic and symmetrical characteristics of human gait the gait system dynamics can be simplified to be described by functions of joint angles and angular velocities of one side of the human body thus the feature dimension is effectively reduced. locally accurate identification of the gait system dynamics is achieved by using radial basis function rbf neural networks nns through deterministic learning. the obtained knowledge of the approximated gait system dynamics is stored in constant rbf networks. a gait signature is then derived from the extracted gait system dynamics along the phase portrait of joint angles versus angular velocities. a bank of estimators is constructed using constant rbf networks to represent the training gait patterns. in the test phase by comparing the set of estimators with the test gait pattern a set of recognition errors are generated and the average l 1 norms of the errors are taken as the similarity measure between the dynamics of the training gait patterns and the dynamics of the test gait pattern. therefore the test gait pattern similar to one of the training gait patterns can be rapidly recognized according to the smallest error principle. finally experiments are carried out on the nlpr and ucsd gait databases to demonstrate the effectiveness of the proposed approach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11007</th>\n",
       "      <td>body fat predicts exercise capacity in persons with type 2 diabetes mellitus: a machine learning approach. diabetes mellitus is associated with increased cardiovascular disease cvd related morbidity mortality and death. exercise capacity in persons with type 2 diabetes has been shown to be predictive of cardiovascular events. in this study we used the data from the prospective randomized look ahead study and used machine learning algorithms to help predict exercise capacity measured in mets from the baseline data that included cardiovascular history medications blood pressure demographic information anthropometric and dual energy x ray absorptiometry dxa measured body composition metrics. we excluded variables with high collinearity and included dxa obtained subtotal total minus head fat percentage and subtotal lean mass gms . thereafter we used different machine learning methods to predict maximum exercise capacity. the different machine learning models showed a strong predictive performance for both females and males. our study shows that using baseline data from a large prospective cohort we can predict maximum exercise capacity in persons with diabetes mellitus. we show that subtotal fat percentage is the most important feature for predicting the exercise capacity for males and females after accounting for other important variables. until now bmi and waist circumference were commonly used surrogates for adiposity and there was a relative under appreciation of body composition metrics for understanding the pathophysiology of cvd. the recognition of body fat percentage as an important marker in determining cvd risk has prognostic implications with respect to cardiovascular morbidity and mortality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29787</th>\n",
       "      <td>machine learning based approaches for detecting covid 19 using clinical text data. technology advancements have a rapid effect on every field of life be it medical field or any other field. artificial intelligence has shown the promising results in health care through its decision making by analysing the data. covid 19 has affected more than 100 countries in a matter of no time. people all over the world are vulnerable to its consequences in future. it is imperative to develop a control system that will detect the coronavirus. one of the solution to control the current havoc can be the diagnosis of disease with the help of various ai tools. in this paper we classified textual clinical reports into four classes by using classical and ensemble machine learning algorithms. feature engineering was performed using techniques like term frequency/inverse document frequency tf/idf bag of words bow and report length. these features were supplied to traditional and ensemble machine learning classifiers. logistic regression and multinomial naã¯ve bayes showed better results than other ml algorithms by having 96.2% testing accuracy. in future recurrent neural network can be used for better accuracy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56869</th>\n",
       "      <td>application of deep learning in quantitative analysis of 2 dimensional ultrasound imaging of nonalcoholic fatty liver disease. to verify the value of deep learning in diagnosing nonalcoholic fatty liver disease nafld by comparing 3 image processing techniques.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40641</th>\n",
       "      <td>a machine learning based test for adult sleep apnoea screening at home using oximetry and airflow. the most appropriate physiological signals to develop simplified as well as accurate screening tests for obstructive sleep apnoea osa remain unknown. this study aimed at assessing whether joint analysis of at home oximetry and airflow recordings by means of machine learning algorithms leads to a significant diagnostic performance increase compared to single channel approaches. consecutive patients showing moderate to high clinical suspicion of osa were involved. the apnoea hypopnoea index ahi from unsupervised polysomnography was the gold standard. oximetry and airflow from at home polysomnography were parameterised by means of 38 time frequency and non linear variables. complementarity between both signals was exhaustively inspected via automated feature selection. regression support vector machines were used to estimate the ahi from single channel and dual channel approaches. a total of 239 patients successfully completed at home polysomnography. the optimum joint model reached 0.93 95%ci 0.90 0.95 intra class correlation coefficient between estimated and actual ahi. overall performance of the dual channel approach kappa: 0.71; 4 class accuracy: 81.3% significantly outperformed individual oximetry kappa: 0.61; 4 class accuracy: 75.0% and airflow kappa: 0.42; 4 class accuracy: 61.5% . according to our findings oximetry alone was able to reach notably high accuracy particularly to confirm severe cases of the disease. nevertheless oximetry and airflow showed high complementarity leading to a remarkable performance increase compared to single channel approaches. consequently their joint analysis via machine learning enables accurate abbreviated screening of osa at home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126010</th>\n",
       "      <td>automated detection of white matter changes in elderly people using fuzzy geostatistical and information combining models. detection of white matter changes of the brain using magnetic resonance imaging mri has increasingly been an active and challenging research area in computational neuroscience. there have rarely been any single image analysis methods that can effectively address the issue of automated quantification of neuroimages which are subject to different interests of various medical hypotheses. this paper presents new image segmentation models for automated detection of white matter changes of the brain in an elderly population. the methods are based on the computational models of fuzzy clustering possibilistic clustering geostatistics and knowledge combination. experimental results on mri data have shown that the proposed image analysis methodology can be applied as a very useful computerized tool for the validation of our particular medical question where white matter changes of the brain are thought to be the most important social medical evidence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128513</th>\n",
       "      <td>dynamic multiple thresholding breast boundary detection algorithm for mammograms. automated detection of breast boundary is one of the fundamental steps for computer aided analysis of mammograms. in this study the authors developed a new dynamic multiple thresholding based breast boundary mtbb detection method for digitized mammograms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34076</th>\n",
       "      <td>applying artificial intelligence to predict self reported poor health among black and hispanic caregivers with mild cognitive impairment. we applied artificial intelligence techniques to build correlate models that predict general poor health in a national sample of caregivers with mild cognitive impairment mci . our application of deep learning identified age duration of caregiving amount of alcohol intake weight myocardial infarction mi and frequency of mci symptoms for blacks and hispanics whereas frequency of mci symptoms income weight coronary heart disease chd age and use of e cigarette for the others as the strongest correlates of poor health among 81 variables entered. the application of artificial intelligence efficiently provided intervention strategies for black and hispanic caregivers with mci.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27672</th>\n",
       "      <td>enabling early detection of osteoarthritis from presymptomatic cartilage texture maps via transport based learning. many diseases have no visual cues in the early stages eluding image based detection. today osteoarthritis oa is detected after bone damage has occurred at an irreversible stage of the disease. currently no reliable method exists for oa detection at a reversible stage. we present an approach that enables sensitive oa detection in presymptomatic individuals. our approach combines optimal mass transport theory with statistical pattern recognition. eighty six healthy individuals were selected from the osteoarthritis initiative with no symptoms or visual signs of disease on imaging. on 3 y follow up a subset of these individuals had progressed to symptomatic oa. we trained a classifier to differentiate progressors and nonprogressors on baseline cartilage texture maps which achieved a robust test accuracy of 78% in detecting future symptomatic oa progression 3 y prior to symptoms. this work demonstrates that oa detection may be possible at a potentially reversible stage. a key contribution of our work is direct visualization of the cartilage phenotype defining predictive ability as our technique is generative. we observe early biochemical patterns of fissuring in cartilage that define future onset of oa. in the future coupling presymptomatic oa detection with emergent clinical therapies could modify the outcome of a disease that costs the united states healthcare system $16.5 billion annually. furthermore our technique is broadly applicable to earlier image based detection of many diseases currently diagnosed at advanced stages today.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154859</th>\n",
       "      <td>automated epiluminescence microscopy tissue counter analysis using cart and 1 nn in the diagnosis of melanoma. in tissue counter analysis digital images are overlayed with regularly distributed measuring masks elements of equal size and shape and the digital contents grey level colour and texture parameters of each element are used for statistical analysis. in this study we assessed the applicability of tissue counter analysis and machine learning algorithms on tumour segmentation and diagnostic discrimination of benign and malignant melanocytic skin lesions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>ascertaining framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre atherosclerosis risk in communities aric validation study. using free text clinical notes and reports from hospitalised patients determine the performance of natural language processing nlp ascertainment of framingham heart failure hf criteria and phenotype.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115822</th>\n",
       "      <td>lung tumor segmentation in pet images using graph cuts. the aim of segmentation of tumor regions in positron emission tomography pet is to provide more accurate measurements of tumor size and extension into adjacent structures than is possible with visual assessment alone and hence improve patient management decisions. we propose a segmentation energy function for the graph cuts technique to improve lung tumor segmentation with pet. our segmentation energy is based on an analysis of the tumor voxels in pet images combined with a standardized uptake value suv cost function and a monotonic downhill suv feature. the monotonic downhill feature avoids segmentation leakage into surrounding tissues with similar or higher pet tracer uptake than the tumor and the suv cost function improves the boundary definition and also addresses situations where the lung tumor is heterogeneous. we evaluated the method in 42 clinical pet volumes from patients with non small cell lung cancer nsclc . our method improves segmentation and performs better than region growing approaches the watershed technique fuzzy c means region based active contour and tumor customized downhill.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64821</th>\n",
       "      <td>personalized prediction of acquired resistance to egfr targeted inhibitors using a pathway based machine learning approach. epidermal growth factor receptor egfr inhibitors have benefitted cancer patients worldwide but resistance inevitably develops over time resulting in treatment failures. an accurate prediction model for acquired resistance ar to egfr inhibitors is critical for early diagnosis and according intervention but is not yet available due to personal variations and the complex mechanisms of ar. here we have developed a novel pipeline to build a meta analysis based multivariate model for personalized pathways in ar to egfr inhibitors using sophisticated machine learning algorithms. surprisingly the model achieved excellent predictive performance with a cross study validation area under curve auc of over 0.9 and generalization performance on independent cohorts of samples with a perfect auc score of 1. furthermore the model showed excellent transferability across different cancer cell lines and egfr inhibitors including gefitinib erlotinib afatinib and cetuximab. in conclusion our model achieved high predictive accuracy through robust cross study validation and enabled individualized prediction on newly introduced data. we also discovered common pathway alteration signatures for ar to egfr inhibitors which can provide directions for other follow up studies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46102</th>\n",
       "      <td>analyzing associations between chronic disease prevalence and neighborhood quality through google street view images. deep learning and specifically convoltional neural networks cnn represent a class of powerful models that facilitate the understanding of many problems in computer vision. when combined with a reasonable amount of data cnns can outperform traditional models for many tasks including image classification. in this work we utilize these powerful tools with imagery data collected through google street view images to perform virtual audits of neighborhood characteristics. we further investigate different architectures for chronic disease prevalence regression through networks that are applied to sets of images rather than single images. we show quantitative results and demonstrate that our proposed architectures outperform the traditional regression approaches.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "144887                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              neuro fuzzy system for prostate cancer diagnosis. to develop a neuro fuzzy system to predict the presence of prostate cancer. neuro fuzzy systems harness the power of two paradigms: fuzzy logic and artificial neural networks. we compared the predictive accuracy of our neuro fuzzy system with that obtained by total prostate specific antigen tpsa and percent free psa %fpsa .\n",
       "116530  human gait recognition via deterministic learning. recognition of temporal/dynamical patterns is among the most difficult pattern recognition tasks. human gait recognition is a typical difficulty in the area of dynamical pattern recognition. it classifies and identifies individuals by their time varying gait signature data. recently a new dynamical pattern recognition method based on deterministic learning theory was presented in which a time varying dynamical pattern can be effectively represented in a time invariant manner and can be rapidly recognized. in this paper we present a new model based approach for human gait recognition via the aforementioned method specifically for recognizing people by gait. the approach consists of two phases: a training learning phase and a test recognition phase. in the training phase side silhouette lower limb joint angles and angular velocities are selected as gait features. a five link biped model for human gait locomotion is employed to demonstrate that functions containing joint angle and angular velocity state vectors characterize the gait system dynamics. due to the quasi periodic and symmetrical characteristics of human gait the gait system dynamics can be simplified to be described by functions of joint angles and angular velocities of one side of the human body thus the feature dimension is effectively reduced. locally accurate identification of the gait system dynamics is achieved by using radial basis function rbf neural networks nns through deterministic learning. the obtained knowledge of the approximated gait system dynamics is stored in constant rbf networks. a gait signature is then derived from the extracted gait system dynamics along the phase portrait of joint angles versus angular velocities. a bank of estimators is constructed using constant rbf networks to represent the training gait patterns. in the test phase by comparing the set of estimators with the test gait pattern a set of recognition errors are generated and the average l 1 norms of the errors are taken as the similarity measure between the dynamics of the training gait patterns and the dynamics of the test gait pattern. therefore the test gait pattern similar to one of the training gait patterns can be rapidly recognized according to the smallest error principle. finally experiments are carried out on the nlpr and ucsd gait databases to demonstrate the effectiveness of the proposed approach.\n",
       "11007                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      body fat predicts exercise capacity in persons with type 2 diabetes mellitus: a machine learning approach. diabetes mellitus is associated with increased cardiovascular disease cvd related morbidity mortality and death. exercise capacity in persons with type 2 diabetes has been shown to be predictive of cardiovascular events. in this study we used the data from the prospective randomized look ahead study and used machine learning algorithms to help predict exercise capacity measured in mets from the baseline data that included cardiovascular history medications blood pressure demographic information anthropometric and dual energy x ray absorptiometry dxa measured body composition metrics. we excluded variables with high collinearity and included dxa obtained subtotal total minus head fat percentage and subtotal lean mass gms . thereafter we used different machine learning methods to predict maximum exercise capacity. the different machine learning models showed a strong predictive performance for both females and males. our study shows that using baseline data from a large prospective cohort we can predict maximum exercise capacity in persons with diabetes mellitus. we show that subtotal fat percentage is the most important feature for predicting the exercise capacity for males and females after accounting for other important variables. until now bmi and waist circumference were commonly used surrogates for adiposity and there was a relative under appreciation of body composition metrics for understanding the pathophysiology of cvd. the recognition of body fat percentage as an important marker in determining cvd risk has prognostic implications with respect to cardiovascular morbidity and mortality.\n",
       "29787                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                machine learning based approaches for detecting covid 19 using clinical text data. technology advancements have a rapid effect on every field of life be it medical field or any other field. artificial intelligence has shown the promising results in health care through its decision making by analysing the data. covid 19 has affected more than 100 countries in a matter of no time. people all over the world are vulnerable to its consequences in future. it is imperative to develop a control system that will detect the coronavirus. one of the solution to control the current havoc can be the diagnosis of disease with the help of various ai tools. in this paper we classified textual clinical reports into four classes by using classical and ensemble machine learning algorithms. feature engineering was performed using techniques like term frequency/inverse document frequency tf/idf bag of words bow and report length. these features were supplied to traditional and ensemble machine learning classifiers. logistic regression and multinomial naã¯ve bayes showed better results than other ml algorithms by having 96.2% testing accuracy. in future recurrent neural network can be used for better accuracy.\n",
       "56869                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  application of deep learning in quantitative analysis of 2 dimensional ultrasound imaging of nonalcoholic fatty liver disease. to verify the value of deep learning in diagnosing nonalcoholic fatty liver disease nafld by comparing 3 image processing techniques.\n",
       "40641                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   a machine learning based test for adult sleep apnoea screening at home using oximetry and airflow. the most appropriate physiological signals to develop simplified as well as accurate screening tests for obstructive sleep apnoea osa remain unknown. this study aimed at assessing whether joint analysis of at home oximetry and airflow recordings by means of machine learning algorithms leads to a significant diagnostic performance increase compared to single channel approaches. consecutive patients showing moderate to high clinical suspicion of osa were involved. the apnoea hypopnoea index ahi from unsupervised polysomnography was the gold standard. oximetry and airflow from at home polysomnography were parameterised by means of 38 time frequency and non linear variables. complementarity between both signals was exhaustively inspected via automated feature selection. regression support vector machines were used to estimate the ahi from single channel and dual channel approaches. a total of 239 patients successfully completed at home polysomnography. the optimum joint model reached 0.93 95%ci 0.90 0.95 intra class correlation coefficient between estimated and actual ahi. overall performance of the dual channel approach kappa: 0.71; 4 class accuracy: 81.3% significantly outperformed individual oximetry kappa: 0.61; 4 class accuracy: 75.0% and airflow kappa: 0.42; 4 class accuracy: 61.5% . according to our findings oximetry alone was able to reach notably high accuracy particularly to confirm severe cases of the disease. nevertheless oximetry and airflow showed high complementarity leading to a remarkable performance increase compared to single channel approaches. consequently their joint analysis via machine learning enables accurate abbreviated screening of osa at home.\n",
       "126010                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               automated detection of white matter changes in elderly people using fuzzy geostatistical and information combining models. detection of white matter changes of the brain using magnetic resonance imaging mri has increasingly been an active and challenging research area in computational neuroscience. there have rarely been any single image analysis methods that can effectively address the issue of automated quantification of neuroimages which are subject to different interests of various medical hypotheses. this paper presents new image segmentation models for automated detection of white matter changes of the brain in an elderly population. the methods are based on the computational models of fuzzy clustering possibilistic clustering geostatistics and knowledge combination. experimental results on mri data have shown that the proposed image analysis methodology can be applied as a very useful computerized tool for the validation of our particular medical question where white matter changes of the brain are thought to be the most important social medical evidence.\n",
       "128513                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    dynamic multiple thresholding breast boundary detection algorithm for mammograms. automated detection of breast boundary is one of the fundamental steps for computer aided analysis of mammograms. in this study the authors developed a new dynamic multiple thresholding based breast boundary mtbb detection method for digitized mammograms.\n",
       "34076                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     applying artificial intelligence to predict self reported poor health among black and hispanic caregivers with mild cognitive impairment. we applied artificial intelligence techniques to build correlate models that predict general poor health in a national sample of caregivers with mild cognitive impairment mci . our application of deep learning identified age duration of caregiving amount of alcohol intake weight myocardial infarction mi and frequency of mci symptoms for blacks and hispanics whereas frequency of mci symptoms income weight coronary heart disease chd age and use of e cigarette for the others as the strongest correlates of poor health among 81 variables entered. the application of artificial intelligence efficiently provided intervention strategies for black and hispanic caregivers with mci.\n",
       "27672                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                enabling early detection of osteoarthritis from presymptomatic cartilage texture maps via transport based learning. many diseases have no visual cues in the early stages eluding image based detection. today osteoarthritis oa is detected after bone damage has occurred at an irreversible stage of the disease. currently no reliable method exists for oa detection at a reversible stage. we present an approach that enables sensitive oa detection in presymptomatic individuals. our approach combines optimal mass transport theory with statistical pattern recognition. eighty six healthy individuals were selected from the osteoarthritis initiative with no symptoms or visual signs of disease on imaging. on 3 y follow up a subset of these individuals had progressed to symptomatic oa. we trained a classifier to differentiate progressors and nonprogressors on baseline cartilage texture maps which achieved a robust test accuracy of 78% in detecting future symptomatic oa progression 3 y prior to symptoms. this work demonstrates that oa detection may be possible at a potentially reversible stage. a key contribution of our work is direct visualization of the cartilage phenotype defining predictive ability as our technique is generative. we observe early biochemical patterns of fissuring in cartilage that define future onset of oa. in the future coupling presymptomatic oa detection with emergent clinical therapies could modify the outcome of a disease that costs the united states healthcare system $16.5 billion annually. furthermore our technique is broadly applicable to earlier image based detection of many diseases currently diagnosed at advanced stages today.\n",
       "154859                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                automated epiluminescence microscopy tissue counter analysis using cart and 1 nn in the diagnosis of melanoma. in tissue counter analysis digital images are overlayed with regularly distributed measuring masks elements of equal size and shape and the digital contents grey level colour and texture parameters of each element are used for statistical analysis. in this study we assessed the applicability of tissue counter analysis and machine learning algorithms on tumour segmentation and diagnostic discrimination of benign and malignant melanocytic skin lesions.\n",
       "3558                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ascertaining framingham heart failure phenotype from inpatient electronic health record data using natural language processing: a multicentre atherosclerosis risk in communities aric validation study. using free text clinical notes and reports from hospitalised patients determine the performance of natural language processing nlp ascertainment of framingham heart failure hf criteria and phenotype.\n",
       "115822                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   lung tumor segmentation in pet images using graph cuts. the aim of segmentation of tumor regions in positron emission tomography pet is to provide more accurate measurements of tumor size and extension into adjacent structures than is possible with visual assessment alone and hence improve patient management decisions. we propose a segmentation energy function for the graph cuts technique to improve lung tumor segmentation with pet. our segmentation energy is based on an analysis of the tumor voxels in pet images combined with a standardized uptake value suv cost function and a monotonic downhill suv feature. the monotonic downhill feature avoids segmentation leakage into surrounding tissues with similar or higher pet tracer uptake than the tumor and the suv cost function improves the boundary definition and also addresses situations where the lung tumor is heterogeneous. we evaluated the method in 42 clinical pet volumes from patients with non small cell lung cancer nsclc . our method improves segmentation and performs better than region growing approaches the watershed technique fuzzy c means region based active contour and tumor customized downhill.\n",
       "64821                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        personalized prediction of acquired resistance to egfr targeted inhibitors using a pathway based machine learning approach. epidermal growth factor receptor egfr inhibitors have benefitted cancer patients worldwide but resistance inevitably develops over time resulting in treatment failures. an accurate prediction model for acquired resistance ar to egfr inhibitors is critical for early diagnosis and according intervention but is not yet available due to personal variations and the complex mechanisms of ar. here we have developed a novel pipeline to build a meta analysis based multivariate model for personalized pathways in ar to egfr inhibitors using sophisticated machine learning algorithms. surprisingly the model achieved excellent predictive performance with a cross study validation area under curve auc of over 0.9 and generalization performance on independent cohorts of samples with a perfect auc score of 1. furthermore the model showed excellent transferability across different cancer cell lines and egfr inhibitors including gefitinib erlotinib afatinib and cetuximab. in conclusion our model achieved high predictive accuracy through robust cross study validation and enabled individualized prediction on newly introduced data. we also discovered common pathway alteration signatures for ar to egfr inhibitors which can provide directions for other follow up studies.\n",
       "46102                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   analyzing associations between chronic disease prevalence and neighborhood quality through google street view images. deep learning and specifically convoltional neural networks cnn represent a class of powerful models that facilitate the understanding of many problems in computer vision. when combined with a reasonable amount of data cnns can outperform traditional models for many tasks including image classification. in this work we utilize these powerful tools with imagery data collected through google street view images to perform virtual audits of neighborhood characteristics. we further investigate different architectures for chronic disease prevalence regression through networks that are applied to sets of images rather than single images. we show quantitative results and demonstrate that our proposed architectures outperform the traditional regression approaches."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a975d5",
   "metadata": {},
   "source": [
    "## Text2Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d98467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5000000'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_to_num import alpha2digit\n",
    "\n",
    "#test\n",
    "alpha2digit(\"five million\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b110822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected string or bytes-like object\n"
     ]
    }
   ],
   "source": [
    "templist = []\n",
    "\n",
    "for x in all_text['text']:\n",
    "    try:\n",
    "        templist.append(alpha2digit(x, \"en\"))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        templist.append('skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d209a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text['a2d'] = templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97910393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>a2d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>performance assessment of the metastatic spinal tumor frailty index using machine learning algorithms: limitations and future directions. frailty is recognized as an important consideration in patients with cancer who are undergoing therapies including spine surgery. the definition of frailty in the context of spinal metastases is unclear and few have studied such markers and their association with postoperative outcomes and survival. using national databases the metastatic spinal tumor frailty index mstfi was developed as a tool to predict outcomes in this specific patient population and has not been tested with external data. the purpose of this study was to test the performance of the mstfi with institutional data and determine whether machine learning methods could better identify measures of frailty as predictors of outcomes.</td>\n",
       "      <td>performance assessment of the metastatic spinal tumor frailty index using machine learning algorithms: limitations and future directions. frailty is recognized as an important consideration in patients with cancer who are undergoing therapies including spine surgery. the definition of frailty in the context of spinal metastases is unclear and few have studied such markers and their association with postoperative outcomes and survival. using national databases the metastatic spinal tumor frailty index mstfi was developed as a tool to predict outcomes in this specific patient population and has not been tested with external data. the purpose of this study was to test the performance of the mstfi with institutional data and determine whether machine learning methods could better identify measures of frailty as predictors of outcomes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148585</th>\n",
       "      <td>adaptive neuro fuzzy inference systems for analysis of internal carotid arterial doppler signals. in this study a new approach based on adaptive neuro fuzzy inference system anfis was presented for detection of internal carotid artery stenosis and occlusion. the internal carotid arterial doppler signals were recorded from 130 subjects that 45 of them suffered from internal carotid artery stenosis 44 of them suffered from internal carotid artery occlusion and the rest of them were healthy subjects. the three anfis classifiers were used to detect internal carotid artery conditions normal stenosis and occlusion when two features resistivity and pulsatility indices defining changes of internal carotid arterial doppler waveforms were used as inputs. to improve diagnostic accuracy the fourth anfis classifier combining anfis was trained using the outputs of the three anfis classifiers as input data. the proposed anfis model combined the neural network adaptive capabilities and the fuzzy logic qualitative approach. some conclusions concerning the impacts of features on the detection of internal carotid artery stenosis and occlusion were obtained through analysis of the anfis. the performance of the anfis model was evaluated in terms of classification accuracies and the results confirmed that the proposed anfis classifiers have some potential in detecting the internal carotid artery stenosis and occlusion. the anfis model achieved accuracy rates which were higher than that of the stand alone neural network model.</td>\n",
       "      <td>adaptive neuro fuzzy inference systems for analysis of internal carotid arterial doppler signals. in this study a new approach based on adaptive neuro fuzzy inference system anfis was presented for detection of internal carotid artery stenosis and occlusion. the internal carotid arterial doppler signals were recorded from 130 subjects that 45 of them suffered from internal carotid artery stenosis 44 of them suffered from internal carotid artery occlusion and the rest of them were healthy subjects. the 3 anfis classifiers were used to detect internal carotid artery conditions normal stenosis and occlusion when 2 features resistivity and pulsatility indices defining changes of internal carotid arterial doppler waveforms were used as inputs. to improve diagnostic accuracy the 4th anfis classifier combining anfis was trained using the outputs of the 3 anfis classifiers as input data. the proposed anfis model combined the neural network adaptive capabilities and the fuzzy logic qualitative approach. some conclusions concerning the impacts of features on the detection of internal carotid artery stenosis and occlusion were obtained through analysis of the anfis. the performance of the anfis model was evaluated in terms of classification accuracies and the results confirmed that the proposed anfis classifiers have some potential in detecting the internal carotid artery stenosis and occlusion. the anfis model achieved accuracy rates which were higher than that of the stand alone neural network model.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60160</th>\n",
       "      <td>lstm based ecg classification for continuous monitoring on personal wearable devices. a novel electrocardiogram ecg classification algorithm is proposed for continuous cardiac monitoring on wearable devices with limited processing capacity.</td>\n",
       "      <td>lstm based ecg classification for continuous monitoring on personal wearable devices. a novel electrocardiogram ecg classification algorithm is proposed for continuous cardiac monitoring on wearable devices with limited processing capacity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107301</th>\n",
       "      <td>a fuzzy controller for lower limb exoskeletons during sit to stand and stand to sit movement using wearable sensors. human motion is a daily and rhythmic activity. the exoskeleton concept is a very positive scientific approach for human rehabilitation in case of lower limb impairment. although the exoskeleton shows potential it is not yet applied extensively in clinical rehabilitation. in this research a fuzzy based control algorithm is proposed for lower limb exoskeletons during sit to stand and stand to sit movements. surface electromyograms emgs are acquired from the vastus lateralis muscle using a wearable emg sensor. the resultant acceleration angle along the z axis is determined from a kinematics sensor. twenty volunteers were chosen to perform the experiments. the whole experiment was accomplished in two phases. in the first phase acceleration angles and emg data were acquired from the volunteers during both sit to stand and stand to sit motions. during sit to stand movements the average acceleration angle at activation was 11° 48° and the emg varied from 0.19 mv to 0.19 mv. on the other hand during stand to sit movements the average acceleration angle was found to be 57.5° 108° at the activation point and the emg varied from 0.32 mv to 0.32 mv. in the second phase a fuzzy controller was designed from the experimental data. the controller was tested and validated with both offline and real time data using labview.</td>\n",
       "      <td>a fuzzy controller for lower limb exoskeletons during sit to stand and stand to sit movement using wearable sensors. human motion is a daily and rhythmic activity. the exoskeleton concept is a very positive scientific approach for human rehabilitation in case of lower limb impairment. although the exoskeleton shows potential it is not yet applied extensively in clinical rehabilitation. in this research a fuzzy based control algorithm is proposed for lower limb exoskeletons during sit to stand and stand to sit movements. surface electromyograms emgs are acquired from the vastus lateralis muscle using a wearable emg sensor. the resultant acceleration angle along the z axis is determined from a kinematics sensor. 20 volunteers were chosen to perform the experiments. the whole experiment was accomplished in 2 phases. in the first phase acceleration angles and emg data were acquired from the volunteers during both sit to stand and stand to sit motions. during sit to stand movements the average acceleration angle at activation was 11° 48° and the emg varied from 0.19 mv to 0.19 mv. on the other hand during stand to sit movements the average acceleration angle was found to be 57.5° 108° at the activation point and the emg varied from 0.32 mv to 0.32 mv. in the second phase a fuzzy controller was designed from the experimental data. the controller was tested and validated with both offline and real time data using labview.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144856</th>\n",
       "      <td>development and assessment of methods for detecting dementia using the human electroencephalogram. this paper makes an outline case for the need for a low cost easy to administer method for detecting dementia within the growing at risk population. it proposes two methods for electroencephalogram eeg analysis for detecting dementia that could fulfil such a need. the paper describes a fractal dimension based method for analyzing the eeg waveforms of subjects with dementia and reports on an assessment which demonstrates that an appropriate fractal dimension measure could achieve 67% sensitivity to probable alzheimer's disease as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. an alternative method based on the probability density function of the zero crossing intervals is shown to achieve 78% sensitivity to probable alzheimer's disease and an estimated sensitivity to probable vascular or mixed dementia of 35% as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. this compares well with other studies reported by the american academy of neurology which typically provide a sensitivity of 81% and specificity of 70%. the eeg recordings used to assess these methods included artefacts and had no a priori selection of elements \"suitable for analysis.\" this approach gives a good prediction of the usefulness of the methods as they would be used in practice. a total of 39 patients 30 probable alzheimer's disease six vascular dementia and three mixed dementia and 42 healthy volunteers were involved in the study. however although results from the preliminary evaluation of the methods are promising there is a need for a more extensive study to validate the methods using eegs from a larger and more varied patient cohorts with neuroimaging results to exclude other causes and cognitive scores to correlate results with severity of cognitive status.</td>\n",
       "      <td>development and assessment of methods for detecting dementia using the human electroencephalogram. this paper makes an outline case for the need for a low cost easy to administer method for detecting dementia within the growing at risk population. it proposes 2 methods for electroencephalogram eeg analysis for detecting dementia that could fulfil such a need. the paper describes a fractal dimension based method for analyzing the eeg waveforms of subjects with dementia and reports on an assessment which demonstrates that an appropriate fractal dimension measure could achieve 67% sensitivity to probable alzheimer's disease as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. an alternative method based on the probability density function of the zero crossing intervals is shown to achieve 78% sensitivity to probable alzheimer's disease and an estimated sensitivity to probable vascular or mixed dementia of 35% as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. this compares well with other studies reported by the american academy of neurology which typically provide a sensitivity of 81% and specificity of 70%. the eeg recordings used to assess these methods included artefacts and had no a priori selection of elements \"suitable for analysis.\" this approach gives a good prediction of the usefulness of the methods as they would be used in practice. a total of 39 patients 30 probable alzheimer's disease 6 vascular dementia and 3 mixed dementia and 42 healthy volunteers were involved in the study. however although results from the preliminary evaluation of the methods are promising there is a need for a more extensive study to validate the methods using eegs from a larger and more varied patient cohorts with neuroimaging results to exclude other causes and cognitive scores to correlate results with severity of cognitive status.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39877</th>\n",
       "      <td>research of low rank representation and discriminant correlation analysis for alzheimer's disease diagnosis. as population aging is becoming more common worldwide applying artificial intelligence into the diagnosis of alzheimer's disease ad is critical to improve the diagnostic level in recent years. in early diagnosis of ad the fusion of complementary information contained in multimodality data e.g. magnetic resonance imaging mri positron emission tomography pet and cerebrospinal fluid csf  has obtained enormous achievement. detecting alzheimer's disease using multimodality data has two difficulties: 1 there exists noise information in multimodal data; 2 how to establish an effective mathematical model of the relationship between multimodal data? to this end we proposed a method named ldf which is based on the combination of low rank representation and discriminant correlation analysis dca to fuse multimodal datasets. specifically the low rank representation method is used to extract the latent features of the submodal data so the noise information in the submodal data is removed. then discriminant correlation analysis is used to fuse the submodal data so the complementary information can be fully utilized. the experimental results indicate the effectiveness of this method.</td>\n",
       "      <td>research of low rank representation and discriminant correlation analysis for alzheimer's disease diagnosis. as population aging is becoming more common worldwide applying artificial intelligence into the diagnosis of alzheimer's disease ad is critical to improve the diagnostic level in recent years. in early diagnosis of ad the fusion of complementary information contained in multimodality data e.g. magnetic resonance imaging mri positron emission tomography pet and cerebrospinal fluid csf has obtained enormous achievement. detecting alzheimer's disease using multimodality data has 2 difficulties: 1 there exists noise information in multimodal data; 2 how to establish an effective mathematical model of the relationship between multimodal data? to this end we proposed a method named ldf which is based on the combination of low rank representation and discriminant correlation analysis dca to fuse multimodal datasets. specifically the low rank representation method is used to extract the latent features of the submodal data so the noise information in the submodal data is removed. then discriminant correlation analysis is used to fuse the submodal data so the complementary information can be fully utilized. the experimental results indicate the effectiveness of this method.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76312</th>\n",
       "      <td>shared and distinct rupture discriminants of small and large intracranial aneurysms. many ruptured intracranial aneurysms ias are small. clinical presentations suggest that small and large ias could have different phenotypes. it is unknown if small and large ias have different characteristics that discriminate rupture.</td>\n",
       "      <td>shared and distinct rupture discriminants of small and large intracranial aneurysms. many ruptured intracranial aneurysms ias are small. clinical presentations suggest that small and large ias could have different phenotypes. it is unknown if small and large ias have different characteristics that discriminate rupture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85862</th>\n",
       "      <td>expert system classifier for adaptive radiation therapy in prostate cancer. a classifier based expert system was developed to compare delivered and planned radiation therapy in prostate cancer patients. its aim is to automatically identify patients that can benefit from an adaptive treatment strategy. the study predominantly addresses dosimetric uncertainties and critical issues caused by motion of hollow organs. 1200 mvct images of 38 prostate adenocarcinoma cases were analyzed. an automatic daily re contouring of structures i.e. rectum bladder and femoral heads rigid/deformable registration and dose warping was carried out to simulate dose and volume variations during therapy. support vector machine k means clustering algorithms and similarity index analysis were used to create an unsupervised predictive tool to detect incorrect setup and/or morphological changes as a consequence of inadequate patient preparation due to stochastic physiological changes supporting clinical decision making. after training on a dataset that was considered sufficiently dosimetrically stable the system identified two equally sized macro clusters with distinctly different volumetric and dosimetric baseline properties and defined thresholds for these two clusters. application to the test cohort resulted in 25% of the patients located outside the two macro clusters thresholds and which were therefore suspected to be dosimetrically unstable. in these patients over the treatment course mean volumetric changes of 30 and 40% for rectum and bladder were detected which possibly represents values justifying adjustment of patient preparation frequent re planning or a plan of the day strategy. based on our research by combining daily igrt images with rigid/deformable registration and dose warping it is possible to apply a machine learning approach to the clinical setting obtaining useful information for a decision regarding an individualized adaptive strategy. especially for treatments influenced by the movement of hollow organs this could reduce inadequate treatments and possibly reduce toxicity thereby increasing overall rt efficacy.</td>\n",
       "      <td>expert system classifier for adaptive radiation therapy in prostate cancer. a classifier based expert system was developed to compare delivered and planned radiation therapy in prostate cancer patients. its aim is to automatically identify patients that can benefit from an adaptive treatment strategy. the study predominantly addresses dosimetric uncertainties and critical issues caused by motion of hollow organs. 1200 mvct images of 38 prostate adenocarcinoma cases were analyzed. an automatic daily re contouring of structures i.e. rectum bladder and femoral heads rigid/deformable registration and dose warping was carried out to simulate dose and volume variations during therapy. support vector machine k means clustering algorithms and similarity index analysis were used to create an unsupervised predictive tool to detect incorrect setup and/or morphological changes as a consequence of inadequate patient preparation due to stochastic physiological changes supporting clinical decision making. after training on a dataset that was considered sufficiently dosimetrically stable the system identified 2 equally sized macro clusters with distinctly different volumetric and dosimetric baseline properties and defined thresholds for these 2 clusters. application to the test cohort resulted in 25% of the patients located outside the 2 macro clusters thresholds and which were therefore suspected to be dosimetrically unstable. in these patients over the treatment course mean volumetric changes of 30 and 40% for rectum and bladder were detected which possibly represents values justifying adjustment of patient preparation frequent re planning or a plan of the day strategy. based on our research by combining daily igrt images with rigid/deformable registration and dose warping it is possible to apply a machine learning approach to the clinical setting obtaining useful information for a decision regarding an individualized adaptive strategy. especially for treatments influenced by the movement of hollow organs this could reduce inadequate treatments and possibly reduce toxicity thereby increasing overall rt efficacy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113792</th>\n",
       "      <td>an autonomous mobile system for the management of copd. managing chronic disease through automated systems has the potential to both benefit the patient and reduce health care costs. we have developed and evaluated a disease management system for patients with chronic obstructive pulmonary disease copd . its aim is to predict and detect exacerbations and through this help patients self manage their disease to prevent hospitalisation.</td>\n",
       "      <td>an autonomous mobile system for the management of copd. managing chronic disease through automated systems has the potential to both benefit the patient and reduce health care costs. we have developed and evaluated a disease management system for patients with chronic obstructive pulmonary disease copd . its aim is to predict and detect exacerbations and through this help patients self manage their disease to prevent hospitalisation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114451</th>\n",
       "      <td>glaucoma risk assessment based on clinical data and automated nerve fiber layer defects detection. glaucoma is the first leading cause of vision loss in japan thus developing a scheme for helping glaucoma diagnosis is important. for this problem automated nerve fiber layer defects nflds detection method was proposed but glaucoma risk assessment using this method was not evaluated. in this paper computerized risk assessment for having glaucoma was attempted by use of the patients' clinical information and the performances of the nflds detection and the glaucoma risk assessment were compared. the clinical data includes the systemic data ophthalmologic data and right and left retinal images. glaucoma risk assessment was built by using machine learning technique which were artificial neural network radial basis function rbf network k nearest neighbor algorithm and support vector machine. the inputting parameter was ten clinical ones with/without the results of nflds detection. as a result proposed glaucoma risk assessment showed the higher performance than the nfld detection. the result of the glaucoma risk assessment indicates that the computerized assessment may be useful for the determination of glaucoma risk.</td>\n",
       "      <td>glaucoma risk assessment based on clinical data and automated nerve fiber layer defects detection. glaucoma is the first leading cause of vision loss in japan thus developing a scheme for helping glaucoma diagnosis is important. for this problem automated nerve fiber layer defects nflds detection method was proposed but glaucoma risk assessment using this method was not evaluated. in this paper computerized risk assessment for having glaucoma was attempted by use of the patients' clinical information and the performances of the nflds detection and the glaucoma risk assessment were compared. the clinical data includes the systemic data ophthalmologic data and right and left retinal images. glaucoma risk assessment was built by using machine learning technique which were artificial neural network radial basis function rbf network k nearest neighbor algorithm and support vector machine. the inputting parameter was 10 clinical ones with/without the results of nflds detection. as a result proposed glaucoma risk assessment showed the higher performance than the nfld detection. the result of the glaucoma risk assessment indicates that the computerized assessment may be useful for the determination of glaucoma risk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>short term prediction of future continuous glucose monitoring readings in type 1 diabetes: development and validation of a neural network regression model. cgm systems are still subject to a time delay which especially during rapid changes causes clinically significant difference between the cgm and the actual bg level. this study had the aim of exploring the potential of developing and validating a model for prediction of future cgm measurements in order to overcome the time delay.</td>\n",
       "      <td>short term prediction of future continuous glucose monitoring readings in type 1 diabetes: development and validation of a neural network regression model. cgm systems are still subject to a time delay which especially during rapid changes causes clinically significant difference between the cgm and the actual bg level. this study had the aim of exploring the potential of developing and validating a model for prediction of future cgm measurements in order to overcome the time delay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123827</th>\n",
       "      <td>identification of a blood based biomarker panel for classification of alzheimer's disease. an ideal diagnostic test for alzheimer's disease ad should be non invasive and easily applicable. thus there is a clear need to search for biomarkers in blood. in the present study we have used multivariate data analysis  support vector machine svm   to investigate whether a blood based biomarker panel allows discrimination between ad patients and healthy controls at the individual level. we collected a total of 155 serum samples from individuals with early ad and age matched healthy controls and measured serum levels of 24 markers involved in several biological pathways by elisa. the dataset was randomly split into a training set for predictor discovery and classification training and a test set for class prediction of blinded samples 3:1 ratio to evaluate the chosen predictors and parameters. after selection of a feature group of the three most discriminative parameters cortisol von willebrand factor oxidized ldl antibodies in the training set the application of svm to the training/independent test dataset resulted in an 81.7%/87.1% correct classification for ad and control subjects. in conclusion we identified a panel of three blood markers which allowed svm based distinguishing of ad patients from healthy controls on a single subject classification level with clinically relevant accuracy and validity. blood based biomarkers might have utility in ad diagnostics as screening tool before further classification with csf biomarkers and imaging. future studies should examine whether blood based biomarkers may also be useful to differentiate ad patients from other dementias.</td>\n",
       "      <td>identification of a blood based biomarker panel for classification of alzheimer's disease. an ideal diagnostic test for alzheimer's disease ad should be non invasive and easily applicable. thus there is a clear need to search for biomarkers in blood. in the present study we have used multivariate data analysis support vector machine svm to investigate whether a blood based biomarker panel allows discrimination between ad patients and healthy controls at the individual level. we collected a total of 155 serum samples from individuals with early ad and age matched healthy controls and measured serum levels of 24 markers involved in several biological pathways by elisa. the dataset was randomly split into a training set for predictor discovery and classification training and a test set for class prediction of blinded samples 3:1 ratio to evaluate the chosen predictors and parameters. after selection of a feature group of the 3 most discriminative parameters cortisol von willebrand factor oxidized ldl antibodies in the training set the application of svm to the training/independent test dataset resulted in an 81.7%/87.1% correct classification for ad and control subjects. in conclusion we identified a panel of 3 blood markers which allowed svm based distinguishing of ad patients from healthy controls on a single subject classification level with clinically relevant accuracy and validity. blood based biomarkers might have utility in ad diagnostics as screening tool before further classification with csf biomarkers and imaging. future studies should examine whether blood based biomarkers may also be useful to differentiate ad patients from other dementias.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44102</th>\n",
       "      <td>diagnosis and classification of cancer using hybrid model based on relieff and convolutional neural network. machine learning and deep learning methods aims to discover patterns out of datasets such as microarray data and medical data. in recent years the importance of producing microarray data from tissue and cell samples and analyzing these microarray data has increased. machine learning and deep learning methods have been started to use in the diagnosis and classification of microarray data of cancer diseases. however it is challenging to analyze microarray data due to the small number of sample size and high number of features of microarray data and in some cases some features may not be relevant with the classification. because of this reason studies in the literature focused on developing feature selection/dimension reduction techniques and classification algorithms to improve classification accuracy of the microarray data. this study proposes hybrid methods by using relief and stacked autoencoder approaches for dimension reduction and support vector machines svm and convolutional neural networks cnn for classification. in the study three microarray datasets of overian leukemia and central nervous system cns were used. ovarian dataset contains 253 samples 15154 genes and 2 classes leukemia dataset contains 72 samples 7129 genes and 2 classes and cns dataset contains 60 samples 7129 genes and 2 classes. among the methods applied to the three microarray data the best classification accuracy without dimension reduction was observed with svm as 96.14% for ovarian dataset 94.83% for leukemia dataset and 65% for cns dataset. the proposed hybrid method relieff  cnn method outperformed other approaches. it gave 98.6% 99.86% and 83.95% classification accuracy for the datasets of ovarian leukemia and cns datasets respectively. results shows that dimension reduction methods improved the classification accuracy of the methods of svm and cnn.</td>\n",
       "      <td>diagnosis and classification of cancer using hybrid model based on relieff and convolutional neural network. machine learning and deep learning methods aims to discover patterns out of datasets such as microarray data and medical data. in recent years the importance of producing microarray data from tissue and cell samples and analyzing these microarray data has increased. machine learning and deep learning methods have been started to use in the diagnosis and classification of microarray data of cancer diseases. however it is challenging to analyze microarray data due to the small number of sample size and high number of features of microarray data and in some cases some features may not be relevant with the classification. because of this reason studies in the literature focused on developing feature selection/dimension reduction techniques and classification algorithms to improve classification accuracy of the microarray data. this study proposes hybrid methods by using relief and stacked autoencoder approaches for dimension reduction and support vector machines svm and convolutional neural networks cnn for classification. in the study 3 microarray datasets of overian leukemia and central nervous system cns were used. ovarian dataset contains 253 samples 15154 genes and 2 classes leukemia dataset contains 72 samples 7129 genes and 2 classes and cns dataset contains 60 samples 7129 genes and 2 classes. among the methods applied to the 3 microarray data the best classification accuracy without dimension reduction was observed with svm as 96.14% for ovarian dataset 94.83% for leukemia dataset and 65% for cns dataset. the proposed hybrid method relieff cnn method outperformed other approaches. it gave 98.6% 99.86% and 83.95% classification accuracy for the datasets of ovarian leukemia and cns datasets respectively. results shows that dimension reduction methods improved the classification accuracy of the methods of svm and cnn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148137</th>\n",
       "      <td>texture analysis for tissue discrimination on t1 weighted mr images of the knee joint in a multicenter study: transferability of texture features and comparison of feature selection methods and classifiers. to investigate the reproducibility and transferability of texture features between mr centers and to compare two feature selection methods and two classifiers.</td>\n",
       "      <td>texture analysis for tissue discrimination on t1 weighted mr images of the knee joint in a multicenter study: transferability of texture features and comparison of feature selection methods and classifiers. to investigate the reproducibility and transferability of texture features between mr centers and to compare 2 feature selection methods and 2 classifiers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50349</th>\n",
       "      <td>classification of heart sound signals in congenital heart disease based on convolutional neural network . cardiac auscultation is the basic way for primary diagnosis and screening of congenital heart disease chd . a new classification algorithm of chd based on convolution neural network was proposed for analysis and classification of chd heart sounds in this work. the algorithm was based on the clinically collected diagnosed chd heart sound signal. firstly the heart sound signal preprocessing algorithm was used to extract and organize the mel cepstral coefficient mfsc of the heart sound signal in the one dimensional time domain and turn it into a two dimensional feature sample. secondly 1 000 feature samples were used to train and optimize the convolutional neural network and the training results with the accuracy of 0.896 and the loss value of 0.25 were obtained by using the adam optimizer. finally 200 samples were tested with convolution neural network and the results showed that the accuracy was up to 0.895 the sensitivity was 0.910 and the specificity was 0.880. compared with other algorithms the proposed algorithm has improved accuracy and specificity. it proves that the proposed method effectively improves the robustness and accuracy of heart sound classification and is expected to be applied to machine assisted auscultation.</td>\n",
       "      <td>classification of heart sound signals in congenital heart disease based on convolutional neural network . cardiac auscultation is the basic way for primary diagnosis and screening of congenital heart disease chd . a new classification algorithm of chd based on convolution neural network was proposed for analysis and classification of chd heart sounds in this work. the algorithm was based on the clinically collected diagnosed chd heart sound signal. firstly the heart sound signal preprocessing algorithm was used to extract and organize the mel cepstral coefficient mfsc of the heart sound signal in the one dimensional time domain and turn it into a 2 dimensional feature sample. secondly 1 000 feature samples were used to train and optimize the convolutional neural network and the training results with the accuracy of 0.896 and the loss value of 0.25 were obtained by using the adam optimizer. finally 200 samples were tested with convolution neural network and the results showed that the accuracy was up to 0.895 the sensitivity was 0.910 and the specificity was 0.880. compared with other algorithms the proposed algorithm has improved accuracy and specificity. it proves that the proposed method effectively improves the robustness and accuracy of heart sound classification and is expected to be applied to machine assisted auscultation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "7929                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       performance assessment of the metastatic spinal tumor frailty index using machine learning algorithms: limitations and future directions. frailty is recognized as an important consideration in patients with cancer who are undergoing therapies including spine surgery. the definition of frailty in the context of spinal metastases is unclear and few have studied such markers and their association with postoperative outcomes and survival. using national databases the metastatic spinal tumor frailty index mstfi was developed as a tool to predict outcomes in this specific patient population and has not been tested with external data. the purpose of this study was to test the performance of the mstfi with institutional data and determine whether machine learning methods could better identify measures of frailty as predictors of outcomes.   \n",
       "148585                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      adaptive neuro fuzzy inference systems for analysis of internal carotid arterial doppler signals. in this study a new approach based on adaptive neuro fuzzy inference system anfis was presented for detection of internal carotid artery stenosis and occlusion. the internal carotid arterial doppler signals were recorded from 130 subjects that 45 of them suffered from internal carotid artery stenosis 44 of them suffered from internal carotid artery occlusion and the rest of them were healthy subjects. the three anfis classifiers were used to detect internal carotid artery conditions normal stenosis and occlusion when two features resistivity and pulsatility indices defining changes of internal carotid arterial doppler waveforms were used as inputs. to improve diagnostic accuracy the fourth anfis classifier combining anfis was trained using the outputs of the three anfis classifiers as input data. the proposed anfis model combined the neural network adaptive capabilities and the fuzzy logic qualitative approach. some conclusions concerning the impacts of features on the detection of internal carotid artery stenosis and occlusion were obtained through analysis of the anfis. the performance of the anfis model was evaluated in terms of classification accuracies and the results confirmed that the proposed anfis classifiers have some potential in detecting the internal carotid artery stenosis and occlusion. the anfis model achieved accuracy rates which were higher than that of the stand alone neural network model.   \n",
       "60160                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                lstm based ecg classification for continuous monitoring on personal wearable devices. a novel electrocardiogram ecg classification algorithm is proposed for continuous cardiac monitoring on wearable devices with limited processing capacity.   \n",
       "107301                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          a fuzzy controller for lower limb exoskeletons during sit to stand and stand to sit movement using wearable sensors. human motion is a daily and rhythmic activity. the exoskeleton concept is a very positive scientific approach for human rehabilitation in case of lower limb impairment. although the exoskeleton shows potential it is not yet applied extensively in clinical rehabilitation. in this research a fuzzy based control algorithm is proposed for lower limb exoskeletons during sit to stand and stand to sit movements. surface electromyograms emgs are acquired from the vastus lateralis muscle using a wearable emg sensor. the resultant acceleration angle along the z axis is determined from a kinematics sensor. twenty volunteers were chosen to perform the experiments. the whole experiment was accomplished in two phases. in the first phase acceleration angles and emg data were acquired from the volunteers during both sit to stand and stand to sit motions. during sit to stand movements the average acceleration angle at activation was 11° 48° and the emg varied from 0.19 mv to 0.19 mv. on the other hand during stand to sit movements the average acceleration angle was found to be 57.5° 108° at the activation point and the emg varied from 0.32 mv to 0.32 mv. in the second phase a fuzzy controller was designed from the experimental data. the controller was tested and validated with both offline and real time data using labview.    \n",
       "144856                                                                                                                                                                                                             development and assessment of methods for detecting dementia using the human electroencephalogram. this paper makes an outline case for the need for a low cost easy to administer method for detecting dementia within the growing at risk population. it proposes two methods for electroencephalogram eeg analysis for detecting dementia that could fulfil such a need. the paper describes a fractal dimension based method for analyzing the eeg waveforms of subjects with dementia and reports on an assessment which demonstrates that an appropriate fractal dimension measure could achieve 67% sensitivity to probable alzheimer's disease as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. an alternative method based on the probability density function of the zero crossing intervals is shown to achieve 78% sensitivity to probable alzheimer's disease and an estimated sensitivity to probable vascular or mixed dementia of 35% as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. this compares well with other studies reported by the american academy of neurology which typically provide a sensitivity of 81% and specificity of 70%. the eeg recordings used to assess these methods included artefacts and had no a priori selection of elements \"suitable for analysis.\" this approach gives a good prediction of the usefulness of the methods as they would be used in practice. a total of 39 patients 30 probable alzheimer's disease six vascular dementia and three mixed dementia and 42 healthy volunteers were involved in the study. however although results from the preliminary evaluation of the methods are promising there is a need for a more extensive study to validate the methods using eegs from a larger and more varied patient cohorts with neuroimaging results to exclude other causes and cognitive scores to correlate results with severity of cognitive status.   \n",
       "39877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 research of low rank representation and discriminant correlation analysis for alzheimer's disease diagnosis. as population aging is becoming more common worldwide applying artificial intelligence into the diagnosis of alzheimer's disease ad is critical to improve the diagnostic level in recent years. in early diagnosis of ad the fusion of complementary information contained in multimodality data e.g. magnetic resonance imaging mri positron emission tomography pet and cerebrospinal fluid csf  has obtained enormous achievement. detecting alzheimer's disease using multimodality data has two difficulties: 1 there exists noise information in multimodal data; 2 how to establish an effective mathematical model of the relationship between multimodal data? to this end we proposed a method named ldf which is based on the combination of low rank representation and discriminant correlation analysis dca to fuse multimodal datasets. specifically the low rank representation method is used to extract the latent features of the submodal data so the noise information in the submodal data is removed. then discriminant correlation analysis is used to fuse the submodal data so the complementary information can be fully utilized. the experimental results indicate the effectiveness of this method.   \n",
       "76312                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                shared and distinct rupture discriminants of small and large intracranial aneurysms. many ruptured intracranial aneurysms ias are small. clinical presentations suggest that small and large ias could have different phenotypes. it is unknown if small and large ias have different characteristics that discriminate rupture.   \n",
       "85862   expert system classifier for adaptive radiation therapy in prostate cancer. a classifier based expert system was developed to compare delivered and planned radiation therapy in prostate cancer patients. its aim is to automatically identify patients that can benefit from an adaptive treatment strategy. the study predominantly addresses dosimetric uncertainties and critical issues caused by motion of hollow organs. 1200 mvct images of 38 prostate adenocarcinoma cases were analyzed. an automatic daily re contouring of structures i.e. rectum bladder and femoral heads rigid/deformable registration and dose warping was carried out to simulate dose and volume variations during therapy. support vector machine k means clustering algorithms and similarity index analysis were used to create an unsupervised predictive tool to detect incorrect setup and/or morphological changes as a consequence of inadequate patient preparation due to stochastic physiological changes supporting clinical decision making. after training on a dataset that was considered sufficiently dosimetrically stable the system identified two equally sized macro clusters with distinctly different volumetric and dosimetric baseline properties and defined thresholds for these two clusters. application to the test cohort resulted in 25% of the patients located outside the two macro clusters thresholds and which were therefore suspected to be dosimetrically unstable. in these patients over the treatment course mean volumetric changes of 30 and 40% for rectum and bladder were detected which possibly represents values justifying adjustment of patient preparation frequent re planning or a plan of the day strategy. based on our research by combining daily igrt images with rigid/deformable registration and dose warping it is possible to apply a machine learning approach to the clinical setting obtaining useful information for a decision regarding an individualized adaptive strategy. especially for treatments influenced by the movement of hollow organs this could reduce inadequate treatments and possibly reduce toxicity thereby increasing overall rt efficacy.   \n",
       "113792                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          an autonomous mobile system for the management of copd. managing chronic disease through automated systems has the potential to both benefit the patient and reduce health care costs. we have developed and evaluated a disease management system for patients with chronic obstructive pulmonary disease copd . its aim is to predict and detect exacerbations and through this help patients self manage their disease to prevent hospitalisation.   \n",
       "114451                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   glaucoma risk assessment based on clinical data and automated nerve fiber layer defects detection. glaucoma is the first leading cause of vision loss in japan thus developing a scheme for helping glaucoma diagnosis is important. for this problem automated nerve fiber layer defects nflds detection method was proposed but glaucoma risk assessment using this method was not evaluated. in this paper computerized risk assessment for having glaucoma was attempted by use of the patients' clinical information and the performances of the nflds detection and the glaucoma risk assessment were compared. the clinical data includes the systemic data ophthalmologic data and right and left retinal images. glaucoma risk assessment was built by using machine learning technique which were artificial neural network radial basis function rbf network k nearest neighbor algorithm and support vector machine. the inputting parameter was ten clinical ones with/without the results of nflds detection. as a result proposed glaucoma risk assessment showed the higher performance than the nfld detection. the result of the glaucoma risk assessment indicates that the computerized assessment may be useful for the determination of glaucoma risk.   \n",
       "7932                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          short term prediction of future continuous glucose monitoring readings in type 1 diabetes: development and validation of a neural network regression model. cgm systems are still subject to a time delay which especially during rapid changes causes clinically significant difference between the cgm and the actual bg level. this study had the aim of exploring the potential of developing and validating a model for prediction of future cgm measurements in order to overcome the time delay.   \n",
       "123827                                                                                                                                                                                                                                                                                                                                                                                                                                                                      identification of a blood based biomarker panel for classification of alzheimer's disease. an ideal diagnostic test for alzheimer's disease ad should be non invasive and easily applicable. thus there is a clear need to search for biomarkers in blood. in the present study we have used multivariate data analysis  support vector machine svm   to investigate whether a blood based biomarker panel allows discrimination between ad patients and healthy controls at the individual level. we collected a total of 155 serum samples from individuals with early ad and age matched healthy controls and measured serum levels of 24 markers involved in several biological pathways by elisa. the dataset was randomly split into a training set for predictor discovery and classification training and a test set for class prediction of blinded samples 3:1 ratio to evaluate the chosen predictors and parameters. after selection of a feature group of the three most discriminative parameters cortisol von willebrand factor oxidized ldl antibodies in the training set the application of svm to the training/independent test dataset resulted in an 81.7%/87.1% correct classification for ad and control subjects. in conclusion we identified a panel of three blood markers which allowed svm based distinguishing of ad patients from healthy controls on a single subject classification level with clinically relevant accuracy and validity. blood based biomarkers might have utility in ad diagnostics as screening tool before further classification with csf biomarkers and imaging. future studies should examine whether blood based biomarkers may also be useful to differentiate ad patients from other dementias.   \n",
       "44102                                                                                                                                                                               diagnosis and classification of cancer using hybrid model based on relieff and convolutional neural network. machine learning and deep learning methods aims to discover patterns out of datasets such as microarray data and medical data. in recent years the importance of producing microarray data from tissue and cell samples and analyzing these microarray data has increased. machine learning and deep learning methods have been started to use in the diagnosis and classification of microarray data of cancer diseases. however it is challenging to analyze microarray data due to the small number of sample size and high number of features of microarray data and in some cases some features may not be relevant with the classification. because of this reason studies in the literature focused on developing feature selection/dimension reduction techniques and classification algorithms to improve classification accuracy of the microarray data. this study proposes hybrid methods by using relief and stacked autoencoder approaches for dimension reduction and support vector machines svm and convolutional neural networks cnn for classification. in the study three microarray datasets of overian leukemia and central nervous system cns were used. ovarian dataset contains 253 samples 15154 genes and 2 classes leukemia dataset contains 72 samples 7129 genes and 2 classes and cns dataset contains 60 samples 7129 genes and 2 classes. among the methods applied to the three microarray data the best classification accuracy without dimension reduction was observed with svm as 96.14% for ovarian dataset 94.83% for leukemia dataset and 65% for cns dataset. the proposed hybrid method relieff  cnn method outperformed other approaches. it gave 98.6% 99.86% and 83.95% classification accuracy for the datasets of ovarian leukemia and cns datasets respectively. results shows that dimension reduction methods improved the classification accuracy of the methods of svm and cnn.   \n",
       "148137                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 texture analysis for tissue discrimination on t1 weighted mr images of the knee joint in a multicenter study: transferability of texture features and comparison of feature selection methods and classifiers. to investigate the reproducibility and transferability of texture features between mr centers and to compare two feature selection methods and two classifiers.   \n",
       "50349                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       classification of heart sound signals in congenital heart disease based on convolutional neural network . cardiac auscultation is the basic way for primary diagnosis and screening of congenital heart disease chd . a new classification algorithm of chd based on convolution neural network was proposed for analysis and classification of chd heart sounds in this work. the algorithm was based on the clinically collected diagnosed chd heart sound signal. firstly the heart sound signal preprocessing algorithm was used to extract and organize the mel cepstral coefficient mfsc of the heart sound signal in the one dimensional time domain and turn it into a two dimensional feature sample. secondly 1 000 feature samples were used to train and optimize the convolutional neural network and the training results with the accuracy of 0.896 and the loss value of 0.25 were obtained by using the adam optimizer. finally 200 samples were tested with convolution neural network and the results showed that the accuracy was up to 0.895 the sensitivity was 0.910 and the specificity was 0.880. compared with other algorithms the proposed algorithm has improved accuracy and specificity. it proves that the proposed method effectively improves the robustness and accuracy of heart sound classification and is expected to be applied to machine assisted auscultation.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            a2d  \n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "7929                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 performance assessment of the metastatic spinal tumor frailty index using machine learning algorithms: limitations and future directions. frailty is recognized as an important consideration in patients with cancer who are undergoing therapies including spine surgery. the definition of frailty in the context of spinal metastases is unclear and few have studied such markers and their association with postoperative outcomes and survival. using national databases the metastatic spinal tumor frailty index mstfi was developed as a tool to predict outcomes in this specific patient population and has not been tested with external data. the purpose of this study was to test the performance of the mstfi with institutional data and determine whether machine learning methods could better identify measures of frailty as predictors of outcomes.  \n",
       "148585                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             adaptive neuro fuzzy inference systems for analysis of internal carotid arterial doppler signals. in this study a new approach based on adaptive neuro fuzzy inference system anfis was presented for detection of internal carotid artery stenosis and occlusion. the internal carotid arterial doppler signals were recorded from 130 subjects that 45 of them suffered from internal carotid artery stenosis 44 of them suffered from internal carotid artery occlusion and the rest of them were healthy subjects. the 3 anfis classifiers were used to detect internal carotid artery conditions normal stenosis and occlusion when 2 features resistivity and pulsatility indices defining changes of internal carotid arterial doppler waveforms were used as inputs. to improve diagnostic accuracy the 4th anfis classifier combining anfis was trained using the outputs of the 3 anfis classifiers as input data. the proposed anfis model combined the neural network adaptive capabilities and the fuzzy logic qualitative approach. some conclusions concerning the impacts of features on the detection of internal carotid artery stenosis and occlusion were obtained through analysis of the anfis. the performance of the anfis model was evaluated in terms of classification accuracies and the results confirmed that the proposed anfis classifiers have some potential in detecting the internal carotid artery stenosis and occlusion. the anfis model achieved accuracy rates which were higher than that of the stand alone neural network model.  \n",
       "60160                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          lstm based ecg classification for continuous monitoring on personal wearable devices. a novel electrocardiogram ecg classification algorithm is proposed for continuous cardiac monitoring on wearable devices with limited processing capacity.  \n",
       "107301                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          a fuzzy controller for lower limb exoskeletons during sit to stand and stand to sit movement using wearable sensors. human motion is a daily and rhythmic activity. the exoskeleton concept is a very positive scientific approach for human rehabilitation in case of lower limb impairment. although the exoskeleton shows potential it is not yet applied extensively in clinical rehabilitation. in this research a fuzzy based control algorithm is proposed for lower limb exoskeletons during sit to stand and stand to sit movements. surface electromyograms emgs are acquired from the vastus lateralis muscle using a wearable emg sensor. the resultant acceleration angle along the z axis is determined from a kinematics sensor. 20 volunteers were chosen to perform the experiments. the whole experiment was accomplished in 2 phases. in the first phase acceleration angles and emg data were acquired from the volunteers during both sit to stand and stand to sit motions. during sit to stand movements the average acceleration angle at activation was 11° 48° and the emg varied from 0.19 mv to 0.19 mv. on the other hand during stand to sit movements the average acceleration angle was found to be 57.5° 108° at the activation point and the emg varied from 0.32 mv to 0.32 mv. in the second phase a fuzzy controller was designed from the experimental data. the controller was tested and validated with both offline and real time data using labview.   \n",
       "144856                                                                                                                                                                                                               development and assessment of methods for detecting dementia using the human electroencephalogram. this paper makes an outline case for the need for a low cost easy to administer method for detecting dementia within the growing at risk population. it proposes 2 methods for electroencephalogram eeg analysis for detecting dementia that could fulfil such a need. the paper describes a fractal dimension based method for analyzing the eeg waveforms of subjects with dementia and reports on an assessment which demonstrates that an appropriate fractal dimension measure could achieve 67% sensitivity to probable alzheimer's disease as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. an alternative method based on the probability density function of the zero crossing intervals is shown to achieve 78% sensitivity to probable alzheimer's disease and an estimated sensitivity to probable vascular or mixed dementia of 35% as suggested by clinical psychometric testing and eeg findings with a specificity of 99.9%. this compares well with other studies reported by the american academy of neurology which typically provide a sensitivity of 81% and specificity of 70%. the eeg recordings used to assess these methods included artefacts and had no a priori selection of elements \"suitable for analysis.\" this approach gives a good prediction of the usefulness of the methods as they would be used in practice. a total of 39 patients 30 probable alzheimer's disease 6 vascular dementia and 3 mixed dementia and 42 healthy volunteers were involved in the study. however although results from the preliminary evaluation of the methods are promising there is a need for a more extensive study to validate the methods using eegs from a larger and more varied patient cohorts with neuroimaging results to exclude other causes and cognitive scores to correlate results with severity of cognitive status.  \n",
       "39877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              research of low rank representation and discriminant correlation analysis for alzheimer's disease diagnosis. as population aging is becoming more common worldwide applying artificial intelligence into the diagnosis of alzheimer's disease ad is critical to improve the diagnostic level in recent years. in early diagnosis of ad the fusion of complementary information contained in multimodality data e.g. magnetic resonance imaging mri positron emission tomography pet and cerebrospinal fluid csf has obtained enormous achievement. detecting alzheimer's disease using multimodality data has 2 difficulties: 1 there exists noise information in multimodal data; 2 how to establish an effective mathematical model of the relationship between multimodal data? to this end we proposed a method named ldf which is based on the combination of low rank representation and discriminant correlation analysis dca to fuse multimodal datasets. specifically the low rank representation method is used to extract the latent features of the submodal data so the noise information in the submodal data is removed. then discriminant correlation analysis is used to fuse the submodal data so the complementary information can be fully utilized. the experimental results indicate the effectiveness of this method.  \n",
       "76312                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          shared and distinct rupture discriminants of small and large intracranial aneurysms. many ruptured intracranial aneurysms ias are small. clinical presentations suggest that small and large ias could have different phenotypes. it is unknown if small and large ias have different characteristics that discriminate rupture.  \n",
       "85862   expert system classifier for adaptive radiation therapy in prostate cancer. a classifier based expert system was developed to compare delivered and planned radiation therapy in prostate cancer patients. its aim is to automatically identify patients that can benefit from an adaptive treatment strategy. the study predominantly addresses dosimetric uncertainties and critical issues caused by motion of hollow organs. 1200 mvct images of 38 prostate adenocarcinoma cases were analyzed. an automatic daily re contouring of structures i.e. rectum bladder and femoral heads rigid/deformable registration and dose warping was carried out to simulate dose and volume variations during therapy. support vector machine k means clustering algorithms and similarity index analysis were used to create an unsupervised predictive tool to detect incorrect setup and/or morphological changes as a consequence of inadequate patient preparation due to stochastic physiological changes supporting clinical decision making. after training on a dataset that was considered sufficiently dosimetrically stable the system identified 2 equally sized macro clusters with distinctly different volumetric and dosimetric baseline properties and defined thresholds for these 2 clusters. application to the test cohort resulted in 25% of the patients located outside the 2 macro clusters thresholds and which were therefore suspected to be dosimetrically unstable. in these patients over the treatment course mean volumetric changes of 30 and 40% for rectum and bladder were detected which possibly represents values justifying adjustment of patient preparation frequent re planning or a plan of the day strategy. based on our research by combining daily igrt images with rigid/deformable registration and dose warping it is possible to apply a machine learning approach to the clinical setting obtaining useful information for a decision regarding an individualized adaptive strategy. especially for treatments influenced by the movement of hollow organs this could reduce inadequate treatments and possibly reduce toxicity thereby increasing overall rt efficacy.  \n",
       "113792                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    an autonomous mobile system for the management of copd. managing chronic disease through automated systems has the potential to both benefit the patient and reduce health care costs. we have developed and evaluated a disease management system for patients with chronic obstructive pulmonary disease copd . its aim is to predict and detect exacerbations and through this help patients self manage their disease to prevent hospitalisation.  \n",
       "114451                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              glaucoma risk assessment based on clinical data and automated nerve fiber layer defects detection. glaucoma is the first leading cause of vision loss in japan thus developing a scheme for helping glaucoma diagnosis is important. for this problem automated nerve fiber layer defects nflds detection method was proposed but glaucoma risk assessment using this method was not evaluated. in this paper computerized risk assessment for having glaucoma was attempted by use of the patients' clinical information and the performances of the nflds detection and the glaucoma risk assessment were compared. the clinical data includes the systemic data ophthalmologic data and right and left retinal images. glaucoma risk assessment was built by using machine learning technique which were artificial neural network radial basis function rbf network k nearest neighbor algorithm and support vector machine. the inputting parameter was 10 clinical ones with/without the results of nflds detection. as a result proposed glaucoma risk assessment showed the higher performance than the nfld detection. the result of the glaucoma risk assessment indicates that the computerized assessment may be useful for the determination of glaucoma risk.  \n",
       "7932                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    short term prediction of future continuous glucose monitoring readings in type 1 diabetes: development and validation of a neural network regression model. cgm systems are still subject to a time delay which especially during rapid changes causes clinically significant difference between the cgm and the actual bg level. this study had the aim of exploring the potential of developing and validating a model for prediction of future cgm measurements in order to overcome the time delay.  \n",
       "123827                                                                                                                                                                                                                                                                                                                                                                                                                                                                           identification of a blood based biomarker panel for classification of alzheimer's disease. an ideal diagnostic test for alzheimer's disease ad should be non invasive and easily applicable. thus there is a clear need to search for biomarkers in blood. in the present study we have used multivariate data analysis support vector machine svm to investigate whether a blood based biomarker panel allows discrimination between ad patients and healthy controls at the individual level. we collected a total of 155 serum samples from individuals with early ad and age matched healthy controls and measured serum levels of 24 markers involved in several biological pathways by elisa. the dataset was randomly split into a training set for predictor discovery and classification training and a test set for class prediction of blinded samples 3:1 ratio to evaluate the chosen predictors and parameters. after selection of a feature group of the 3 most discriminative parameters cortisol von willebrand factor oxidized ldl antibodies in the training set the application of svm to the training/independent test dataset resulted in an 81.7%/87.1% correct classification for ad and control subjects. in conclusion we identified a panel of 3 blood markers which allowed svm based distinguishing of ad patients from healthy controls on a single subject classification level with clinically relevant accuracy and validity. blood based biomarkers might have utility in ad diagnostics as screening tool before further classification with csf biomarkers and imaging. future studies should examine whether blood based biomarkers may also be useful to differentiate ad patients from other dementias.  \n",
       "44102                                                                                                                                                                                  diagnosis and classification of cancer using hybrid model based on relieff and convolutional neural network. machine learning and deep learning methods aims to discover patterns out of datasets such as microarray data and medical data. in recent years the importance of producing microarray data from tissue and cell samples and analyzing these microarray data has increased. machine learning and deep learning methods have been started to use in the diagnosis and classification of microarray data of cancer diseases. however it is challenging to analyze microarray data due to the small number of sample size and high number of features of microarray data and in some cases some features may not be relevant with the classification. because of this reason studies in the literature focused on developing feature selection/dimension reduction techniques and classification algorithms to improve classification accuracy of the microarray data. this study proposes hybrid methods by using relief and stacked autoencoder approaches for dimension reduction and support vector machines svm and convolutional neural networks cnn for classification. in the study 3 microarray datasets of overian leukemia and central nervous system cns were used. ovarian dataset contains 253 samples 15154 genes and 2 classes leukemia dataset contains 72 samples 7129 genes and 2 classes and cns dataset contains 60 samples 7129 genes and 2 classes. among the methods applied to the 3 microarray data the best classification accuracy without dimension reduction was observed with svm as 96.14% for ovarian dataset 94.83% for leukemia dataset and 65% for cns dataset. the proposed hybrid method relieff cnn method outperformed other approaches. it gave 98.6% 99.86% and 83.95% classification accuracy for the datasets of ovarian leukemia and cns datasets respectively. results shows that dimension reduction methods improved the classification accuracy of the methods of svm and cnn.  \n",
       "148137                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               texture analysis for tissue discrimination on t1 weighted mr images of the knee joint in a multicenter study: transferability of texture features and comparison of feature selection methods and classifiers. to investigate the reproducibility and transferability of texture features between mr centers and to compare 2 feature selection methods and 2 classifiers.  \n",
       "50349                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   classification of heart sound signals in congenital heart disease based on convolutional neural network . cardiac auscultation is the basic way for primary diagnosis and screening of congenital heart disease chd . a new classification algorithm of chd based on convolution neural network was proposed for analysis and classification of chd heart sounds in this work. the algorithm was based on the clinically collected diagnosed chd heart sound signal. firstly the heart sound signal preprocessing algorithm was used to extract and organize the mel cepstral coefficient mfsc of the heart sound signal in the one dimensional time domain and turn it into a 2 dimensional feature sample. secondly 1 000 feature samples were used to train and optimize the convolutional neural network and the training results with the accuracy of 0.896 and the loss value of 0.25 were obtained by using the adam optimizer. finally 200 samples were tested with convolution neural network and the results showed that the accuracy was up to 0.895 the sensitivity was 0.910 and the specificity was 0.880. compared with other algorithms the proposed algorithm has improved accuracy and specificity. it proves that the proposed method effectively improves the robustness and accuracy of heart sound classification and is expected to be applied to machine assisted auscultation.  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e51a0f",
   "metadata": {},
   "source": [
    "## String2NumericEntities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "465d4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3c8a460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5%', '20']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##gets tokens for all numbers only\n",
    "\n",
    "def get_num(string):\n",
    "    tokens = re.findall(r'[0-9%]+(?:,[0-9]{3})*(?:\\.[0-9]+)?|\\.[0-9]+', string)  \n",
    "    return tokens\n",
    "\n",
    "##test\n",
    "get_num(\"maud owns 5% cats which have 20 legs between them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bff47357",
   "metadata": {},
   "outputs": [],
   "source": [
    "##gets tokens for numbers + following one word\n",
    "#\n",
    "#def get_num_plusone(string):\n",
    "#    tokens = re.findall(r' ([0-9]+(?:,[0-9]{3})*(?:\\.[0-9]+)?|\\.[0-9]+) ?([a-zA-Z]*)', string)  \n",
    "#    \n",
    "#    tokens2 = []\n",
    "#    \n",
    "#    for y in tokens:\n",
    "#        z = ' '.join(y)\n",
    "#        tokens2.append(z)\n",
    "#    \n",
    "#    return tokens2\n",
    "#\n",
    "##test\n",
    "#get_num_plusone(\"maud owns 5 cats which have 20 legs between them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "32a77283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 cats which have ',\n",
       " '20 legs between them as',\n",
       " '5 tails and  ',\n",
       " '10 eyes   ']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##gets tokens for numbers + following words with look ahead -> (?=(regex))\n",
    "\n",
    "def get_num_plus(string):\n",
    "    tokens = re.findall(r' (?=([0-9]+(?:,[0-9]{3})*(?:\\.[0-9]+)?|\\.[0-9]+) ?([a-zA-Z]*) ?([a-zA-Z]*) ?([a-zA-Z]*) ?([a-zA-Z]*))', string)  \n",
    "    \n",
    "    tokens2 = []\n",
    "    \n",
    "    for y in tokens:\n",
    "        z = ' '.join(y)\n",
    "        tokens2.append(z)\n",
    "    \n",
    "    return tokens2\n",
    "\n",
    "##test\n",
    "get_num_plus(\"maud owns 5 cats which have 20 legs between them as well as 5 tails and 10 eyes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3d78b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##gets tokens for numbers + preceding word\n",
    "#\n",
    "#def get_num_minusone(string):\n",
    "#    tokens = re.findall(r'([a-zA-Z]+) ([0-9]+(?:,[0-9]{3})*(?:\\.[0-9]+)?|\\.[0-9]+)', string)  \n",
    "#    \n",
    "#    tokens2 = []\n",
    "#    \n",
    "#    for y in tokens:\n",
    "#        z = ' '.join(y)\n",
    "#        tokens2.append(z)\n",
    "#    \n",
    "#    return tokens2\n",
    "#\n",
    "##test\n",
    "#get_num_minusone(\"maud owns 5 cats which have 20 legs between them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10a50b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n = 5', 'which have 20']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##gets tokens for numbers + preceding three words\n",
    "\n",
    "def get_num_minus(string):\n",
    "    tokens = re.findall(r' ([a-zA-Z=]+) ([a-zA-Z=]+) ([0-9]+(?:,[0-9]{3})*(?:\\.[0-9]+)?|\\.[0-9]+)', string)  \n",
    "    \n",
    "    tokens2 = []\n",
    "    \n",
    "    for y in tokens:\n",
    "        z = ' '.join(y)\n",
    "        tokens2.append(z)\n",
    "    \n",
    "    return tokens2\n",
    "\n",
    "##test\n",
    "get_num_minus(\"maud owns n = 5 cats which have 20 legs between them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a13aa3",
   "metadata": {},
   "source": [
    "## Parse Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8da049c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "\n",
    "for x in all_text['a2d']:\n",
    "    try:\n",
    "        templist.append(get_num(x))\n",
    "    except Exception:\n",
    "        templist.append('skip')\n",
    "\n",
    "all_text['num'] = templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92f5dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now stop parsing % as space\n",
    "all_text['a2d']=all_text['a2d'].str.replace('%','percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcaeeb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "\n",
    "for x in all_text['a2d']:\n",
    "    try:\n",
    "        templist.append(get_num_plus(x))\n",
    "    except Exception:\n",
    "        templist.append('skip')\n",
    "\n",
    "all_text['num_plus'] = templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c82b72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "templist = []\n",
    "\n",
    "for x in all_text['a2d']:\n",
    "    try:\n",
    "        templist.append(get_num_minus(x))\n",
    "    except Exception:\n",
    "        templist.append('skip')\n",
    "\n",
    "all_text['num_minus'] = templist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db1fafa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>a2d</th>\n",
       "      <th>num</th>\n",
       "      <th>num_plus</th>\n",
       "      <th>num_minus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132042</th>\n",
       "      <td>diagnosis of airway obstruction or restrictive spirometric patterns by multiclass support vector machines. this paper presents the use of multiclass support vector machines svms for diagnosis of spirometric patterns normal restrictive obstructive . the svm decisions were fused using the error correcting output codes ecoc . the multiclass svm with the ecoc was trained on three spirometric parameters forced expiratory volume in 1s fev1 forced vital capacity fvc and fev1/fvc ratio . the total classification accuracy of the svm is 97.32%. the obtained results confirmed the validity of the svms to help in clinical decision making.</td>\n",
       "      <td>diagnosis of airway obstruction or restrictive spirometric patterns by multiclass support vector machines. this paper presents the use of multiclass support vector machines svms for diagnosis of spirometric patterns normal restrictive obstructive . the svm decisions were fused using the error correcting output codes ecoc . the multiclass svm with the ecoc was trained on 3 spirometric parameters forced expiratory volume in 1s fev1 forced vital capacity fvc and fev1/fvc ratio . the total classification accuracy of the svm is 97.32percent. the obtained results confirmed the validity of the svms to help in clinical decision making.</td>\n",
       "      <td>[3, 1, 1, 1, 97.32, %]</td>\n",
       "      <td>[3 spirometric parameters forced expiratory, 1 s fev  , 97.32 percent   ]</td>\n",
       "      <td>[trained on 3, volume in 1, svm is 97.32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46879</th>\n",
       "      <td>prediction of skin disease with three different feature selection techniques using stacking ensemble method. skin disease is the most common problem between people. due to pollution and deployment of ozone layer harmful uv rays of sun burn the skin and develop various types of skin diseases. nowadays machine learning and deep learning algorithms are generally used for diagnosis for various kinds of diseases. in this study we have applied three feature extraction techniques univariate feature selection feature importance and correlation matrix with heat map to find the optimum data subset of erythemato squamous disease. four classification techniques gaussian naã¯ve bayesian nb decision tree dt support vector machine svm and random forest are used for measuring the performance of model. stacking ensemble technique is then applied to enhance the prediction performance of the model. the proposed method used for measuring the performance of the model. it is finding that the optimal subset of the erythemato squamous disease is performed well in the case of correlation and heat map feature selection techniques. the mean value slandered deviation root mean square error kappa statistical error and area under receiver operating characteristics and accuracy are calculated for demonstrating the effectiveness of the proposed model. the feature selection techniques applied with staking ensemble technique gives the better result as compared to individual machine learning techniques. the obtained results show that the performance of proposed model is higher than previous results obtained by researchers.</td>\n",
       "      <td>prediction of skin disease with 3 different feature selection techniques using stacking ensemble method. skin disease is the most common problem between people. due to pollution and deployment of ozone layer harmful uv rays of sun burn the skin and develop various types of skin diseases. nowadays machine learning and deep learning algorithms are generally used for diagnosis for various kinds of diseases. in this study we have applied 3 feature extraction techniques univariate feature selection feature importance and correlation matrix with heat map to find the optimum data subset of erythemato squamous disease. 4 classification techniques gaussian naã¯ve bayesian nb decision tree dt support vector machine svm and random forest are used for measuring the performance of model. stacking ensemble technique is then applied to enhance the prediction performance of the model. the proposed method used for measuring the performance of the model. it is finding that the optimal subset of the erythemato squamous disease is performed well in the case of correlation and heat map feature selection techniques. the mean value slandered deviation root mean square error kappa statistical error and area under receiver operating characteristics and accuracy are calculated for demonstrating the effectiveness of the proposed model. the feature selection techniques applied with staking ensemble technique gives the better result as compared to individual machine learning techniques. the obtained results show that the performance of proposed model is higher than previous results obtained by researchers.</td>\n",
       "      <td>[3, 3, 4]</td>\n",
       "      <td>[3 different feature selection techniques, 3 feature extraction techniques univariate, 4 classification techniques gaussian na]</td>\n",
       "      <td>[disease with 3, have applied 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47200</th>\n",
       "      <td>automatic detection of pain from facial expressions: a survey. pain sensation is essential for survival since it draws attention to physical threat to the body. pain assessment is usually done through self reports. however self assessment of pain is not available in the case of noncommunicative patients and therefore observer reports should be relied upon. observer reports of pain could be prone to errors due to subjective biases of observers. moreover continuous monitoring by humans is impractical. therefore automatic pain detection technology could be deployed to assist human caregivers and complement their service thereby improving the quality of pain management especially for noncommunicative patients. facial expressions are a reliable indicator of pain and are used in all observer based pain assessment tools. following the advancements in automatic facial expression analysis computer vision researchers have tried to use this technology for developing approaches for automatically detecting pain from facial expressions. this paper surveys the literature published in this field over the past decade categorizes it and identifies future research directions. the survey covers the pain datasets used in the reviewed literature the learning tasks targeted by the approaches the features extracted from images and image sequences to represent pain related information and finally the machine learning methods used.</td>\n",
       "      <td>automatic detection of pain from facial expressions: a survey. pain sensation is essential for survival since it draws attention to physical threat to the body. pain assessment is usually done through self reports. however self assessment of pain is not available in the case of noncommunicative patients and therefore observer reports should be relied upon. observer reports of pain could be prone to errors due to subjective biases of observers. moreover continuous monitoring by humans is impractical. therefore automatic pain detection technology could be deployed to assist human caregivers and complement their service thereby improving the quality of pain management especially for noncommunicative patients. facial expressions are a reliable indicator of pain and are used in all observer based pain assessment tools. following the advancements in automatic facial expression analysis computer vision researchers have tried to use this technology for developing approaches for automatically detecting pain from facial expressions. this paper surveys the literature published in this field over the past decade categorizes it and identifies future research directions. the survey covers the pain datasets used in the reviewed literature the learning tasks targeted by the approaches the features extracted from images and image sequences to represent pain related information and finally the machine learning methods used.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>ensemble manifold regularized multi modal graph convolutional network for cognitive ability prediction. multi modal functional magnetic resonance imaging fmri can be used to make predictions about individual behavioral and cognitive traits based on brain connectivity networks.</td>\n",
       "      <td>ensemble manifold regularized multi modal graph convolutional network for cognitive ability prediction. multi modal functional magnetic resonance imaging fmri can be used to make predictions about individual behavioral and cognitive traits based on brain connectivity networks.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39129</th>\n",
       "      <td>predicting wait times in pediatric ophthalmology outpatient clinic using machine learning. patient perceptions of wait time during outpatient office visits can affect patient satisfaction. providing accurate information about wait times could improve patients' satisfaction by reducing uncertainty. however these are rarely known about efficient ways to predict wait time in the clinic. supervised machine learning algorithms is a powerful tool for predictive modeling with large and complicated data sets. in this study we tested machine learning models to predict wait times based on secondary ehr data in pediatric ophthalmology outpatient clinic. we compared several machine learning algorithms including random forest elastic net gradient boosting machine support vector machine and multiple linear regressions to find the most accurate model for prediction. the importance of the predictors was also identified via machine learning models. in the future these models have the potential to combine with real time ehr data to provide real time accurate estimates of patient wait time outpatient clinics.</td>\n",
       "      <td>predicting wait times in pediatric ophthalmology outpatient clinic using machine learning. patient perceptions of wait time during outpatient office visits can affect patient satisfaction. providing accurate information about wait times could improve patients' satisfaction by reducing uncertainty. however these are rarely known about efficient ways to predict wait time in the clinic. supervised machine learning algorithms is a powerful tool for predictive modeling with large and complicated data sets. in this study we tested machine learning models to predict wait times based on secondary ehr data in pediatric ophthalmology outpatient clinic. we compared several machine learning algorithms including random forest elastic net gradient boosting machine support vector machine and multiple linear regressions to find the most accurate model for prediction. the importance of the predictors was also identified via machine learning models. in the future these models have the potential to combine with real time ehr data to provide real time accurate estimates of patient wait time outpatient clinics.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80095</th>\n",
       "      <td>classifying mci subtypes in community dwelling elderly using cross sectional and longitudinal mri based biomarkers. amnestic mci amci and non amnestic mci namci are considered to differ in etiology and outcome. accurately classifying mci into meaningful subtypes would enable early intervention with targeted treatment. in this study we employed structural magnetic resonance imaging mri for mci subtype classification. this was carried out in a sample of 184 community dwelling individuals aged 73 85 years . cortical surface based measurements were computed from longitudinal and cross sectional scans. by introducing a feature selection algorithm we identified a set of discriminative features and further investigated the temporal patterns of these features. a voting classifier was trained and evaluated via 10 iterations of cross validation. the best classification accuracies achieved were: 77% namci vs. amci 81% amci vs. cognitively normal cn  and 70% namci vs. cn . the best results for differentiating amci from namci were achieved with baseline features. hippocampus amygdala and frontal pole were found to be most discriminative for classifying mci subtypes. additionally we observed the dynamics of classification of several mri biomarkers. learning the dynamics of atrophy may aid in the development of better biomarkers as it may track the progression of cognitive impairment.</td>\n",
       "      <td>classifying mci subtypes in community dwelling elderly using cross sectional and longitudinal mri based biomarkers. amnestic mci amci and non amnestic mci namci are considered to differ in etiology and outcome. accurately classifying mci into meaningful subtypes would enable early intervention with targeted treatment. in this study we employed structural magnetic resonance imaging mri for mci subtype classification. this was carried out in a sample of 184 community dwelling individuals aged 73 85 years . cortical surface based measurements were computed from longitudinal and cross sectional scans. by introducing a feature selection algorithm we identified a set of discriminative features and further investigated the temporal patterns of these features. a voting classifier was trained and evaluated via 10 iterations of cross validation. the best classification accuracies achieved were: 77percent namci vs. amci 81percent amci vs. cognitively normal cn and 70percent namci vs. cn . the best results for differentiating amci from namci were achieved with baseline features. hippocampus amygdala and frontal pole were found to be most discriminative for classifying mci subtypes. additionally we observed the dynamics of classification of several mri biomarkers. learning the dynamics of atrophy may aid in the development of better biomarkers as it may track the progression of cognitive impairment.</td>\n",
       "      <td>[184, 73, 85, 10, 77%, 81%, 70%]</td>\n",
       "      <td>[184 community dwelling individuals aged, 73    , 85 years   , 10 iterations of cross validation, 77 percent namci vs , 81 percent amci vs , 70 percent namci vs ]</td>\n",
       "      <td>[sample of 184, individuals aged 73, evaluated via 10, cn and 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49860</th>\n",
       "      <td>using machine learning to predict hyperchloremia in critically ill patients. elevated serum chloride levels hyperchloremia and the administration of intravenous iv fluids with high chloride content have both been associated with increased morbidity and mortality in certain subgroups of critically ill patients such as those with sepsis. here we demonstrate this association in a general intensive care unit icu population using data from the medical information mart for intensive care iii mimic iii database and propose the use of supervised learning to predict hyperchloremia in critically ill patients. clinical variables from records of the first 24h of adult icu stays were represented as features for four predictive supervised learning classifiers. the best performing model was able to predict second day hyperchloremia with an auc of 0.80 and a ratio of 5 false alerts for every true alert which is a clinically actionable rate. our results suggest that clinicians can be effectively alerted to patients at risk of developing hyperchloremia providing an opportunity to mitigate this risk and potentially improve outcomes.</td>\n",
       "      <td>using machine learning to predict hyperchloremia in critically ill patients. elevated serum chloride levels hyperchloremia and the administration of intravenous iv fluids with high chloride content have both been associated with increased morbidity and mortality in certain subgroups of critically ill patients such as those with sepsis. here we demonstrate this association in a general intensive care unit icu population using data from the medical information mart for intensive care iii mimic iii database and propose the use of supervised learning to predict hyperchloremia in critically ill patients. clinical variables from records of the first 24h of adult icu stays were represented as features for 4 predictive supervised learning classifiers. the best performing model was able to predict second day hyperchloremia with an auc of 0.80 and a ratio of 5 false alerts for every true alert which is a clinically actionable rate. our results suggest that clinicians can be effectively alerted to patients at risk of developing hyperchloremia providing an opportunity to mitigate this risk and potentially improve outcomes.</td>\n",
       "      <td>[24, 4, 0.80, 5]</td>\n",
       "      <td>[24 h of adult icu, 4 predictive supervised learning classifiers, 0.80 and a ratio of, 5 false alerts for every]</td>\n",
       "      <td>[the first 24, features for 4, auc of 0.80, ratio of 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15281</th>\n",
       "      <td>shallow convolutional neural network for covid 19 outbreak screening using chest x rays. among radiological imaging data chest x rays cxrs are of great use in observing covid 19 manifestations. for mass screening using cxrs a computationally efficient ai driven tool is the must to detect covid 19 positive cases from non covid ones. for this purpose we proposed a light weight convolutional neural network cnn tailored shallow architecture that can automatically detect covid 19 positive cases using cxrs with no false negatives. the shallow cnn tailored architecture was designed with fewer parameters as compared to other deep learning models. the shallow cnn tailored architecture was validated using 321 covid 19 positive cxrs. in addition to covid 19 positive cases another set of non covid 19 5856 cases publicly available source: kaggle was taken into account consisting of normal viral and bacterial pneumonia cases. in our experimental tests to avoid possible bias 5 fold cross validation was followed and both balanced and imbalanced datasets were used. the proposed model achieved the highest possible accuracy of 99.69% sensitivity of 1.0 where auc was 0.9995. furthermore the reported false positive rate was only 0.0015 for 5856 covid 19 negative cases. our results stated that the proposed cnn could possibly be used for mass screening. using the exact same set of cxr collection the current results were better than other deep learning models and major state of the art works.</td>\n",
       "      <td>shallow convolutional neural network for covid 19 outbreak screening using chest x rays. among radiological imaging data chest x rays cxrs are of great use in observing covid 19 manifestations. for mass screening using cxrs a computationally efficient ai driven tool is the must to detect covid 19 positive cases from non covid ones. for this purpose we proposed a light weight convolutional neural network cnn tailored shallow architecture that can automatically detect covid 19 positive cases using cxrs with no false negatives. the shallow cnn tailored architecture was designed with fewer parameters as compared to other deep learning models. the shallow cnn tailored architecture was validated using 321 covid 19 positive cxrs. in addition to covid 19 positive cases another set of non covid 19 5856 cases publicly available source: kaggle was taken into account consisting of normal viral and bacterial pneumonia cases. in our experimental tests to avoid possible bias 5 fold cross validation was followed and both balanced and imbalanced datasets were used. the proposed model achieved the highest possible accuracy of 99.69percent sensitivity of 1.0 where auc was 0.9995. furthermore the reported false positive rate was only 0.0015 for 5856 covid 19 negative cases. our results stated that the proposed cnn could possibly be used for mass screening. using the exact same set of cxr collection the current results were better than other deep learning models and major state of the art works.</td>\n",
       "      <td>[19, 19, 19, 19, 321, 19, 19, 19, 5856, 5, 99.69, %, 1.0, 0.9995, 0.0015, 5856, 19]</td>\n",
       "      <td>[19 outbreak screening using chest, 19 manifestations   , 19 positive cases from non, 19 positive cases using cxrs, 321 covid   , 19 positive cxrs  , 19 positive cases another set, 19    , 5856 cases publicly available source, 5 fold cross validation was, 99.69 percent sensitivity of , 1.0 where auc was , 0.9995    , 0.0015 for   , 5856 covid   , 19 negative cases  ]</td>\n",
       "      <td>[for covid 19, observing covid 19, detect covid 19, detect covid 19, validated using 321, to covid 19, non covid 19, possible bias 5, accuracy of 99.69, sensitivity of 1.0, auc was 0.9995, was only 0.0015]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67163</th>\n",
       "      <td>real time cardiac arrhythmia classification using memristor neuromorphic computing system. cardiac arrhythmia is known to be one of the most common causes of death worldwide. therefore development of efficient arrhythmia detection techniques is essential to save patients' lives. in this paper we introduce a new real time cardiac arrhythmia classification using memristor neuromorphic computing system for classification of 5 different beat types. neuromorphic computing systems utilize new emerging devices such as memristors as a basic building block. hence these systems provide excellent trade off between real time processing power consumption and overall accuracy. experimental results showed that the proposed system outperforms most of the methods in comparison in terms of accuracy and testing time since it achieved 96.17% average accuracy and 34 ms average testing time per beat.</td>\n",
       "      <td>real time cardiac arrhythmia classification using memristor neuromorphic computing system. cardiac arrhythmia is known to be one of the most common causes of death worldwide. therefore development of efficient arrhythmia detection techniques is essential to save patients' lives. in this paper we introduce a new real time cardiac arrhythmia classification using memristor neuromorphic computing system for classification of 5 different beat types. neuromorphic computing systems utilize new emerging devices such as memristors as a basic building block. hence these systems provide excellent trade off between real time processing power consumption and overall accuracy. experimental results showed that the proposed system outperforms most of the methods in comparison in terms of accuracy and testing time since it achieved 96.17percent average accuracy and 34 ms average testing time per beat.</td>\n",
       "      <td>[5, 96.17, %, 34]</td>\n",
       "      <td>[5 different beat types , 96.17 percent average accuracy and, 34 ms average testing time]</td>\n",
       "      <td>[classification of 5, it achieved 96.17, accuracy and 34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121673</th>\n",
       "      <td>tumor detection from enhanced magnetic resonance imaging using fuzzy curvelet. effective medical image analysis is possible by the use of technique known as segmentation. segmentation is a very challenging task because there is not any standard segmentation method is available for any medical application. in this article we have proposed an automatic brain mr image segmentation method. fast discrete curvelet transform and spatial fuzzy c mean algorithm is used for noise removal and segmentation of brain mr image. fuzzy entropy has been used for calculating adaptive and optimal threshold to separate out the image segments. our proposed system is exclusively based on the information contained by the image itself. no extra information and no human intervention are required in our proposed system. we have tested our proposed system on different t1 t2 and pd brain mr images.</td>\n",
       "      <td>tumor detection from enhanced magnetic resonance imaging using fuzzy curvelet. effective medical image analysis is possible by the use of technique known as segmentation. segmentation is a very challenging task because there is not any standard segmentation method is available for any medical application. in this article we have proposed an automatic brain mr image segmentation method. fast discrete curvelet transform and spatial fuzzy c mean algorithm is used for noise removal and segmentation of brain mr image. fuzzy entropy has been used for calculating adaptive and optimal threshold to separate out the image segments. our proposed system is exclusively based on the information contained by the image itself. no extra information and no human intervention are required in our proposed system. we have tested our proposed system on different t1 t2 and pd brain mr images.</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24199</th>\n",
       "      <td>predicting peritoneal metastasis of gastric cancer patients based on machine learning. the aim is to explore the prediction effect of 5 machine learning algorithms on peritoneal metastasis of gastric cancer.</td>\n",
       "      <td>predicting peritoneal metastasis of gastric cancer patients based on machine learning. the aim is to explore the prediction effect of 5 machine learning algorithms on peritoneal metastasis of gastric cancer.</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[5 machine learning algorithms on]</td>\n",
       "      <td>[effect of 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50347</th>\n",
       "      <td>research on glioma magnetic resonance imaging segmentation based on dual channel three dimensional densely connected network . focus on the inconsistency of the shape location and size of brain glioma a dual channel 3 dimensional 3d densely connected network is proposed to automatically segment brain glioma tumor on magnetic resonance images. our method is based on a 3d convolutional neural network frame and two convolution kernel sizes are adopted in each channel to extract multi scale features in different scales of receptive fields. then we construct two densely connected blocks in each pathway for feature learning and transmission. finally the concatenation of two pathway features was sent to classification layer to classify central region voxels to segment brain tumor automatically. we train and test our model on open brain tumor segmentation challenge dataset and we also compared our results with other models. experimental results show that our algorithm can segment different tumor lesions more accurately. it has important application value in the clinical diagnosis and treatment of brain tumor diseases.</td>\n",
       "      <td>research on glioma magnetic resonance imaging segmentation based on dual channel 3 dimensional densely connected network . focus on the inconsistency of the shape location and size of brain glioma a dual channel 3 dimensional 3d densely connected network is proposed to automatically segment brain glioma tumor on magnetic resonance images. our method is based on a 3d convolutional neural network frame and 2 convolution kernel sizes are adopted in each channel to extract multi scale features in different scales of receptive fields. then we construct 2 densely connected blocks in each pathway for feature learning and transmission. finally the concatenation of 2 pathway features was sent to classification layer to classify central region voxels to segment brain tumor automatically. we train and test our model on open brain tumor segmentation challenge dataset and we also compared our results with other models. experimental results show that our algorithm can segment different tumor lesions more accurately. it has important application value in the clinical diagnosis and treatment of brain tumor diseases.</td>\n",
       "      <td>[3, 3, 3, 3, 2, 2, 2]</td>\n",
       "      <td>[3 dimensional densely connected network, 3 dimensional   , 3 d densely connected network, 3 d convolutional neural network, 2 convolution kernel sizes are, 2 densely connected blocks in, 2 pathway features was sent]</td>\n",
       "      <td>[dual channel 3, dual channel 3, on a 3, frame and 2, we construct 2, concatenation of 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24948</th>\n",
       "      <td>sickle cell disease diagnosis support selecting the most appropriate machine learning method: towards a general and interpretable approach for cell morphology analysis from microscopy images. in this work we propose an approach to select the classification method and features based on the state of the art with best performance for diagnostic support through peripheral blood smear images of red blood cells. in our case we used samples of patients with sickle cell disease which can be generalized for other study cases. to trust the behavior of the proposed system we also analyzed the interpretability. we pre processed and segmented microscopic images to ensure high feature quality. we applied the methods used in the literature to extract the features from blood cells and the machine learning methods to classify their morphology. next we searched for their best parameters from the resulting data in the feature extraction phase. then we found the best parameters for every classifier using randomized and grid search. for the sake of scientific progress we published parameters for each classifier the implemented code library the confusion matrices with the raw data and we used the public erythrocytesidb dataset for validation. we also defined how to select the most important features for classification to decrease the complexity and the training time and for interpretability purpose in opaque models. finally comparing the best performing classification methods with the state of the art we obtained better results even with interpretable model classifiers.</td>\n",
       "      <td>sickle cell disease diagnosis support selecting the most appropriate machine learning method: towards a general and interpretable approach for cell morphology analysis from microscopy images. in this work we propose an approach to select the classification method and features based on the state of the art with best performance for diagnostic support through peripheral blood smear images of red blood cells. in our case we used samples of patients with sickle cell disease which can be generalized for other study cases. to trust the behavior of the proposed system we also analyzed the interpretability. we pre processed and segmented microscopic images to ensure high feature quality. we applied the methods used in the literature to extract the features from blood cells and the machine learning methods to classify their morphology. next we searched for their best parameters from the resulting data in the feature extraction phase. then we found the best parameters for every classifier using randomized and grid search. for the sake of scientific progress we published parameters for each classifier the implemented code library the confusion matrices with the raw data and we used the public erythrocytesidb dataset for validation. we also defined how to select the most important features for classification to decrease the complexity and the training time and for interpretability purpose in opaque models. finally comparing the best performing classification methods with the state of the art we obtained better results even with interpretable model classifiers.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13048</th>\n",
       "      <td>an intelligent and energy efficient wireless body area network to control coronavirus outbreak. the coronaviruses are a deadly family of epidemic viruses that can spread from one individual to another very quickly infecting masses. the literature on epidemics indicates that the early diagnosis of a coronavirus infection can lead to a reduction in mortality rates. to prevent coronavirus disease 2019 covid 19 from spreading the regular identification and monitoring of infected patients are needed. in this regard wireless body area networks wbans can be used in conjunction with machine learning and the internet of things iot to identify and monitor the human body for health related information which in turn can aid in the early diagnosis of diseases. this paper proposes a novel coronavirus body area network cov ban model based on iot technology as a real time health monitoring system for the detection of the early stages of coronavirus infection using a number of wearable biosensors to examine the health status of the patient. the proposed cov ban model is tested with five machine learning based classification methods including random forest logistic regression naive bayes support vector machine and multi layer perceptron classifiers to optimize the accuracy of the diagnosis of covid 19. for the long term sustainability of the sensor devices the development of energy efficient wban is critical. to address this issue a long range lora based iot program is used to receive biosensor signals from the patient and transmit them to the cloud directly for monitoring. the experimental results indicate that the proposed model using the random forest classifier outperforms models using the other classifiers with an average accuracy of 88.6%. in addition power consumption is reduced when lora technology is used as a relay node.</td>\n",
       "      <td>an intelligent and energy efficient wireless body area network to control coronavirus outbreak. the coronaviruses are a deadly family of epidemic viruses that can spread from one individual to another very quickly infecting masses. the literature on epidemics indicates that the early diagnosis of a coronavirus infection can lead to a reduction in mortality rates. to prevent coronavirus disease 2019 covid 19 from spreading the regular identification and monitoring of infected patients are needed. in this regard wireless body area networks wbans can be used in conjunction with machine learning and the internet of things iot to identify and monitor the human body for health related information which in turn can aid in the early diagnosis of diseases. this paper proposes a novel coronavirus body area network cov ban model based on iot technology as a real time health monitoring system for the detection of the early stages of coronavirus infection using a number of wearable biosensors to examine the health status of the patient. the proposed cov ban model is tested with 5 machine learning based classification methods including random forest logistic regression naive bayes support vector machine and multi layer perceptron classifiers to optimize the accuracy of the diagnosis of covid 19. for the long term sustainability of the sensor devices the development of energy efficient wban is critical. to address this issue a long range lora based iot program is used to receive biosensor signals from the patient and transmit them to the cloud directly for monitoring. the experimental results indicate that the proposed model using the random forest classifier outperforms models using the other classifiers with an average accuracy of 88.6percent. in addition power consumption is reduced when lora technology is used as a relay node.</td>\n",
       "      <td>[2019, 19, 5, 19, 88.6, %]</td>\n",
       "      <td>[2019 covid   , 19 from spreading the regular, 5 machine learning based classification, 19    , 88.6 percent   ]</td>\n",
       "      <td>[coronavirus disease 2019, tested with 5, of covid 19, accuracy of 88.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81168</th>\n",
       "      <td>patterns of blood pressure response during intensive bp lowering and clinical events: results from the secondary prevention of small subcortical strokes trial. we applied cluster analysis to identify discrete patterns of concomitant responses of systolic sbp diastolic dbp and pulse pressure pp during intensive bp lowering; and to evaluate their clinical relevance and association with risk of mortality major vascular events mves and stroke.</td>\n",
       "      <td>patterns of blood pressure response during intensive bp lowering and clinical events: results from the secondary prevention of small subcortical strokes trial. we applied cluster analysis to identify discrete patterns of concomitant responses of systolic sbp diastolic dbp and pulse pressure pp during intensive bp lowering; and to evaluate their clinical relevance and association with risk of mortality major vascular events mves and stroke.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "132042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             diagnosis of airway obstruction or restrictive spirometric patterns by multiclass support vector machines. this paper presents the use of multiclass support vector machines svms for diagnosis of spirometric patterns normal restrictive obstructive . the svm decisions were fused using the error correcting output codes ecoc . the multiclass svm with the ecoc was trained on three spirometric parameters forced expiratory volume in 1s fev1 forced vital capacity fvc and fev1/fvc ratio . the total classification accuracy of the svm is 97.32%. the obtained results confirmed the validity of the svms to help in clinical decision making.   \n",
       "46879                                                                                                                                                                                                                                        prediction of skin disease with three different feature selection techniques using stacking ensemble method. skin disease is the most common problem between people. due to pollution and deployment of ozone layer harmful uv rays of sun burn the skin and develop various types of skin diseases. nowadays machine learning and deep learning algorithms are generally used for diagnosis for various kinds of diseases. in this study we have applied three feature extraction techniques univariate feature selection feature importance and correlation matrix with heat map to find the optimum data subset of erythemato squamous disease. four classification techniques gaussian naã¯ve bayesian nb decision tree dt support vector machine svm and random forest are used for measuring the performance of model. stacking ensemble technique is then applied to enhance the prediction performance of the model. the proposed method used for measuring the performance of the model. it is finding that the optimal subset of the erythemato squamous disease is performed well in the case of correlation and heat map feature selection techniques. the mean value slandered deviation root mean square error kappa statistical error and area under receiver operating characteristics and accuracy are calculated for demonstrating the effectiveness of the proposed model. the feature selection techniques applied with staking ensemble technique gives the better result as compared to individual machine learning techniques. the obtained results show that the performance of proposed model is higher than previous results obtained by researchers.   \n",
       "47200                                                                                                                                                                                                                                                                                                                                                                                                                                  automatic detection of pain from facial expressions: a survey. pain sensation is essential for survival since it draws attention to physical threat to the body. pain assessment is usually done through self reports. however self assessment of pain is not available in the case of noncommunicative patients and therefore observer reports should be relied upon. observer reports of pain could be prone to errors due to subjective biases of observers. moreover continuous monitoring by humans is impractical. therefore automatic pain detection technology could be deployed to assist human caregivers and complement their service thereby improving the quality of pain management especially for noncommunicative patients. facial expressions are a reliable indicator of pain and are used in all observer based pain assessment tools. following the advancements in automatic facial expression analysis computer vision researchers have tried to use this technology for developing approaches for automatically detecting pain from facial expressions. this paper surveys the literature published in this field over the past decade categorizes it and identifies future research directions. the survey covers the pain datasets used in the reviewed literature the learning tasks targeted by the approaches the features extracted from images and image sequences to represent pain related information and finally the machine learning methods used.   \n",
       "7013                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ensemble manifold regularized multi modal graph convolutional network for cognitive ability prediction. multi modal functional magnetic resonance imaging fmri can be used to make predictions about individual behavioral and cognitive traits based on brain connectivity networks.   \n",
       "39129                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    predicting wait times in pediatric ophthalmology outpatient clinic using machine learning. patient perceptions of wait time during outpatient office visits can affect patient satisfaction. providing accurate information about wait times could improve patients' satisfaction by reducing uncertainty. however these are rarely known about efficient ways to predict wait time in the clinic. supervised machine learning algorithms is a powerful tool for predictive modeling with large and complicated data sets. in this study we tested machine learning models to predict wait times based on secondary ehr data in pediatric ophthalmology outpatient clinic. we compared several machine learning algorithms including random forest elastic net gradient boosting machine support vector machine and multiple linear regressions to find the most accurate model for prediction. the importance of the predictors was also identified via machine learning models. in the future these models have the potential to combine with real time ehr data to provide real time accurate estimates of patient wait time outpatient clinics.   \n",
       "80095                                                                                                                                                                                                                                                                                                                                                                                                                                                                       classifying mci subtypes in community dwelling elderly using cross sectional and longitudinal mri based biomarkers. amnestic mci amci and non amnestic mci namci are considered to differ in etiology and outcome. accurately classifying mci into meaningful subtypes would enable early intervention with targeted treatment. in this study we employed structural magnetic resonance imaging mri for mci subtype classification. this was carried out in a sample of 184 community dwelling individuals aged 73 85 years . cortical surface based measurements were computed from longitudinal and cross sectional scans. by introducing a feature selection algorithm we identified a set of discriminative features and further investigated the temporal patterns of these features. a voting classifier was trained and evaluated via 10 iterations of cross validation. the best classification accuracies achieved were: 77% namci vs. amci 81% amci vs. cognitively normal cn  and 70% namci vs. cn . the best results for differentiating amci from namci were achieved with baseline features. hippocampus amygdala and frontal pole were found to be most discriminative for classifying mci subtypes. additionally we observed the dynamics of classification of several mri biomarkers. learning the dynamics of atrophy may aid in the development of better biomarkers as it may track the progression of cognitive impairment.   \n",
       "49860                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            using machine learning to predict hyperchloremia in critically ill patients. elevated serum chloride levels hyperchloremia and the administration of intravenous iv fluids with high chloride content have both been associated with increased morbidity and mortality in certain subgroups of critically ill patients such as those with sepsis. here we demonstrate this association in a general intensive care unit icu population using data from the medical information mart for intensive care iii mimic iii database and propose the use of supervised learning to predict hyperchloremia in critically ill patients. clinical variables from records of the first 24h of adult icu stays were represented as features for four predictive supervised learning classifiers. the best performing model was able to predict second day hyperchloremia with an auc of 0.80 and a ratio of 5 false alerts for every true alert which is a clinically actionable rate. our results suggest that clinicians can be effectively alerted to patients at risk of developing hyperchloremia providing an opportunity to mitigate this risk and potentially improve outcomes.   \n",
       "15281                                                                                                                                                                                                                                                                                                                                                                  shallow convolutional neural network for covid 19 outbreak screening using chest x rays. among radiological imaging data chest x rays cxrs are of great use in observing covid 19 manifestations. for mass screening using cxrs a computationally efficient ai driven tool is the must to detect covid 19 positive cases from non covid ones. for this purpose we proposed a light weight convolutional neural network cnn tailored shallow architecture that can automatically detect covid 19 positive cases using cxrs with no false negatives. the shallow cnn tailored architecture was designed with fewer parameters as compared to other deep learning models. the shallow cnn tailored architecture was validated using 321 covid 19 positive cxrs. in addition to covid 19 positive cases another set of non covid 19 5856 cases publicly available source: kaggle was taken into account consisting of normal viral and bacterial pneumonia cases. in our experimental tests to avoid possible bias 5 fold cross validation was followed and both balanced and imbalanced datasets were used. the proposed model achieved the highest possible accuracy of 99.69% sensitivity of 1.0 where auc was 0.9995. furthermore the reported false positive rate was only 0.0015 for 5856 covid 19 negative cases. our results stated that the proposed cnn could possibly be used for mass screening. using the exact same set of cxr collection the current results were better than other deep learning models and major state of the art works.   \n",
       "67163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            real time cardiac arrhythmia classification using memristor neuromorphic computing system. cardiac arrhythmia is known to be one of the most common causes of death worldwide. therefore development of efficient arrhythmia detection techniques is essential to save patients' lives. in this paper we introduce a new real time cardiac arrhythmia classification using memristor neuromorphic computing system for classification of 5 different beat types. neuromorphic computing systems utilize new emerging devices such as memristors as a basic building block. hence these systems provide excellent trade off between real time processing power consumption and overall accuracy. experimental results showed that the proposed system outperforms most of the methods in comparison in terms of accuracy and testing time since it achieved 96.17% average accuracy and 34 ms average testing time per beat.   \n",
       "121673                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    tumor detection from enhanced magnetic resonance imaging using fuzzy curvelet. effective medical image analysis is possible by the use of technique known as segmentation. segmentation is a very challenging task because there is not any standard segmentation method is available for any medical application. in this article we have proposed an automatic brain mr image segmentation method. fast discrete curvelet transform and spatial fuzzy c mean algorithm is used for noise removal and segmentation of brain mr image. fuzzy entropy has been used for calculating adaptive and optimal threshold to separate out the image segments. our proposed system is exclusively based on the information contained by the image itself. no extra information and no human intervention are required in our proposed system. we have tested our proposed system on different t1 t2 and pd brain mr images.   \n",
       "24199                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        predicting peritoneal metastasis of gastric cancer patients based on machine learning. the aim is to explore the prediction effect of 5 machine learning algorithms on peritoneal metastasis of gastric cancer.   \n",
       "50347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                research on glioma magnetic resonance imaging segmentation based on dual channel three dimensional densely connected network . focus on the inconsistency of the shape location and size of brain glioma a dual channel 3 dimensional 3d densely connected network is proposed to automatically segment brain glioma tumor on magnetic resonance images. our method is based on a 3d convolutional neural network frame and two convolution kernel sizes are adopted in each channel to extract multi scale features in different scales of receptive fields. then we construct two densely connected blocks in each pathway for feature learning and transmission. finally the concatenation of two pathway features was sent to classification layer to classify central region voxels to segment brain tumor automatically. we train and test our model on open brain tumor segmentation challenge dataset and we also compared our results with other models. experimental results show that our algorithm can segment different tumor lesions more accurately. it has important application value in the clinical diagnosis and treatment of brain tumor diseases.   \n",
       "24948                                                                                                                                                                                                                                                                                 sickle cell disease diagnosis support selecting the most appropriate machine learning method: towards a general and interpretable approach for cell morphology analysis from microscopy images. in this work we propose an approach to select the classification method and features based on the state of the art with best performance for diagnostic support through peripheral blood smear images of red blood cells. in our case we used samples of patients with sickle cell disease which can be generalized for other study cases. to trust the behavior of the proposed system we also analyzed the interpretability. we pre processed and segmented microscopic images to ensure high feature quality. we applied the methods used in the literature to extract the features from blood cells and the machine learning methods to classify their morphology. next we searched for their best parameters from the resulting data in the feature extraction phase. then we found the best parameters for every classifier using randomized and grid search. for the sake of scientific progress we published parameters for each classifier the implemented code library the confusion matrices with the raw data and we used the public erythrocytesidb dataset for validation. we also defined how to select the most important features for classification to decrease the complexity and the training time and for interpretability purpose in opaque models. finally comparing the best performing classification methods with the state of the art we obtained better results even with interpretable model classifiers.   \n",
       "13048   an intelligent and energy efficient wireless body area network to control coronavirus outbreak. the coronaviruses are a deadly family of epidemic viruses that can spread from one individual to another very quickly infecting masses. the literature on epidemics indicates that the early diagnosis of a coronavirus infection can lead to a reduction in mortality rates. to prevent coronavirus disease 2019 covid 19 from spreading the regular identification and monitoring of infected patients are needed. in this regard wireless body area networks wbans can be used in conjunction with machine learning and the internet of things iot to identify and monitor the human body for health related information which in turn can aid in the early diagnosis of diseases. this paper proposes a novel coronavirus body area network cov ban model based on iot technology as a real time health monitoring system for the detection of the early stages of coronavirus infection using a number of wearable biosensors to examine the health status of the patient. the proposed cov ban model is tested with five machine learning based classification methods including random forest logistic regression naive bayes support vector machine and multi layer perceptron classifiers to optimize the accuracy of the diagnosis of covid 19. for the long term sustainability of the sensor devices the development of energy efficient wban is critical. to address this issue a long range lora based iot program is used to receive biosensor signals from the patient and transmit them to the cloud directly for monitoring. the experimental results indicate that the proposed model using the random forest classifier outperforms models using the other classifiers with an average accuracy of 88.6%. in addition power consumption is reduced when lora technology is used as a relay node.   \n",
       "81168                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            patterns of blood pressure response during intensive bp lowering and clinical events: results from the secondary prevention of small subcortical strokes trial. we applied cluster analysis to identify discrete patterns of concomitant responses of systolic sbp diastolic dbp and pulse pressure pp during intensive bp lowering; and to evaluate their clinical relevance and association with risk of mortality major vascular events mves and stroke.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            a2d  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "132042                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              diagnosis of airway obstruction or restrictive spirometric patterns by multiclass support vector machines. this paper presents the use of multiclass support vector machines svms for diagnosis of spirometric patterns normal restrictive obstructive . the svm decisions were fused using the error correcting output codes ecoc . the multiclass svm with the ecoc was trained on 3 spirometric parameters forced expiratory volume in 1s fev1 forced vital capacity fvc and fev1/fvc ratio . the total classification accuracy of the svm is 97.32percent. the obtained results confirmed the validity of the svms to help in clinical decision making.   \n",
       "46879                                                                                                                                                                                                                                                      prediction of skin disease with 3 different feature selection techniques using stacking ensemble method. skin disease is the most common problem between people. due to pollution and deployment of ozone layer harmful uv rays of sun burn the skin and develop various types of skin diseases. nowadays machine learning and deep learning algorithms are generally used for diagnosis for various kinds of diseases. in this study we have applied 3 feature extraction techniques univariate feature selection feature importance and correlation matrix with heat map to find the optimum data subset of erythemato squamous disease. 4 classification techniques gaussian naã¯ve bayesian nb decision tree dt support vector machine svm and random forest are used for measuring the performance of model. stacking ensemble technique is then applied to enhance the prediction performance of the model. the proposed method used for measuring the performance of the model. it is finding that the optimal subset of the erythemato squamous disease is performed well in the case of correlation and heat map feature selection techniques. the mean value slandered deviation root mean square error kappa statistical error and area under receiver operating characteristics and accuracy are calculated for demonstrating the effectiveness of the proposed model. the feature selection techniques applied with staking ensemble technique gives the better result as compared to individual machine learning techniques. the obtained results show that the performance of proposed model is higher than previous results obtained by researchers.   \n",
       "47200                                                                                                                                                                                                                                                                                                                                                                                                                                     automatic detection of pain from facial expressions: a survey. pain sensation is essential for survival since it draws attention to physical threat to the body. pain assessment is usually done through self reports. however self assessment of pain is not available in the case of noncommunicative patients and therefore observer reports should be relied upon. observer reports of pain could be prone to errors due to subjective biases of observers. moreover continuous monitoring by humans is impractical. therefore automatic pain detection technology could be deployed to assist human caregivers and complement their service thereby improving the quality of pain management especially for noncommunicative patients. facial expressions are a reliable indicator of pain and are used in all observer based pain assessment tools. following the advancements in automatic facial expression analysis computer vision researchers have tried to use this technology for developing approaches for automatically detecting pain from facial expressions. this paper surveys the literature published in this field over the past decade categorizes it and identifies future research directions. the survey covers the pain datasets used in the reviewed literature the learning tasks targeted by the approaches the features extracted from images and image sequences to represent pain related information and finally the machine learning methods used.   \n",
       "7013                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ensemble manifold regularized multi modal graph convolutional network for cognitive ability prediction. multi modal functional magnetic resonance imaging fmri can be used to make predictions about individual behavioral and cognitive traits based on brain connectivity networks.   \n",
       "39129                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       predicting wait times in pediatric ophthalmology outpatient clinic using machine learning. patient perceptions of wait time during outpatient office visits can affect patient satisfaction. providing accurate information about wait times could improve patients' satisfaction by reducing uncertainty. however these are rarely known about efficient ways to predict wait time in the clinic. supervised machine learning algorithms is a powerful tool for predictive modeling with large and complicated data sets. in this study we tested machine learning models to predict wait times based on secondary ehr data in pediatric ophthalmology outpatient clinic. we compared several machine learning algorithms including random forest elastic net gradient boosting machine support vector machine and multiple linear regressions to find the most accurate model for prediction. the importance of the predictors was also identified via machine learning models. in the future these models have the potential to combine with real time ehr data to provide real time accurate estimates of patient wait time outpatient clinics.   \n",
       "80095                                                                                                                                                                                                                                                                                                                                                                                                                                                         classifying mci subtypes in community dwelling elderly using cross sectional and longitudinal mri based biomarkers. amnestic mci amci and non amnestic mci namci are considered to differ in etiology and outcome. accurately classifying mci into meaningful subtypes would enable early intervention with targeted treatment. in this study we employed structural magnetic resonance imaging mri for mci subtype classification. this was carried out in a sample of 184 community dwelling individuals aged 73 85 years . cortical surface based measurements were computed from longitudinal and cross sectional scans. by introducing a feature selection algorithm we identified a set of discriminative features and further investigated the temporal patterns of these features. a voting classifier was trained and evaluated via 10 iterations of cross validation. the best classification accuracies achieved were: 77percent namci vs. amci 81percent amci vs. cognitively normal cn and 70percent namci vs. cn . the best results for differentiating amci from namci were achieved with baseline features. hippocampus amygdala and frontal pole were found to be most discriminative for classifying mci subtypes. additionally we observed the dynamics of classification of several mri biomarkers. learning the dynamics of atrophy may aid in the development of better biomarkers as it may track the progression of cognitive impairment.   \n",
       "49860                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  using machine learning to predict hyperchloremia in critically ill patients. elevated serum chloride levels hyperchloremia and the administration of intravenous iv fluids with high chloride content have both been associated with increased morbidity and mortality in certain subgroups of critically ill patients such as those with sepsis. here we demonstrate this association in a general intensive care unit icu population using data from the medical information mart for intensive care iii mimic iii database and propose the use of supervised learning to predict hyperchloremia in critically ill patients. clinical variables from records of the first 24h of adult icu stays were represented as features for 4 predictive supervised learning classifiers. the best performing model was able to predict second day hyperchloremia with an auc of 0.80 and a ratio of 5 false alerts for every true alert which is a clinically actionable rate. our results suggest that clinicians can be effectively alerted to patients at risk of developing hyperchloremia providing an opportunity to mitigate this risk and potentially improve outcomes.   \n",
       "15281                                                                                                                                                                                                                                                                                                                                                               shallow convolutional neural network for covid 19 outbreak screening using chest x rays. among radiological imaging data chest x rays cxrs are of great use in observing covid 19 manifestations. for mass screening using cxrs a computationally efficient ai driven tool is the must to detect covid 19 positive cases from non covid ones. for this purpose we proposed a light weight convolutional neural network cnn tailored shallow architecture that can automatically detect covid 19 positive cases using cxrs with no false negatives. the shallow cnn tailored architecture was designed with fewer parameters as compared to other deep learning models. the shallow cnn tailored architecture was validated using 321 covid 19 positive cxrs. in addition to covid 19 positive cases another set of non covid 19 5856 cases publicly available source: kaggle was taken into account consisting of normal viral and bacterial pneumonia cases. in our experimental tests to avoid possible bias 5 fold cross validation was followed and both balanced and imbalanced datasets were used. the proposed model achieved the highest possible accuracy of 99.69percent sensitivity of 1.0 where auc was 0.9995. furthermore the reported false positive rate was only 0.0015 for 5856 covid 19 negative cases. our results stated that the proposed cnn could possibly be used for mass screening. using the exact same set of cxr collection the current results were better than other deep learning models and major state of the art works.   \n",
       "67163                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         real time cardiac arrhythmia classification using memristor neuromorphic computing system. cardiac arrhythmia is known to be one of the most common causes of death worldwide. therefore development of efficient arrhythmia detection techniques is essential to save patients' lives. in this paper we introduce a new real time cardiac arrhythmia classification using memristor neuromorphic computing system for classification of 5 different beat types. neuromorphic computing systems utilize new emerging devices such as memristors as a basic building block. hence these systems provide excellent trade off between real time processing power consumption and overall accuracy. experimental results showed that the proposed system outperforms most of the methods in comparison in terms of accuracy and testing time since it achieved 96.17percent average accuracy and 34 ms average testing time per beat.   \n",
       "121673                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       tumor detection from enhanced magnetic resonance imaging using fuzzy curvelet. effective medical image analysis is possible by the use of technique known as segmentation. segmentation is a very challenging task because there is not any standard segmentation method is available for any medical application. in this article we have proposed an automatic brain mr image segmentation method. fast discrete curvelet transform and spatial fuzzy c mean algorithm is used for noise removal and segmentation of brain mr image. fuzzy entropy has been used for calculating adaptive and optimal threshold to separate out the image segments. our proposed system is exclusively based on the information contained by the image itself. no extra information and no human intervention are required in our proposed system. we have tested our proposed system on different t1 t2 and pd brain mr images.   \n",
       "24199                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           predicting peritoneal metastasis of gastric cancer patients based on machine learning. the aim is to explore the prediction effect of 5 machine learning algorithms on peritoneal metastasis of gastric cancer.   \n",
       "50347                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             research on glioma magnetic resonance imaging segmentation based on dual channel 3 dimensional densely connected network . focus on the inconsistency of the shape location and size of brain glioma a dual channel 3 dimensional 3d densely connected network is proposed to automatically segment brain glioma tumor on magnetic resonance images. our method is based on a 3d convolutional neural network frame and 2 convolution kernel sizes are adopted in each channel to extract multi scale features in different scales of receptive fields. then we construct 2 densely connected blocks in each pathway for feature learning and transmission. finally the concatenation of 2 pathway features was sent to classification layer to classify central region voxels to segment brain tumor automatically. we train and test our model on open brain tumor segmentation challenge dataset and we also compared our results with other models. experimental results show that our algorithm can segment different tumor lesions more accurately. it has important application value in the clinical diagnosis and treatment of brain tumor diseases.   \n",
       "24948                                                                                                                                                                                                                                                                                    sickle cell disease diagnosis support selecting the most appropriate machine learning method: towards a general and interpretable approach for cell morphology analysis from microscopy images. in this work we propose an approach to select the classification method and features based on the state of the art with best performance for diagnostic support through peripheral blood smear images of red blood cells. in our case we used samples of patients with sickle cell disease which can be generalized for other study cases. to trust the behavior of the proposed system we also analyzed the interpretability. we pre processed and segmented microscopic images to ensure high feature quality. we applied the methods used in the literature to extract the features from blood cells and the machine learning methods to classify their morphology. next we searched for their best parameters from the resulting data in the feature extraction phase. then we found the best parameters for every classifier using randomized and grid search. for the sake of scientific progress we published parameters for each classifier the implemented code library the confusion matrices with the raw data and we used the public erythrocytesidb dataset for validation. we also defined how to select the most important features for classification to decrease the complexity and the training time and for interpretability purpose in opaque models. finally comparing the best performing classification methods with the state of the art we obtained better results even with interpretable model classifiers.   \n",
       "13048   an intelligent and energy efficient wireless body area network to control coronavirus outbreak. the coronaviruses are a deadly family of epidemic viruses that can spread from one individual to another very quickly infecting masses. the literature on epidemics indicates that the early diagnosis of a coronavirus infection can lead to a reduction in mortality rates. to prevent coronavirus disease 2019 covid 19 from spreading the regular identification and monitoring of infected patients are needed. in this regard wireless body area networks wbans can be used in conjunction with machine learning and the internet of things iot to identify and monitor the human body for health related information which in turn can aid in the early diagnosis of diseases. this paper proposes a novel coronavirus body area network cov ban model based on iot technology as a real time health monitoring system for the detection of the early stages of coronavirus infection using a number of wearable biosensors to examine the health status of the patient. the proposed cov ban model is tested with 5 machine learning based classification methods including random forest logistic regression naive bayes support vector machine and multi layer perceptron classifiers to optimize the accuracy of the diagnosis of covid 19. for the long term sustainability of the sensor devices the development of energy efficient wban is critical. to address this issue a long range lora based iot program is used to receive biosensor signals from the patient and transmit them to the cloud directly for monitoring. the experimental results indicate that the proposed model using the random forest classifier outperforms models using the other classifiers with an average accuracy of 88.6percent. in addition power consumption is reduced when lora technology is used as a relay node.   \n",
       "81168                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               patterns of blood pressure response during intensive bp lowering and clinical events: results from the secondary prevention of small subcortical strokes trial. we applied cluster analysis to identify discrete patterns of concomitant responses of systolic sbp diastolic dbp and pulse pressure pp during intensive bp lowering; and to evaluate their clinical relevance and association with risk of mortality major vascular events mves and stroke.   \n",
       "\n",
       "                                                                                        num  \\\n",
       "index                                                                                         \n",
       "132042                                                               [3, 1, 1, 1, 97.32, %]   \n",
       "46879                                                                             [3, 3, 4]   \n",
       "47200                                                                                    []   \n",
       "7013                                                                                     []   \n",
       "39129                                                                                    []   \n",
       "80095                                                      [184, 73, 85, 10, 77%, 81%, 70%]   \n",
       "49860                                                                      [24, 4, 0.80, 5]   \n",
       "15281   [19, 19, 19, 19, 321, 19, 19, 19, 5856, 5, 99.69, %, 1.0, 0.9995, 0.0015, 5856, 19]   \n",
       "67163                                                                     [5, 96.17, %, 34]   \n",
       "121673                                                                               [1, 2]   \n",
       "24199                                                                                   [5]   \n",
       "50347                                                                 [3, 3, 3, 3, 2, 2, 2]   \n",
       "24948                                                                                    []   \n",
       "13048                                                            [2019, 19, 5, 19, 88.6, %]   \n",
       "81168                                                                                    []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                 num_plus  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "132042                                                                                                                                                                                                                                                                                                          [3 spirometric parameters forced expiratory, 1 s fev  , 97.32 percent   ]   \n",
       "46879                                                                                                                                                                                                                                                     [3 different feature selection techniques, 3 feature extraction techniques univariate, 4 classification techniques gaussian na]   \n",
       "47200                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "7013                                                                                                                                                                                                                                                                                                                                                                                   []   \n",
       "39129                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "80095                                                                                                                                                                                                                  [184 community dwelling individuals aged, 73    , 85 years   , 10 iterations of cross validation, 77 percent namci vs , 81 percent amci vs , 70 percent namci vs ]   \n",
       "49860                                                                                                                                                                                                                                                                    [24 h of adult icu, 4 predictive supervised learning classifiers, 0.80 and a ratio of, 5 false alerts for every]   \n",
       "15281   [19 outbreak screening using chest, 19 manifestations   , 19 positive cases from non, 19 positive cases using cxrs, 321 covid   , 19 positive cxrs  , 19 positive cases another set, 19    , 5856 cases publicly available source, 5 fold cross validation was, 99.69 percent sensitivity of , 1.0 where auc was , 0.9995    , 0.0015 for   , 5856 covid   , 19 negative cases  ]   \n",
       "67163                                                                                                                                                                                                                                                                                           [5 different beat types , 96.17 percent average accuracy and, 34 ms average testing time]   \n",
       "121673                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "24199                                                                                                                                                                                                                                                                                                                                                  [5 machine learning algorithms on]   \n",
       "50347                                                                                                                                                            [3 dimensional densely connected network, 3 dimensional   , 3 d densely connected network, 3 d convolutional neural network, 2 convolution kernel sizes are, 2 densely connected blocks in, 2 pathway features was sent]   \n",
       "24948                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "13048                                                                                                                                                                                                                                                                    [2019 covid   , 19 from spreading the regular, 5 machine learning based classification, 19    , 88.6 percent   ]   \n",
       "81168                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "\n",
       "                                                                                                                                                                                                            num_minus  \n",
       "index                                                                                                                                                                                                                  \n",
       "132042                                                                                                                                                                      [trained on 3, volume in 1, svm is 97.32]  \n",
       "46879                                                                                                                                                                                [disease with 3, have applied 3]  \n",
       "47200                                                                                                                                                                                                              []  \n",
       "7013                                                                                                                                                                                                               []  \n",
       "39129                                                                                                                                                                                                              []  \n",
       "80095                                                                                                                                               [sample of 184, individuals aged 73, evaluated via 10, cn and 70]  \n",
       "49860                                                                                                                                                         [the first 24, features for 4, auc of 0.80, ratio of 5]  \n",
       "15281   [for covid 19, observing covid 19, detect covid 19, detect covid 19, validated using 321, to covid 19, non covid 19, possible bias 5, accuracy of 99.69, sensitivity of 1.0, auc was 0.9995, was only 0.0015]  \n",
       "67163                                                                                                                                                       [classification of 5, it achieved 96.17, accuracy and 34]  \n",
       "121673                                                                                                                                                                                                             []  \n",
       "24199                                                                                                                                                                                                   [effect of 5]  \n",
       "50347                                                                                                                       [dual channel 3, dual channel 3, on a 3, frame and 2, we construct 2, concatenation of 2]  \n",
       "24948                                                                                                                                                                                                              []  \n",
       "13048                                                                                                                                        [coronavirus disease 2019, tested with 5, of covid 19, accuracy of 88.6]  \n",
       "81168                                                                                                                                                                                                              []  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df1786d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_text['merged'] = (all_text['num'] + all_text['num_plus'] + all_text['num_minus']).map(set).map(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f3529",
   "metadata": {},
   "source": [
    "## Info Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ddc16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelleddf = all_text[['text', 'num_plus', 'num_minus']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d249a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_plus</th>\n",
       "      <th>num_minus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160742</th>\n",
       "      <td>application of artificial neural networks for quantitative analysis of image data in chest radiographs for detection of interstitial lung disease. the authors have developed an automated computeraided diagnostic cad scheme by using artificial neural networks anns on quantitative analysis of image data. three separate anns were applied for detection of interstitial disease on digitized chest images. the first ann was trained with horizontal profiles in regions of interest rois selected from normal and abnormal chest radiographs for distinguishing between normal and abnormal patterns. for training and testing of the second ann the vertical output patterns obtained from the 1st ann were used for each roi. the output value of the second ann was used to distinguish between normal and abnormal rois with interstitial infiltrates. if the ratio of the number of abnormal rois to the total number of all rois in a chest image was greater than a specified threshold level the image was classified as abnormal. in addition the third ann was applied to distinguish between normal and abnormal chest images. the combination of the rule-based method and the third ann also was applied to the classification between normal and abnormal chest images. the performance of the anns was evaluated by means of receiver operating characteristic roc analysis. the average az value area under the roc curve for distinguishing between normal and abnormal cases was 0.976 /- 0.012 for 100 chest radiographs that were not used in training of anns. the results indicate that the ann trained with image data can learn some statistical properties associated with interstitial infiltrates in chest radiographs.</td>\n",
       "      <td>[3 separate anns were applied, 1 st ann were used, 0.976    , 0.012 for   , 100 chest radiographs that were]</td>\n",
       "      <td>[from the 1, cases was 0.976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>deep learning to automate the labelling of head mri datasets for computer vision applications. the purpose of this study was to build a deep learning model to derive labels from neuroradiology reports and assign these to the corresponding examinations overcoming a bottleneck to computer vision model development.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71415</th>\n",
       "      <td>automation of detection of cervical cancer using convolutional neural networks. classification of digital cervical images acquired during visual inspection with acetic acid via is an important step in automated image-based cervical cancer detection. many algorithms have been developed for classification of cervical images based on extracting mathematical features and classifying these images. deciding the suitability of a feature and learning the algorithm is a complex task. on the other hand convolutional neural networks cnns self-learn most suitable hierarchical features from the raw input image. in this paper we demonstrate the feasibility of using a shallow layer cnn for classification of image patches of cervical images as cancerous or not cancerous. we used cervix images acquired after the application of 3%-5% acetic acid using an android device in 102 women. of these 42 cervix images belonged in the via-positive category pathologic and 60 in the via-negative category healthy controls . a total of 275 image patches of 15 ã— 15 pixels were manually extracted from via-positive areas and we considered these patches as positive examples. similarly 409 image patches were extracted from via-negative areas and were labeled as via negative. these image patches were classified using a shallow layer cnn composed of a layer each of convolutional rectified linear unit pooling and two fully connected layers. a classification accuracy of 100% is achieved using shallow cnn.</td>\n",
       "      <td>[3 percent   , 102 women   , 42 cervix images belonged in, 60 in the via , 275 image patches of , 15    , 15 pixels were manually extracted, 409 image patches were extracted, 2 fully connected layers , 100 percent is achieved using]</td>\n",
       "      <td>[application of 3, device in 102, of these 42, pathologic and 60, total of 275, patches of 15, pooling and 2, accuracy of 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30756</th>\n",
       "      <td>using wearable sensors and machine learning to automatically detect freezing of gait during a fog-provoking test. freezing of gait fog is a debilitating motor phenomenon that is common among individuals with advanced parkinson's disease. objective and sensitive measures are needed to better quantify fog. the present work addresses this need by leveraging wearable devices and machine-learning methods to develop and evaluate automated detection of fog and quantification of its severity. seventy-one subjects with fog completed a fog-provoking test while wearing three wearable sensors lower back and each ankle . subjects were videotaped before off state and after on state they took their antiparkinsonian medications. annotations of the videos provided the \"ground-truth\" for fog detection. a leave-one-patient-out validation process with a training set of 57 subjects resulted in 84.1% sensitivity 83.4% specificity and 85.0% accuracy for fog detection. similar results were seen in an independent test set data from 14 other subjects . two derived outcomes percent time frozen and number of fog episodes were associated with self-report of fog. bother derived-metrics were higher in the off state than in the on state and in the most challenging level of the fog-provoking test compared to the least challenging level. these results suggest that this automated machine-learning approach can objectively assess fog and that its outcomes are responsive to therapeutic interventions.</td>\n",
       "      <td>[71 subjects with fog completed, 3 wearable sensors lower back, 57 subjects resulted in , 84.1 percent sensitivity  , 83.4 percent specificity and , 85.0 percent accuracy for fog, 14 other subjects  , 2 derived outcomes percent time]</td>\n",
       "      <td>[while wearing 3, set of 57, resulted in 84.1, specificity and 85.0, data from 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61157</th>\n",
       "      <td>ct-based machine learning model to predict the fuhrman nuclear grade of clear cell renal cell carcinoma. to predict the fuhrman grade of clear cell renal cell carcinoma ccrcc with a machine learning classifier based on single- or three-phase computed tomography ct images.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36530</th>\n",
       "      <td>acoustic analysis and detection of pharyngeal fricative in cleft palate speech using correlation of signals in independent frequency bands and octave spectrum prominent peak. pharyngeal fricative is one typical compensatory articulation error of cleft palate speech. it passively influences daily communication for people who suffer from it. the automatic detection of pharyngeal fricatives in cleft palate speech can provide information for clinical doctors and speech-language pathologists to aid in diagnosis.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52089</th>\n",
       "      <td>using supervised learning machine algorithm to identify future fallers based on gait patterns: a two-year longitudinal study. given their major health consequences in the elderly identifying people at risk of fall is a major challenge faced by clinicians. a lot of studies have confirmed the relationships between gait parameters and falls incidence. however accurate tools to predict individual risk among independent older adults without a history of falls are lacking.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28713</th>\n",
       "      <td>machine-learning analysis of voice samples recorded through smartphones: the combined effect of ageing and gender. experimental studies using qualitative or quantitative analysis have demonstrated that the human voice progressively worsens with ageing. these studies however have mostly focused on specific voice features without examining their dynamic interaction. to examine the complexity of age-related changes in voice more advanced techniques based on machine learning have been recently applied to voice recordings but only in a laboratory setting. we here recorded voice samples in a large sample of healthy subjects. to improve the ecological value of our analysis we collected voice samples directly at home using smartphones.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16458</th>\n",
       "      <td>the challenge of predicting blood glucose concentration changes in patients with type i diabetes. patients with type i diabetes t1d must take insulin injections to prevent the serious long term effects of hyperglycemia. they must also be careful not to inject too much insulin because this could induce potentially fatal hypoglycemia. patients therefore follow a \"regimen\" that determines how much insulin to inject at each time based on various measurements. we can produce an effective regimen if we can accurately predict a patient's future blood glucose bg values from his/her current features. this study explores the challenges of predicting future bg by applying a number of machine learning algorithms as well as various data preprocessing variations corresponding to 312 [learner preprocessed-dataset] combinations to a new t1d dataset that contains 29601 entries from 47 different patients. our most accurate predictor a weighted ensemble of two gaussian process regression models achieved a cross-validation &lt;math xmlns=\"http://www.w3.org/1998/math/mathml\"&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt; loss of 2.7mmol/l 48.65mg/dl . this result was unexpectedly poor given that one can obtain an &lt;math xmlns=\"http://www.w3.org/1998/math/mathml\"&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;msub&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;/math&gt; of 2.9mmol/l 52.43mg/dl using the naive approach of simply predicting the patient's average bg. these results suggest that the diabetes diary data that is typically collected may be insufficient to produce accurate bg prediction models; additional data may be necessary to build accurate bg prediction models over hours.</td>\n",
       "      <td>[312    , 29601 entries from  , 47 different patients  , 2 gaussian process regression models, 2.7 mmol   , 48.65 mg   , 2.9 mmol   , 52.43 mg   ]</td>\n",
       "      <td>[corresponding to 312, that contains 29601, entries from 47, ensemble of 2, loss of 2.7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126594</th>\n",
       "      <td>simultaneous and proportional force estimation for multifunction myoelectric prostheses using mirrored bilateral training. this study presents a novel method for associating features of the surface electromyogram emg recorded from one upper limb to the force produced by the contralateral limb. bilateral-mirrored contractions from ten able-bodied subjects were recorded along with isometric forces in multiple degrees of freedom dof from the right wrist. an artificial neural network was trained to provide force estimation. combinations of processing parameters were evaluated and an estimation algorithm allowing high accuracy from relatively short signal epochs 100 ms was proposed. the estimation performance when using surface emg from the contralateral limb was 0.90 ± 0.02 for the able-bodied subjects. in comparison the estimation performance for one subject with congenital malformation of the left forearm was 0.72 which albeit lower than for able-bodied subjects is still comparable to or better than previously reported results. the proposed method requires only the measured forces from one limb such as in the case of unilateral amputees and has thus the potential to be used in clinical settings for intuitive simultaneous control of multiple dofs in myoelectric prostheses.</td>\n",
       "      <td>[10 able   , 100 ms was proposed , 0.90    , 0.02 for the able , 0.72 which albeit lower than]</td>\n",
       "      <td>[contractions from 10, signal epochs 100, limb was 0.90, forearm was 0.72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149882</th>\n",
       "      <td>a method for detection of alzheimer's disease using ica-enhanced eeg measurements. many researchers have studied automatic eeg classification and recently a lot of work has been done on artefact-removal from eeg data using independent component analyses ica . however demonstrating that a ica-processed multichannel eeg measurement becomes more interpretable compared to the raw data as is usually done in work on ica-processing of eeg data does not yet prove that detection of incipient anomalies is also better possible after ica-processing. the objective of this study is to show that ica-preprocessing is useful when constructing a detection system for alzheimer's disease.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123313</th>\n",
       "      <td>automatic evaluation of pressure sore status by combining information obtained from high-frequency ultrasound and digital photography. in this study the different phases of pressure sore generation and healing are investigated through a combined analysis of high-frequency ultrasound 20 mhz images and digital color photographs. pressure sores were artificially induced in guinea pigs and the injured regions were monitored for 21 days data were obtained on days 3 7 14 and 21 . several statistical features of the images were extracted relating to both the altering pattern of tissue and its superficial appearance. the features were grouped into five independent categories and each category was used to train a neural network whose outputs were the four days. the outputs of the five classifiers were then fused using a fuzzy integral to provide the final decision. we demonstrate that the suggested method provides a better decision regarding tissue status than using either imaging technique separately. this new approach may be a viable tool for detecting the phases of pressure sore generation and healing in clinical settings.</td>\n",
       "      <td>[20 mhz images and digital, 21 days data were obtained, 3    , 7    , 14 and   , 21    , 5 independent categories and each, 4 days   , 5 classifiers were then fused]</td>\n",
       "      <td>[monitored for 21, on days 3, grouped into 5, were the 4, of the 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137045</th>\n",
       "      <td>computer-aided identification of ovarian cancer in confocal microendoscope images. the confocal microendoscope is an instrument for imaging the surface of the human ovary. images taken with this instrument from normal and diseased tissue show significant differences in cellular distribution. a real-time computer-aided system to facilitate the identification of ovarian cancer is introduced. the cellular-level structure present in ex vivo confocal microendoscope images is modeled as texture. features are extracted based on first-order statistics spatial gray-level-dependence matrices and spatial-frequency content. selection of the features is performed using stepwise discriminant analysis forward sequential search a nonparametric method principal component analysis and a heuristic technique that combines the results of these other methods. the selected features are used for classification and the performance of various machine classifiers is compared by analyzing areas under their receiver operating characteristic curves. the machine classifiers studied included linear discriminant analysis quadratic discriminant analysis and the k-nearest-neighbor algorithm. the results suggest it is possible to automatically identify pathology based on texture features extracted from confocal microendoscope images and that the machine performance is superior to that of a human observer.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137530</th>\n",
       "      <td>mixture of expert 3d massive-training anns for reduction of multiple types of false positives in cad for detection of polyps in ct colonography. one of the major challenges in computer-aided detection cad of polyps in ct colonography ctc is the reduction of false-positive detections fps without a concomitant reduction in sensitivity. a large number of fps is likely to confound the radiologist's task of image interpretation lower the radiologist's efficiency and cause radiologists to lose their confidence in cad as a useful tool. major sources of fps generated by cad schemes include haustral folds residual stool rectal tubes the ileocecal valve and extra-colonic structures such as the small bowel and stomach. our purpose in this study was to develop a method for the removal of various types of fps in cad of polyps while maintaining a high sensitivity. to achieve this we developed a \"mixture of expert\" three-dimensional 3d massive-training artificial neural networks mtanns consisting of four 3d mtanns that were designed to differentiate between polyps and four categories of fps: 1 rectal tubes 2 stool with bubbles 3 colonic walls with haustral folds and 4 solid stool. each expert 3d mtann was trained with examples from a specific non-polyp category along with typical polyps. the four expert 3d mtanns were combined with a mixing artificial neural network ann such that different types of fps could be removed. our database consisted of 146 ctc datasets obtained from 73 patients whose colons were prepared by standard pre-colonoscopy cleansing. each patient was scanned in both supine and prone positions. radiologists established the locations of polyps through the use of optical-colonoscopy reports. fifteen patients had 28 polyps 15 of which were 5-9 mm and 13 were 10-25 mm in size. the ctc cases were subjected to our previously reported cad method consisting of centerline-based extraction of the colon shape-based detection of polyp candidates and a bayesian-ann-based classification of polyps. the original cad method yielded 96.4% 27/28 by-polyp sensitivity with an average of 3.1 224/73 fps per patient. the mixture of expert 3d mtanns removed 63% 142/224 of the fps without the loss of any true positive; thus the fp rate of our cad scheme was improved to 1.1 82/73 fps per patient while the original sensitivity was maintained. by use of the mixture of expert 3d mtanns the specificity of a cad scheme for detection of polyps in ctc was substantially improved while a high sensitivity was maintained.</td>\n",
       "      <td>[3 d massive  , 3 d massive  , 4    , 3 d mtanns that were, 4 categories of fps , 1 rectal tubes  , 2 stool with bubbles , 3 colonic walls with haustral, 4 solid stool  , 3 d mtann was trained, 4 expert   , 3 d mtanns were combined, 146 ctc datasets obtained from, 73 patients whose colons were, 15 patients had  , 28 polyps   , 15 of which were , 5    , 13 were   , 10    , 96.4 percent   , 27    , 3.1    , 224    , 3 d mtanns removed , 63 percent   , 142    , 1.1    , 82    , 3 d mtanns the specificity]</td>\n",
       "      <td>[of expert 3, consisting of 4, polyps and 4, rectal tubes 2, with bubbles 3, folds and 4, each expert 3, consisted of 146, obtained from 73, patients had 28, which were 5, mm and 13, method yielded 96.4, average of 3.1, of expert 3, mtanns removed 63, improved to 1.1, of expert 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58132</th>\n",
       "      <td>predicting affect classification in mental status examination using machine learning face action recognition system: a pilot study in schizophrenia patients. classifying patients' affect is a pivotal part of the mental status examination. however this common practice is often widely inconsistent between raters. recent advances in the field of facial action recognition far have enabled the development of tools that can act to identify facial expressions from videos. in this study we aimed to explore the potential of using machine learning techniques on far features extracted from videotaped semi-structured psychiatric interviews of 25 male schizophrenia inpatients mean age 41.2 years std = 11.4 . five senior psychiatrists rated patients' affect based on the videos. then a novel computer vision algorithm and a machine learning method were used to predict affect classification based on each psychiatrist affect rating. the algorithm is shown to have a significant predictive power for each of the human raters. we also found that the eyes facial area contributed the most to the psychiatrists' evaluation of the patients' affect. this study serves as a proof-of-concept for the potential of using the machine learning far system as a clinician-supporting tool in an attempt to improve the consistency and reliability of mental status examination.</td>\n",
       "      <td>[25 male schizophrenia inpatients mean, 41.2 years std  , 11.4    , 5 senior psychiatrists rated patients]</td>\n",
       "      <td>[interviews of 25, mean age 41.2, std = 11.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47060</th>\n",
       "      <td>high accuracy of convolutional neural network for evaluation of helicobacter pylori infection based on endoscopic images: preliminary experience. application of artificial intelligence in gastrointestinal endoscopy is increasing. the aim of the study was to examine the accuracy of convolutional neural network cnn using endoscopic images for evaluating helicobacter pylori h. pylori infection.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75967</th>\n",
       "      <td>urine proteome profiling predicts lung cancer from control cases and other tumors. development of noninvasive reliable biomarkers for lung cancer diagnosis has many clinical benefits knowing that most of lung cancer patients are diagnosed at the late stage. for this purpose we conducted proteomic analyses of 231 human urine samples in healthy individuals n=33 benign pulmonary diseases n=40 lung cancer n=33 bladder cancer n=17 cervical cancer n=25 colorectal cancer n=22 esophageal cancer n=14 and gastric cancer n=47 patients collected from multiple medical centers. by random forest modeling we nominated a list of urine proteins that could separate lung cancers from other cases. with a feature selection algorithm we selected a panel of five urinary biomarkers ftl: ferritin light chain; mapk1ip1l: mitogen-activated protein kinase 1 interacting protein 1 like; fgb: fibrinogen beta chain; rab33b: rab33b member ras oncogene family; rab15: rab15 member ras oncogene family and established a combinatorial model that can correctly classify the majority of lung cancer cases both in the training set n=46 and the test sets n=14-47 per set with an auc ranging from 0.8747 to 0.9853. a combination of five urinary biomarkers not only discriminates lung cancer patients from control groups but also differentiates lung cancer from other common tumors. the biomarker panel and the predictive model when validated by more samples in a multi-center setting may be used as an auxiliary diagnostic tool along with imaging technology for lung cancer detection.</td>\n",
       "      <td>[231 human urine samples in, 5 urinary biomarkers ftl , 1 interacting protein  , 1 like   , 0.8747 to   , 0.9853    , 5 urinary biomarkers not only]</td>\n",
       "      <td>[analyses of 231, panel of 5, protein kinase 1, interacting protein 1, ranging from 0.8747, combination of 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5854</th>\n",
       "      <td>machine learning for predicting preoperative red blood cell demand. the paucity of accurate quantitative standards for determining the quantity of red blood cells rbcs needed for perioperative patients and the predominant application of the \"preoperative hemoglobin surgery type\" empirical decision-making model have led to widespread rbc application problems.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prediction of chemotherapy response in breast cancer patients at pre-treatment using second derivative texture of ct images and machine learning. although neoadjuvant chemotherapy nac is a crucial component of treatment for locally advanced breast cancer labc only about 70% of patients respond to it. effective adjustment of nac for individual patients can significantly improve survival rates of those resistant to standard regimens. thus the early prediction of nac outcome is of great importance in facilitating a personalized paradigm for breast cancer therapeutics. in this study quantitative computed tomography qct parametric imaging in conjunction with machine learning techniques were investigated to predict labc tumor response to nac. textural and second derivative textural sdt features of ct images of 72 patients diagnosed with labc were analysed before the initiation of nac to quantify intra-tumor heterogeneity. these quantitative features were processed through a correlation-based feature reduction followed by a sequential feature selection with a bootstrap 0.632 area under the receiver operating characteristic roc curve auc0.632 criterion. the best feature subset consisted of a combination of one textural and three sdt features. using these features an adaboost decision tree could predict the patient response with a cross-validated auc0.632 accuracy sensitivity and specificity of 0.88 85% 88% and 75% respectively. this study demonstrates for the first time that a combination of textural and sdt features of ct images can be used to predict breast cancer response nac prior to the start of treatment which can potentially facilitate early therapy adjustments.</td>\n",
       "      <td>[70 percent of patients respond, 72 patients diagnosed with labc, 0.632 area under the receiver, 3 sdt features  , 0.88    , 85 percent   , 88 percent and  , 75 percent respectively  ]</td>\n",
       "      <td>[only about 70, images of 72, a bootstrap 0.632, textural and 3, specificity of 0.88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90019</th>\n",
       "      <td>human movement recognition based on the stochastic characterisation of acceleration data. human activity recognition algorithms based on information obtained from wearable sensors are successfully applied in detecting many basic activities. identified activities with time-stationary features are characterised inside a predefined temporal window by using different machine learning algorithms on extracted features from the measured data. better accuracy precision and recall levels could be achieved by combining the information from different sensors. however detecting short and sporadic human movements gestures and actions is still a challenging task. in this paper a novel algorithm to detect human basic movements from wearable measured data is proposed and evaluated. the proposed algorithm is designed to minimise computational requirements while achieving acceptable accuracy levels based on characterising some particular points in the temporal series obtained from a single sensor. the underlying idea is that this algorithm would be implemented in the sensor device in order to pre-process the sensed data stream before sending the information to a central point combining the information from different sensors to improve accuracy levels. intra- and inter-person validation is used for two particular cases: single step detection and fall detection and classification using a single tri-axial accelerometer. relevant results for the above cases and pertinent conclusions are also presented.</td>\n",
       "      <td>[2 particular cases  ]</td>\n",
       "      <td>[used for 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        text  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "160742                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            application of artificial neural networks for quantitative analysis of image data in chest radiographs for detection of interstitial lung disease. the authors have developed an automated computeraided diagnostic cad scheme by using artificial neural networks anns on quantitative analysis of image data. three separate anns were applied for detection of interstitial disease on digitized chest images. the first ann was trained with horizontal profiles in regions of interest rois selected from normal and abnormal chest radiographs for distinguishing between normal and abnormal patterns. for training and testing of the second ann the vertical output patterns obtained from the 1st ann were used for each roi. the output value of the second ann was used to distinguish between normal and abnormal rois with interstitial infiltrates. if the ratio of the number of abnormal rois to the total number of all rois in a chest image was greater than a specified threshold level the image was classified as abnormal. in addition the third ann was applied to distinguish between normal and abnormal chest images. the combination of the rule-based method and the third ann also was applied to the classification between normal and abnormal chest images. the performance of the anns was evaluated by means of receiver operating characteristic roc analysis. the average az value area under the roc curve for distinguishing between normal and abnormal cases was 0.976 /- 0.012 for 100 chest radiographs that were not used in training of anns. the results indicate that the ann trained with image data can learn some statistical properties associated with interstitial infiltrates in chest radiographs.   \n",
       "117                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                deep learning to automate the labelling of head mri datasets for computer vision applications. the purpose of this study was to build a deep learning model to derive labels from neuroradiology reports and assign these to the corresponding examinations overcoming a bottleneck to computer vision model development.   \n",
       "71415                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      automation of detection of cervical cancer using convolutional neural networks. classification of digital cervical images acquired during visual inspection with acetic acid via is an important step in automated image-based cervical cancer detection. many algorithms have been developed for classification of cervical images based on extracting mathematical features and classifying these images. deciding the suitability of a feature and learning the algorithm is a complex task. on the other hand convolutional neural networks cnns self-learn most suitable hierarchical features from the raw input image. in this paper we demonstrate the feasibility of using a shallow layer cnn for classification of image patches of cervical images as cancerous or not cancerous. we used cervix images acquired after the application of 3%-5% acetic acid using an android device in 102 women. of these 42 cervix images belonged in the via-positive category pathologic and 60 in the via-negative category healthy controls . a total of 275 image patches of 15 ã— 15 pixels were manually extracted from via-positive areas and we considered these patches as positive examples. similarly 409 image patches were extracted from via-negative areas and were labeled as via negative. these image patches were classified using a shallow layer cnn composed of a layer each of convolutional rectified linear unit pooling and two fully connected layers. a classification accuracy of 100% is achieved using shallow cnn.   \n",
       "30756                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        using wearable sensors and machine learning to automatically detect freezing of gait during a fog-provoking test. freezing of gait fog is a debilitating motor phenomenon that is common among individuals with advanced parkinson's disease. objective and sensitive measures are needed to better quantify fog. the present work addresses this need by leveraging wearable devices and machine-learning methods to develop and evaluate automated detection of fog and quantification of its severity. seventy-one subjects with fog completed a fog-provoking test while wearing three wearable sensors lower back and each ankle . subjects were videotaped before off state and after on state they took their antiparkinsonian medications. annotations of the videos provided the \"ground-truth\" for fog detection. a leave-one-patient-out validation process with a training set of 57 subjects resulted in 84.1% sensitivity 83.4% specificity and 85.0% accuracy for fog detection. similar results were seen in an independent test set data from 14 other subjects . two derived outcomes percent time frozen and number of fog episodes were associated with self-report of fog. bother derived-metrics were higher in the off state than in the on state and in the most challenging level of the fog-provoking test compared to the least challenging level. these results suggest that this automated machine-learning approach can objectively assess fog and that its outcomes are responsive to therapeutic interventions.   \n",
       "61157                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ct-based machine learning model to predict the fuhrman nuclear grade of clear cell renal cell carcinoma. to predict the fuhrman grade of clear cell renal cell carcinoma ccrcc with a machine learning classifier based on single- or three-phase computed tomography ct images.   \n",
       "36530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       acoustic analysis and detection of pharyngeal fricative in cleft palate speech using correlation of signals in independent frequency bands and octave spectrum prominent peak. pharyngeal fricative is one typical compensatory articulation error of cleft palate speech. it passively influences daily communication for people who suffer from it. the automatic detection of pharyngeal fricatives in cleft palate speech can provide information for clinical doctors and speech-language pathologists to aid in diagnosis.   \n",
       "52089                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                using supervised learning machine algorithm to identify future fallers based on gait patterns: a two-year longitudinal study. given their major health consequences in the elderly identifying people at risk of fall is a major challenge faced by clinicians. a lot of studies have confirmed the relationships between gait parameters and falls incidence. however accurate tools to predict individual risk among independent older adults without a history of falls are lacking.   \n",
       "28713                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      machine-learning analysis of voice samples recorded through smartphones: the combined effect of ageing and gender. experimental studies using qualitative or quantitative analysis have demonstrated that the human voice progressively worsens with ageing. these studies however have mostly focused on specific voice features without examining their dynamic interaction. to examine the complexity of age-related changes in voice more advanced techniques based on machine learning have been recently applied to voice recordings but only in a laboratory setting. we here recorded voice samples in a large sample of healthy subjects. to improve the ecological value of our analysis we collected voice samples directly at home using smartphones.   \n",
       "16458                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          the challenge of predicting blood glucose concentration changes in patients with type i diabetes. patients with type i diabetes t1d must take insulin injections to prevent the serious long term effects of hyperglycemia. they must also be careful not to inject too much insulin because this could induce potentially fatal hypoglycemia. patients therefore follow a \"regimen\" that determines how much insulin to inject at each time based on various measurements. we can produce an effective regimen if we can accurately predict a patient's future blood glucose bg values from his/her current features. this study explores the challenges of predicting future bg by applying a number of machine learning algorithms as well as various data preprocessing variations corresponding to 312 [learner preprocessed-dataset] combinations to a new t1d dataset that contains 29601 entries from 47 different patients. our most accurate predictor a weighted ensemble of two gaussian process regression models achieved a cross-validation <math xmlns=\"http://www.w3.org/1998/math/mathml\"><mrow><mi>e</mi><mi>r</mi><msub><mi>r</mi><mrow><mi>l</mi><mn>1</mn></mrow></msub></mrow></math> loss of 2.7mmol/l 48.65mg/dl . this result was unexpectedly poor given that one can obtain an <math xmlns=\"http://www.w3.org/1998/math/mathml\"><mrow><mi>e</mi><mi>r</mi><msub><mi>r</mi><mrow><mi>l</mi><mn>1</mn></mrow></msub></mrow></math> of 2.9mmol/l 52.43mg/dl using the naive approach of simply predicting the patient's average bg. these results suggest that the diabetes diary data that is typically collected may be insufficient to produce accurate bg prediction models; additional data may be necessary to build accurate bg prediction models over hours.   \n",
       "126594                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            simultaneous and proportional force estimation for multifunction myoelectric prostheses using mirrored bilateral training. this study presents a novel method for associating features of the surface electromyogram emg recorded from one upper limb to the force produced by the contralateral limb. bilateral-mirrored contractions from ten able-bodied subjects were recorded along with isometric forces in multiple degrees of freedom dof from the right wrist. an artificial neural network was trained to provide force estimation. combinations of processing parameters were evaluated and an estimation algorithm allowing high accuracy from relatively short signal epochs 100 ms was proposed. the estimation performance when using surface emg from the contralateral limb was 0.90 ± 0.02 for the able-bodied subjects. in comparison the estimation performance for one subject with congenital malformation of the left forearm was 0.72 which albeit lower than for able-bodied subjects is still comparable to or better than previously reported results. the proposed method requires only the measured forces from one limb such as in the case of unilateral amputees and has thus the potential to be used in clinical settings for intuitive simultaneous control of multiple dofs in myoelectric prostheses.   \n",
       "149882                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 a method for detection of alzheimer's disease using ica-enhanced eeg measurements. many researchers have studied automatic eeg classification and recently a lot of work has been done on artefact-removal from eeg data using independent component analyses ica . however demonstrating that a ica-processed multichannel eeg measurement becomes more interpretable compared to the raw data as is usually done in work on ica-processing of eeg data does not yet prove that detection of incipient anomalies is also better possible after ica-processing. the objective of this study is to show that ica-preprocessing is useful when constructing a detection system for alzheimer's disease.   \n",
       "123313                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        automatic evaluation of pressure sore status by combining information obtained from high-frequency ultrasound and digital photography. in this study the different phases of pressure sore generation and healing are investigated through a combined analysis of high-frequency ultrasound 20 mhz images and digital color photographs. pressure sores were artificially induced in guinea pigs and the injured regions were monitored for 21 days data were obtained on days 3 7 14 and 21 . several statistical features of the images were extracted relating to both the altering pattern of tissue and its superficial appearance. the features were grouped into five independent categories and each category was used to train a neural network whose outputs were the four days. the outputs of the five classifiers were then fused using a fuzzy integral to provide the final decision. we demonstrate that the suggested method provides a better decision regarding tissue status than using either imaging technique separately. this new approach may be a viable tool for detecting the phases of pressure sore generation and healing in clinical settings.   \n",
       "137045                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      computer-aided identification of ovarian cancer in confocal microendoscope images. the confocal microendoscope is an instrument for imaging the surface of the human ovary. images taken with this instrument from normal and diseased tissue show significant differences in cellular distribution. a real-time computer-aided system to facilitate the identification of ovarian cancer is introduced. the cellular-level structure present in ex vivo confocal microendoscope images is modeled as texture. features are extracted based on first-order statistics spatial gray-level-dependence matrices and spatial-frequency content. selection of the features is performed using stepwise discriminant analysis forward sequential search a nonparametric method principal component analysis and a heuristic technique that combines the results of these other methods. the selected features are used for classification and the performance of various machine classifiers is compared by analyzing areas under their receiver operating characteristic curves. the machine classifiers studied included linear discriminant analysis quadratic discriminant analysis and the k-nearest-neighbor algorithm. the results suggest it is possible to automatically identify pathology based on texture features extracted from confocal microendoscope images and that the machine performance is superior to that of a human observer.   \n",
       "137530  mixture of expert 3d massive-training anns for reduction of multiple types of false positives in cad for detection of polyps in ct colonography. one of the major challenges in computer-aided detection cad of polyps in ct colonography ctc is the reduction of false-positive detections fps without a concomitant reduction in sensitivity. a large number of fps is likely to confound the radiologist's task of image interpretation lower the radiologist's efficiency and cause radiologists to lose their confidence in cad as a useful tool. major sources of fps generated by cad schemes include haustral folds residual stool rectal tubes the ileocecal valve and extra-colonic structures such as the small bowel and stomach. our purpose in this study was to develop a method for the removal of various types of fps in cad of polyps while maintaining a high sensitivity. to achieve this we developed a \"mixture of expert\" three-dimensional 3d massive-training artificial neural networks mtanns consisting of four 3d mtanns that were designed to differentiate between polyps and four categories of fps: 1 rectal tubes 2 stool with bubbles 3 colonic walls with haustral folds and 4 solid stool. each expert 3d mtann was trained with examples from a specific non-polyp category along with typical polyps. the four expert 3d mtanns were combined with a mixing artificial neural network ann such that different types of fps could be removed. our database consisted of 146 ctc datasets obtained from 73 patients whose colons were prepared by standard pre-colonoscopy cleansing. each patient was scanned in both supine and prone positions. radiologists established the locations of polyps through the use of optical-colonoscopy reports. fifteen patients had 28 polyps 15 of which were 5-9 mm and 13 were 10-25 mm in size. the ctc cases were subjected to our previously reported cad method consisting of centerline-based extraction of the colon shape-based detection of polyp candidates and a bayesian-ann-based classification of polyps. the original cad method yielded 96.4% 27/28 by-polyp sensitivity with an average of 3.1 224/73 fps per patient. the mixture of expert 3d mtanns removed 63% 142/224 of the fps without the loss of any true positive; thus the fp rate of our cad scheme was improved to 1.1 82/73 fps per patient while the original sensitivity was maintained. by use of the mixture of expert 3d mtanns the specificity of a cad scheme for detection of polyps in ctc was substantially improved while a high sensitivity was maintained.   \n",
       "58132                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           predicting affect classification in mental status examination using machine learning face action recognition system: a pilot study in schizophrenia patients. classifying patients' affect is a pivotal part of the mental status examination. however this common practice is often widely inconsistent between raters. recent advances in the field of facial action recognition far have enabled the development of tools that can act to identify facial expressions from videos. in this study we aimed to explore the potential of using machine learning techniques on far features extracted from videotaped semi-structured psychiatric interviews of 25 male schizophrenia inpatients mean age 41.2 years std = 11.4 . five senior psychiatrists rated patients' affect based on the videos. then a novel computer vision algorithm and a machine learning method were used to predict affect classification based on each psychiatrist affect rating. the algorithm is shown to have a significant predictive power for each of the human raters. we also found that the eyes facial area contributed the most to the psychiatrists' evaluation of the patients' affect. this study serves as a proof-of-concept for the potential of using the machine learning far system as a clinician-supporting tool in an attempt to improve the consistency and reliability of mental status examination.   \n",
       "47060                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             high accuracy of convolutional neural network for evaluation of helicobacter pylori infection based on endoscopic images: preliminary experience. application of artificial intelligence in gastrointestinal endoscopy is increasing. the aim of the study was to examine the accuracy of convolutional neural network cnn using endoscopic images for evaluating helicobacter pylori h. pylori infection.   \n",
       "75967                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   urine proteome profiling predicts lung cancer from control cases and other tumors. development of noninvasive reliable biomarkers for lung cancer diagnosis has many clinical benefits knowing that most of lung cancer patients are diagnosed at the late stage. for this purpose we conducted proteomic analyses of 231 human urine samples in healthy individuals n=33 benign pulmonary diseases n=40 lung cancer n=33 bladder cancer n=17 cervical cancer n=25 colorectal cancer n=22 esophageal cancer n=14 and gastric cancer n=47 patients collected from multiple medical centers. by random forest modeling we nominated a list of urine proteins that could separate lung cancers from other cases. with a feature selection algorithm we selected a panel of five urinary biomarkers ftl: ferritin light chain; mapk1ip1l: mitogen-activated protein kinase 1 interacting protein 1 like; fgb: fibrinogen beta chain; rab33b: rab33b member ras oncogene family; rab15: rab15 member ras oncogene family and established a combinatorial model that can correctly classify the majority of lung cancer cases both in the training set n=46 and the test sets n=14-47 per set with an auc ranging from 0.8747 to 0.9853. a combination of five urinary biomarkers not only discriminates lung cancer patients from control groups but also differentiates lung cancer from other common tumors. the biomarker panel and the predictive model when validated by more samples in a multi-center setting may be used as an auxiliary diagnostic tool along with imaging technology for lung cancer detection.   \n",
       "5854                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                machine learning for predicting preoperative red blood cell demand. the paucity of accurate quantitative standards for determining the quantity of red blood cells rbcs needed for perioperative patients and the predominant application of the \"preoperative hemoglobin surgery type\" empirical decision-making model have led to widespread rbc application problems.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  prediction of chemotherapy response in breast cancer patients at pre-treatment using second derivative texture of ct images and machine learning. although neoadjuvant chemotherapy nac is a crucial component of treatment for locally advanced breast cancer labc only about 70% of patients respond to it. effective adjustment of nac for individual patients can significantly improve survival rates of those resistant to standard regimens. thus the early prediction of nac outcome is of great importance in facilitating a personalized paradigm for breast cancer therapeutics. in this study quantitative computed tomography qct parametric imaging in conjunction with machine learning techniques were investigated to predict labc tumor response to nac. textural and second derivative textural sdt features of ct images of 72 patients diagnosed with labc were analysed before the initiation of nac to quantify intra-tumor heterogeneity. these quantitative features were processed through a correlation-based feature reduction followed by a sequential feature selection with a bootstrap 0.632 area under the receiver operating characteristic roc curve auc0.632 criterion. the best feature subset consisted of a combination of one textural and three sdt features. using these features an adaboost decision tree could predict the patient response with a cross-validated auc0.632 accuracy sensitivity and specificity of 0.88 85% 88% and 75% respectively. this study demonstrates for the first time that a combination of textural and sdt features of ct images can be used to predict breast cancer response nac prior to the start of treatment which can potentially facilitate early therapy adjustments.   \n",
       "90019                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     human movement recognition based on the stochastic characterisation of acceleration data. human activity recognition algorithms based on information obtained from wearable sensors are successfully applied in detecting many basic activities. identified activities with time-stationary features are characterised inside a predefined temporal window by using different machine learning algorithms on extracted features from the measured data. better accuracy precision and recall levels could be achieved by combining the information from different sensors. however detecting short and sporadic human movements gestures and actions is still a challenging task. in this paper a novel algorithm to detect human basic movements from wearable measured data is proposed and evaluated. the proposed algorithm is designed to minimise computational requirements while achieving acceptable accuracy levels based on characterising some particular points in the temporal series obtained from a single sensor. the underlying idea is that this algorithm would be implemented in the sensor device in order to pre-process the sensed data stream before sending the information to a central point combining the information from different sensors to improve accuracy levels. intra- and inter-person validation is used for two particular cases: single step detection and fall detection and classification using a single tri-axial accelerometer. relevant results for the above cases and pertinent conclusions are also presented.    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           num_plus  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "160742                                                                                                                                                                                                                                                                                                                                                                                                                 [3 separate anns were applied, 1 st ann were used, 0.976    , 0.012 for   , 100 chest radiographs that were]   \n",
       "117                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              []   \n",
       "71415                                                                                                                                                                                                                                                                                      [3 percent   , 102 women   , 42 cervix images belonged in, 60 in the via , 275 image patches of , 15    , 15 pixels were manually extracted, 409 image patches were extracted, 2 fully connected layers , 100 percent is achieved using]   \n",
       "30756                                                                                                                                                                                                                                                                                     [71 subjects with fog completed, 3 wearable sensors lower back, 57 subjects resulted in , 84.1 percent sensitivity  , 83.4 percent specificity and , 85.0 percent accuracy for fog, 14 other subjects  , 2 derived outcomes percent time]   \n",
       "61157                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "36530                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "52089                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "28713                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "16458                                                                                                                                                                                                                                                                                                                                                                            [312    , 29601 entries from  , 47 different patients  , 2 gaussian process regression models, 2.7 mmol   , 48.65 mg   , 2.9 mmol   , 52.43 mg   ]   \n",
       "126594                                                                                                                                                                                                                                                                                                                                                                                                                               [10 able   , 100 ms was proposed , 0.90    , 0.02 for the able , 0.72 which albeit lower than]   \n",
       "149882                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           []   \n",
       "123313                                                                                                                                                                                                                                                                                                                                                        [20 mhz images and digital, 21 days data were obtained, 3    , 7    , 14 and   , 21    , 5 independent categories and each, 4 days   , 5 classifiers were then fused]   \n",
       "137045                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           []   \n",
       "137530  [3 d massive  , 3 d massive  , 4    , 3 d mtanns that were, 4 categories of fps , 1 rectal tubes  , 2 stool with bubbles , 3 colonic walls with haustral, 4 solid stool  , 3 d mtann was trained, 4 expert   , 3 d mtanns were combined, 146 ctc datasets obtained from, 73 patients whose colons were, 15 patients had  , 28 polyps   , 15 of which were , 5    , 13 were   , 10    , 96.4 percent   , 27    , 3.1    , 224    , 3 d mtanns removed , 63 percent   , 142    , 1.1    , 82    , 3 d mtanns the specificity]   \n",
       "58132                                                                                                                                                                                                                                                                                                                                                                                                                    [25 male schizophrenia inpatients mean, 41.2 years std  , 11.4    , 5 senior psychiatrists rated patients]   \n",
       "47060                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            []   \n",
       "75967                                                                                                                                                                                                                                                                                                                                                                          [231 human urine samples in, 5 urinary biomarkers ftl , 1 interacting protein  , 1 like   , 0.8747 to   , 0.9853    , 5 urinary biomarkers not only]   \n",
       "5854                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             []   \n",
       "3                                                                                                                                                                                                                                                                                                                                          [70 percent of patients respond, 72 patients diagnosed with labc, 0.632 area under the receiver, 3 sdt features  , 0.88    , 85 percent   , 88 percent and  , 75 percent respectively  ]   \n",
       "90019                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [2 particular cases  ]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                        num_minus  \n",
       "index                                                                                                                                                                                                                                                                                              \n",
       "160742                                                                                                                                                                                                                                                              [from the 1, cases was 0.976]  \n",
       "117                                                                                                                                                                                                                                                                                            []  \n",
       "71415                                                                                                                                                              [application of 3, device in 102, of these 42, pathologic and 60, total of 275, patches of 15, pooling and 2, accuracy of 100]  \n",
       "30756                                                                                                                                                                                                          [while wearing 3, set of 57, resulted in 84.1, specificity and 85.0, data from 14]  \n",
       "61157                                                                                                                                                                                                                                                                                          []  \n",
       "36530                                                                                                                                                                                                                                                                                          []  \n",
       "52089                                                                                                                                                                                                                                                                                          []  \n",
       "28713                                                                                                                                                                                                                                                                                          []  \n",
       "16458                                                                                                                                                                                                    [corresponding to 312, that contains 29601, entries from 47, ensemble of 2, loss of 2.7]  \n",
       "126594                                                                                                                                                                                                                 [contractions from 10, signal epochs 100, limb was 0.90, forearm was 0.72]  \n",
       "149882                                                                                                                                                                                                                                                                                         []  \n",
       "123313                                                                                                                                                                                                                        [monitored for 21, on days 3, grouped into 5, were the 4, of the 5]  \n",
       "137045                                                                                                                                                                                                                                                                                         []  \n",
       "137530  [of expert 3, consisting of 4, polyps and 4, rectal tubes 2, with bubbles 3, folds and 4, each expert 3, consisted of 146, obtained from 73, patients had 28, which were 5, mm and 13, method yielded 96.4, average of 3.1, of expert 3, mtanns removed 63, improved to 1.1, of expert 3]  \n",
       "58132                                                                                                                                                                                                                                               [interviews of 25, mean age 41.2, std = 11.4]  \n",
       "47060                                                                                                                                                                                                                                                                                          []  \n",
       "75967                                                                                                                                                                               [analyses of 231, panel of 5, protein kinase 1, interacting protein 1, ranging from 0.8747, combination of 5]  \n",
       "5854                                                                                                                                                                                                                                                                                           []  \n",
       "3                                                                                                                                                                                                           [only about 70, images of 72, a bootstrap 0.632, textural and 3, specificity of 0.88]  \n",
       "90019                                                                                                                                                                                                                                                                                [used for 2]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelleddf.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1a34bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_terms = ('patient', 'subject', 'volunt', 'adult', 'youth', 'teen', 'child', 'infant',\n",
    "                 'neonate', 'men ', 'women', 'male', 'admission', 'stay', 'particip', 'case', 'recipient',\n",
    "            'individual', 'notes')\n",
    "\n",
    "main_list = [[] for _ in range(len(labelleddf))] \n",
    "\n",
    "for i in range(len(labelleddf)):        \n",
    "    for y in labelleddf.iloc[i, 1]:\n",
    "        for x in set_terms:          \n",
    "            if x in y and 'percent' not in y:\n",
    "                main_list[i].append(y)\n",
    "            \n",
    "                    \n",
    "num_list = [[re.sub(\"[^\\\\d.]\",\" \",x).strip().lower() for x in y] for y in main_list]\n",
    "num_list = [list(map(float, x)) for x in num_list]\n",
    "max_list = [max(y, default=0) for y in num_list]\n",
    "\n",
    "labelleddf['patient_terms'] = main_list\n",
    "labelleddf['patient_num'] = num_list\n",
    "labelleddf['patient_size'] = max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02eb8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_terms = ('imag', 'ct ', 'tomog', 'mri', 't1', 't2', 'weight', 'radio', 'photo', 'scan', 'pict',\n",
    "            'ecg', 'eeg', 'echo', 'oct', 'result', 'test'\n",
    "            'slide', 'histo', 'annot', 'sample', 'us ', 'ultra', 'mamm',\n",
    "            'endo', 'colono', 'skin', 'tissue', 'gen', 'patch', 'path', 'audio', 'record',\n",
    "            )\n",
    "\n",
    "main_list = [[] for _ in range(len(labelleddf))] \n",
    "\n",
    "for i in range(len(labelleddf)):        \n",
    "    for y in labelleddf.iloc[i, 1]:\n",
    "        for x in set_terms:          \n",
    "            if x in y and 'percent' not in y:\n",
    "                main_list[i].append(y)\n",
    "\n",
    "num_list = [[re.sub(\"[^\\\\d.]\",\" \",x).strip().lower() for x in y] for y in main_list]\n",
    "num_list = [list(map(float, x)) for x in num_list]\n",
    "max_list = [max(y, default=0) for y in num_list]\n",
    "                \n",
    "labelleddf['feature_terms'] = main_list\n",
    "labelleddf['feature_num'] = num_list\n",
    "labelleddf['feature_size'] = max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d5f92e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_terms = ('n=', 'n =')\n",
    "\n",
    "main_list = [[] for _ in range(len(labelleddf))] \n",
    "\n",
    "for i in range(len(labelleddf)):        \n",
    "    for y in labelleddf.iloc[i, 2]:\n",
    "        for x in set_terms:          \n",
    "            if x in y:\n",
    "                main_list[i].append(y)\n",
    "\n",
    "num_list = [[re.sub(\"[^\\\\d.]\",\" \",x).strip().lower() for x in y] for y in main_list]\n",
    "num_list = [list(map(float, x)) for x in num_list]\n",
    "max_list = [max(y, default=0) for y in num_list]\n",
    "                \n",
    "labelleddf['n='] = main_list\n",
    "labelleddf['n_num'] = num_list\n",
    "labelleddf['n_size'] = max_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "417fa7c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_plus</th>\n",
       "      <th>num_minus</th>\n",
       "      <th>patient_terms</th>\n",
       "      <th>patient_num</th>\n",
       "      <th>patient_size</th>\n",
       "      <th>feature_terms</th>\n",
       "      <th>feature_num</th>\n",
       "      <th>feature_size</th>\n",
       "      <th>n=</th>\n",
       "      <th>n_num</th>\n",
       "      <th>n_size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134590</th>\n",
       "      <td>evaluation of a dynamic bayesian belief network to predict osteoarthritic knee pain using data from the osteoarthritis initiative. the most common cause of disability in older adults in the united states is osteoarthritis. to address the problem of early disease prediction we have constructed a bayesian belief network bbn composed of knee oa-related symptoms to support prognostic queries. the purpose of this study is to evaluate a static and dynamic bbn--based on the nih osteoarthritis initiative oai data--in predicting the likelihood of a patient being diagnosed with knee oa. initial validation results are promising: our model outperforms a logistic regression model in several designed studies. we can conclude that our model can effectively predict the symptoms that are commonly associated with the presence of knee oa.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121837</th>\n",
       "      <td>a cellular neural network methodology for the automated segmentation of multiple sclerosis lesions. we present a new application based on genetic algorithms gas that evolves a cellular neural network cnn capable of automatically determining the lesion load in multiple sclerosis ms patients from magnetic resonance imaging mri . in particular it seeks to identify brain areas affected by lesions whose presence is revealed by areas of higher intensity if compared to healthy tissue. the performance of the cnn algorithm has been quantitatively evaluated by comparing the cnn output with the expert's manual delineation of ms lesions. the cnn algorithm was run on a data set of 11 ms patients; for each one a single dataset of mri images matrix resolution of 256ã—256 pixels was acquired. our automated approach gives satisfactory results showing that after the learning process the cnn is capable of detecting ms lesions with different shapes and intensities mean dice coefficient=0.64 . the system could provide a useful support tool for the evaluation of lesions in ms patients although it needs to be evolved and developed in the future.</td>\n",
       "      <td>[11 ms patients  , 256    ]</td>\n",
       "      <td>[set of 11, resolution of 256]</td>\n",
       "      <td>[11 ms patients  ]</td>\n",
       "      <td>[11.0]</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89006</th>\n",
       "      <td>evaluating stability of histomorphometric features across scanner and staining variations: prostate cancer diagnosis from whole slide images. quantitative histomorphometry qh is the process of computerized feature extraction from digitized tissue slide images to predict disease presence behavior and outcome. feature stability between sites may be compromised by laboratory-specific variables including dye batch slice thickness and the whole slide scanner used. we present two new measures preparation-induced instability score and latent instability score to quantify feature instability across and within datasets. in a use case involving prostate cancer we examined qh features which may detect cancer on whole slide images. using our method we found that five feature families graph shape co-occurring gland tensor sub-graph and texture were different between datasets in 19.7% to 48.6% of comparisons while the values expected without site variation were 4.2% to 4.6%. color normalizing all images to a template did not reduce instability. scanning the same 34 slides on three scanners demonstrated that haralick features were most substantively affected by scanner variation being unstable in 62% of comparisons. we found that unstable feature families performed significantly worse in inter- than intrasite classification. our results appear to suggest qh features should be evaluated across sites to assess robustness and class discriminability alone should not represent the benchmark for digital pathology feature selection.</td>\n",
       "      <td>[2 new measures preparation , 5 feature families graph shape, 19.7 percent to  , 48.6 percent of comparisons while, 4.2 percent to  , 4.6 percent   , 34 slides on  , 3 scanners demonstrated that haralick, 62 percent of comparisons ]</td>\n",
       "      <td>[we present 2, found that 5, datasets in 19.7, variation were 4.2, the same 34, slides on 3, unstable in 62]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3 scanners demonstrated that haralick]</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>sell and ifi44 as potential biomarkers of sjã¶gren's syndrome and their correlation with immune cell infiltration. the onset of sjã¶gren's syndrome ss is hidden early diagnosis is difficult and the disorder seriously endangers the physical and mental health of affected people. this study aims to identify potential biomarkers of ss and to investigate the characteristics of immune cell infiltration. we used four ss gene expression profile data series from the gene expression omnibus database and applied bioinformatics analysis and machine learning algorithms to screen two biomarkers sell l-selectin and ifi44 interferon-induced protein 44 from 101 differentially expressed genes. the two-gene model comprising sell and ifi44 showed good diagnostic ability for ss in the training set auc = 0.992 and verification set auc = 0.917 . analysis of infiltrating immune cells in ss identified naive b cells resting cd4 memory t cells activated cd4 memory t cells gamma delta t cells m0 macrophages m1 macrophages plasma cells cd8 t cells activated nk cells and monocytes as candidate participants in the ss process. furthermore sell was associated with m2 macrophages activated cd4 memory t cells gamma delta t cells resting nk cells and plasma cells while ifi44 was associated with activated mast cells resting nk cells resting mast cells and cd8 t cells. this study demonstrates that sell and ifi44 can serve as good diagnostic markers for ss and may also be new diagnostic and therapeutic targets for ss.</td>\n",
       "      <td>[4 ss gene expression profile, 2 biomarkers sell l , 44 from   , 101 differentially expressed genes , 0.992 and verification set auc, 0.917    ]</td>\n",
       "      <td>[we used 4, to screen 2, auc = 0.992, auc = 0.917]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[4 ss gene expression profile, 101 differentially expressed genes ]</td>\n",
       "      <td>[4.0, 101.0]</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14701</th>\n",
       "      <td>prospective development and validation of a liquid immune profile-based signature lips to predict response of patients with recurrent/metastatic cancer to immune checkpoint inhibitors. the predictive power of novel biological markers for treatment response to immune checkpoint inhibitors ici is still not satisfactory for the majority of patients with cancer. one should identify valid predictive markers in the peripheral blood as this is easily available before and during treatment. the current interim analysis of patients of the st-ici cohort therefore focuses on the development and validation of a liquid immune profile-based signature lips to predict response of patients with metastatic cancer to ici targeting the programmed cell death protein 1 pd-1 /programmed cell death-ligand 1 pd-l1 axis.</td>\n",
       "      <td>[1 pd   , 1 pd   ]</td>\n",
       "      <td>[death protein 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20454</th>\n",
       "      <td>covid-19 mortality risk assessment: an international multi-center study. timely identification of covid-19 patients at high risk of mortality can significantly improve patient management and resource allocation within hospitals. this study seeks to develop and validate a data-driven personalized mortality risk calculator for hospitalized covid-19 patients. de-identified data was obtained for 3927 covid-19 positive patients from six independent centers comprising 33 different hospitals. demographic clinical and laboratory variables were collected at hospital admission. the covid-19 mortality risk cmr tool was developed using the xgboost algorithm to predict mortality. its discrimination performance was subsequently evaluated on three validation cohorts. the derivation cohort of 3062 patients has an observed mortality rate of 26.84%. increased age decreased oxygen saturation ¤ 93% elevated levels of c-reactive protein ¥ 130 mg/l blood urea nitrogen ¥ 18 mg/dl and blood creatinine ¥ 1.2 mg/dl were identified as primary risk factors validating clinical findings. the model obtains out-of-sample aucs of 0.90 95% ci 0.87-0.94 on the derivation cohort. in the validation cohorts the model obtains aucs of 0.92 95% ci 0.88-0.95 on seville patients 0.87 95% ci 0.84-0.91 on hellenic covid-19 study group patients and 0.81 95% ci 0.76-0.85 on hartford hospital patients. the cmr tool is available as an online application at covidanalytics.io/mortality_calculator and is currently in clinical use. the cmr model leverages machine learning to generate accurate mortality predictions using commonly available clinical features. this is the first risk score trained and validated on a cohort of covid-19 patients from europe and the united states.</td>\n",
       "      <td>[3927 covid   , 6 independent centers comprising , 33 different hospitals  , 3 validation cohorts  , 3062 patients has an observed, 26.84 percent   , 93 percent elevated levels of, 130 mg   , 18 mg   , 1.2 mg   , 0.90    , 95 percent ci  , 0.87    , 0.92    , 95 percent ci  , 0.88    , 0.87    , 95 percent ci  , 0.84    , 0.81    , 95 percent ci  , 0.76    ]</td>\n",
       "      <td>[obtained for 3927, patients from 6, centers comprising 33, evaluated on 3, cohort of 3062, rate of 26.84, aucs of 0.90, aucs of 0.92, seville patients 0.87, patients and 0.81]</td>\n",
       "      <td>[3062 patients has an observed]</td>\n",
       "      <td>[3062.0]</td>\n",
       "      <td>3062.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94867</th>\n",
       "      <td>effects of prosthesis use on the capability to control myoelectric robotic prosthetic hands. the natural control of robotic prosthetic hands with non-invasive techniques is still a challenge: myoelectric prostheses currently give some control capabilities; the application of pattern recognition techniques is promising and recently started to be applied in practice but still many questions are open in the field. in particular the effects of clinical factors on movement classification accuracy and the capability to control myoelectric prosthetic hands are analyzed in very few studies. the effect of regularly using prostheses on movement classification accuracy has been previously studied showing differences between users of myoelectric and cosmetic prostheses. in this paper we compare users of myoelectric and body-powered prostheses and intact subjects. 36 machine-learning methods are applied on 6 amputees and 40 intact subjects performing 40 movements. then statistical analyses are performed in order to highlight significant differences between the groups of subjects. the statistical analyses do not show significant differences between the two groups of amputees while significant differences are obtained between amputees and intact subjects. these results constitute new information in the field and suggest new interpretations to previous hypotheses thus adding precious information towards natural control of robotic prosthetic hands.</td>\n",
       "      <td>[36 machine   , 6 amputees and  , 40 intact subjects performing , 40 movements   , 2 groups of amputees while]</td>\n",
       "      <td>[applied on 6, amputees and 40, subjects performing 40, between the 2]</td>\n",
       "      <td>[40 intact subjects performing ]</td>\n",
       "      <td>[40.0]</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[40 intact subjects performing ]</td>\n",
       "      <td>[40.0]</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39213</th>\n",
       "      <td>automated detection of vestibular schwannoma growth using a two-dimensional u-net convolutional neural network. to determine if an automated vestibular schwannoma vs segmentation model has comparable performance to using the greatest linear dimension to detect growth.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82669</th>\n",
       "      <td>spinenet: automated classification and evidence visualization in spinal mris. the objective of this work is to automatically produce radiological gradings of spinal lumbar mris and also localize the predicted pathologies. we show that this can be achieved via a convolutional neural network cnn framework that takes intervertebral disc volumes as inputs and is trained only on disc-specific class labels. our contributions are: i a cnn architecture that predicts multiple gradings at once and we propose variants of the architecture including using 3d convolutions; ii showing that this architecture can be trained using a multi-task loss function without requiring segmentation level annotation; and iii a localization method that clearly shows pathological regions in the disc volumes. we compare three visualization methods for the localization. the network is applied to a large corpus of mri t2 sagittal spinal mris using a standard clinical scan protocol acquired from multiple machines and is used to automatically compute disk and vertebra gradings for each mri. these are: pfirrmann grading disc narrowing upper/lower endplate defects upper/lower marrow changes spondylolisthesis and central canal stenosis. we report near human performances across the eight gradings and also visualize the evidence for these gradings localized on the original scans.</td>\n",
       "      <td>[3 d convolutions  , 3 visualization methods for the, 8 gradings and also visualize]</td>\n",
       "      <td>[including using 3, we compare 3, across the 8]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30146</th>\n",
       "      <td>a deep-learning approach for automated oct en-face retinal vessel segmentation in cases of optic disc swelling using multiple en-face images as input. in cases of optic disc swelling segmentation of projected retinal blood vessels from optical coherence tomography oct volumes is challenging due to swelling-based shadowing artifacts. based on our hypothesis that simultaneously considering vessel information from multiple projected retinal layers can substantially increase vessel visibility in this work we propose a deep-learning-based approach to segment vessels involving the simultaneous use of three oct en-face images as input.</td>\n",
       "      <td>[3 oct en  ]</td>\n",
       "      <td>[use of 3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[3 oct en  , 3 oct en  ]</td>\n",
       "      <td>[3.0, 3.0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72715</th>\n",
       "      <td>deep learning models to remix music for cochlear implant users. the severe hearing loss problems that some people suffer can be treated by providing them with a surgically implanted electrical device called cochlear implant ci . ci users struggle to perceive complex audio signals such as music; however previous studies show that ci recipients find music more enjoyable when the vocals are enhanced with respect to the background music. in this manuscript source separation ss algorithms are used to remix pop songs by applying gain to the lead singing voice. this work uses deep convolutional auto-encoders a deep recurrent neural network a multilayer perceptron mlp and non-negative matrix factorization to be evaluated objectively and subjectively through two different perceptual experiments which involve normal hearing subjects and ci recipients. the evaluation assesses the relevance of the artifacts introduced by the ss algorithms considering their computation time as this study aims at proposing one of the algorithms for real-time implementation. results show that the mlp performs in a robust way throughout the tested data while providing levels of distortions and artifacts which are not perceived by ci users. thus an mlp is proposed to be implemented for real-time monaural audio ss to remix music for ci users.</td>\n",
       "      <td>[2 different perceptual experiments which]</td>\n",
       "      <td>[subjectively through 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122198</th>\n",
       "      <td>seven-days-ahead forecasting of childhood asthma admissions using artificial neural networks in athens greece. artificial neural network ann models were developed and applied in order to predict the total weekly number of childhood asthma admission caa at the greater athens area gaa in greece. hourly meteorological data from the national observatory of athens and ambient air pollution data from seven different areas within the gaa for the period 2001-2004 were used. asthma admissions for the same period were obtained from hospital registries of the three main children's hospitals of athens. three different ann models were developed and trained in order to forecast the caa for the subgroups of 0-4 5-14-year olds and for the whole study population. the results of this work have shown that anns could give an adequate forecast of the total weekly number of caa in relation to the bioclimatic and air pollution conditions. the forecasted numbers are in very good agreement with the observed real total weekly numbers of caa.</td>\n",
       "      <td>[7 different areas within the, 2001    , 3 main children  , 3 different ann models were, 0    , 5    ]</td>\n",
       "      <td>[data from 7, the period 2001, of the 3, subgroups of 0]</td>\n",
       "      <td>[3 main children  ]</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24232</th>\n",
       "      <td>internet of things and machine learning for healthy ageing: identifying the early signs of dementia. identifying the symptoms of the early stages of dementia is a difficult task particularly for older adults living in residential care. internet of things iot and smart environments can assist with the early detection of dementia by nonintrusive monitoring of the daily activities of the older adults. in this work we focus on the daily life activities of adults in a smart home setting to discover their potential cognitive anomalies using a public dataset. after analysing the dataset extracting the features and selecting distinctive features based on dynamic ranking a classification model is built. we compare and contrast several machine learning approaches for developing a reliable and efficient model to identify the cognitive status of monitored adults. using our predictive model and our approach of distinctive feature selection we have achieved 90.74% accuracy in detecting the onset of dementia.</td>\n",
       "      <td>[90.74 percent accuracy in detecting]</td>\n",
       "      <td>[have achieved 90.74]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60238</th>\n",
       "      <td>passenger mutations accurately classify human tumors. determining the cancer type and molecular subtype has important clinical implications. the primary site is however unknown for some malignancies discovered in the metastatic stage. moreover liquid biopsies may be used to screen for tumoral dna which upon detection needs to be assigned to a site-of-origin. classifiers based on genomic features are a promising approach to prioritize the tumor anatomical site type and subtype. we examined the predictive ability of causal driver somatic mutations in this task comparing it against global patterns of non-selected passenger mutations including features based on regional mutation density rmd . in the task of distinguishing 18 cancer types the driver mutations-mutated oncogenes or tumor suppressors pathways and hotspots-classified 36% of the patients to the correct cancer type. in contrast the features based on passenger mutations did so at 92% accuracy with similar contribution from the rmd and the trinucleotide mutation spectra. the rmd and the spectra covered distinct sets of patients with predictions. in particular introducing the rmd features into a combined classification model increased the fraction of diagnosed patients by 50 percentage points at 20% fdr . furthermore rmd was able to discriminate molecular subtypes and/or anatomical site of six major cancers. the advantage of passenger mutations was upheld under high rates of false negative mutation calls and with exome sequencing even though overall accuracy decreased. we suggest whole genome sequencing is valuable for classifying tumors because it captures global patterns emanating from mutational processes which are informative of the underlying tumor biology.</td>\n",
       "      <td>[18 cancer types the driver, 36 percent of the patients, 92 percent accuracy with similar, 50 percentage points at , 20 percent fdr  , 6 major cancers  ]</td>\n",
       "      <td>[of distinguishing 18, so at 92, patients by 50, points at 20, site of 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123814</th>\n",
       "      <td>clinical data do not improve artificial neural network interpretation of myocardial perfusion scintigraphy. artificial neural networks interpretation of myocardial perfusion scintigraphy mps has so far been based on image data alone. physicians reporting mps often combine image and clinical data. the aim was to evaluate whether neural network interpretation would be improved by adding clinical data to image data. four hundred and eighteen patients were used for training and 532 patients for testing the neural networks. first the network was trained with image data alone and thereafter with image data in combination with clinical parameters age gender previous infarction percutaneous coronary intervention coronary artery bypass grafting typical chest pain present smoker hypertension hyperlipidaemia diabetes peripheral vascular disease and positive family history . expert interpretation was used as gold standard. receiver operating characteristic roc curves were calculated and the roc areas for the networks trained with and without clinical data were compared for the diagnosis of myocardial infarction and ischaemia. there was no statistically significant difference in roc area for the diagnosis of myocardial infarction between the neural network trained with the combination of clinical and image data 95.8% and with image data alone 95.2% . for the diagnosis of ischaemia there was no statistically significant difference in roc area between the neural network trained with the combination of clinical and image data 87.9% and with image data alone 88.0% . neural network interpretation of mps is not improved when clinical data are added to perfusion and functional data. one reason for this could be that experts base their interpretations of mps mainly on the images and to a lesser degree on clinical data.</td>\n",
       "      <td>[400 and   , 18 patients were used for, 532 patients for testing the, 95.8 percent and with image, 95.2 percent   , 87.9 percent and with image, 88.0 percent   ]</td>\n",
       "      <td>[training and 532, image data 95.8, data alone 95.2, image data 87.9, data alone 88.0]</td>\n",
       "      <td>[18 patients were used for, 532 patients for testing the]</td>\n",
       "      <td>[18.0, 532.0]</td>\n",
       "      <td>532.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61636</th>\n",
       "      <td>prediction of cancer using customised fuzzy rough machine learning approaches. this letter proposes a customised approach for attribute selection applied to the fuzzy rough quick reduct algorithm. the unbalanced data is balanced using synthetic minority oversampling technique. the huge dimensionality of the cancer data is reduced using a correlation-based filter. the dimensionality reduced balanced attribute gene subset is used to compute the final minimal reduct set using a customised fuzzy triangular norm operator on the fuzzy rough quick reduct algorithm. the customised fuzzy triangular norm operator is used with a lukasiewicz fuzzy implicator to compute the fuzzy approximation. the customised operator selects the least number of informative feature genes from the dimensionality reduced datasets. classification accuracy using leave-one-out cross validation of 94.85 76.54 98.11 and 99.13% is obtained using a customised function for lukasiewicz triangular norm operator on leukemia central nervous system lung and ovarian datasets respectively. performance analysis of the conventional fuzzy rough quick reduct and the proposed method are performed using parameters such as classification accuracy precision recall f-measure scatter plots receiver operating characteristic area mcnemar test chi-squared test matthew's correlation coefficient and false discovery rate that are used to prove that the proposed approach performs better than available methods in the literature.</td>\n",
       "      <td>[94.85    , 76.54    , 98.11 and   , 99.13 percent is obtained using]</td>\n",
       "      <td>[validation of 94.85]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29550</th>\n",
       "      <td>radiomics based on cect in differentiating kimura disease from lymph node metastases in head and neck: a non-invasive and reliable method. background: kimura disease may be easily misdiagnosed as malignant tumors such as lymph node metastases based on imaging and clinical symptoms. the aim of this article is to investigate whether the radiomic features and the model based on the features on venous-phase contrast-enhanced ct cect images can distinguish kimura disease from lymph node metastases in the head and neck. methods: a retrospective analysis of 14 patients of head and neck kimura disease a total of 38 enlarged lymph nodes and 39 patients with head and neck lymph node metastases a total of 39 enlarged lymph nodes confirmed by biopsy or surgery resection was conducted. all patients accepted cect within 10 days before biopsy or surgery resection. radiomic features based on venous-phase cect were generated automatically from artificial-intelligence kit ak software. all lymph nodes were randomly divided into the training set n = 54 and testing set n = 23 in a ratio of 7:3. anova mann-whitney spearman correlation least absolute shrinkage and selection operator and gradient descent were introduced for the reduction of the highly redundant features. binary logistic regression model was constructed based on the selected features. receiver operating characteristic was used to evaluate the diagnostic performance of the features and the model. finally a nomogram was established for model application. results: seven features were screened out at the end. significant difference was found between the two groups for all the features with area under the curves aucs ranging from 0.759 to 0.915. the auc of the model's identification performance was 0.970 in the training group and 0.977 in the testing group. the disease discrimination efficiency of the model was better than that of any single feature. conclusions: the radiomic features and the model based on these features on venous-phase cect images had very good performance for the discrimination between kimura disease and lymph node metastases in the head and neck.</td>\n",
       "      <td>[14 patients of head and, 38 enlarged lymph nodes and, 39 patients with head and, 39 enlarged lymph nodes confirmed, 10 days before biopsy or, 54 and testing set n, 23 in a ratio of, 7    , 7 features were screened out, 2 groups for all the, 0.759 to   , 0.915    , 0.970 in the training group, 0.977 in the testing group]</td>\n",
       "      <td>[analysis of 14, total of 38, nodes and 39, total of 39, cect within 10, n = 54, n = 23, ratio of 7, between the 2, ranging from 0.759, performance was 0.970, group and 0.977]</td>\n",
       "      <td>[14 patients of head and, 39 patients with head and]</td>\n",
       "      <td>[14.0, 39.0]</td>\n",
       "      <td>39.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[n = 54, n = 23]</td>\n",
       "      <td>[54.0, 23.0]</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25257</th>\n",
       "      <td>dyspnea effort and muscle pain during exercise in lung transplant recipients: an analysis of their association with cardiopulmonary function parameters using machine learning. despite improvement in lung function most lung transplant ltx recipients show an unexpectedly reduced exercise capacity that could be explained by persisting peripheral muscle dysfunction of multifactorial origin. we analyzed the course of symptoms including dyspnea muscle effort and muscle pain and its relation with cardiac and pulmonary function parameters during an incremental exercise testing.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56291</th>\n",
       "      <td>artificial intelligence estimates the importance of baseline factors in predicting response to anti-pd1 in metastatic melanoma. prognosis of patients with metastatic melanoma has dramatically improved over recent years because of the advent of antibodies targeting programmed cell death protein-1 pd1 . however the response rate is ~40% and baseline biomarkers for the outcome are yet to be identified. here we aimed to determine whether artificial intelligence might be useful in weighting the importance of baseline variables in predicting response to anti-pd1.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31541</th>\n",
       "      <td>a real-time depth of anesthesia monitoring system based on deep neural network with large edo tolerant eeg analog front-end. in this article we present a real-time electroencephalogram eeg based depth of anesthesia doa monitoring system in conjunction with a deep learning framework anesnet. an eeg analog front-end afe that can compensate ±380-mv electrode dc offset using a coarse digital dc servo loop is implemented in the proposed system. the eeg-based mac eegmac is introduced as a novel index to accurately predict the doa which is designed for applying to patients anesthetized by both volatile and intravenous agents. the proposed deep learning protocol consists of four layers of convolutional neural network and two dense layers. in addition we optimize the complexity of the deep neural network dnn to operate on a microcomputer such as the raspberry pi 3 realizing a cost-effective small-size doa monitoring system. fabricated in 110-nm cmos the prototype afe consumes 4.33 î¼w per channel and has the input-referred noise of 0.29 î¼vrms from 0.5 to 100 hz with the noise efficiency factor of 2.2. the proposed dnn was evaluated with pre-recorded eeg data from 374 subjects administrated by inhalational anesthetics under surgery achieving an average squared and absolute errors of 0.048 and 0.05 respectively. the eegmac with subjects anesthetized by an intravenous agent also showed a good agreement with the bispectral index value confirming the proposed doa index is applicable to both anesthetics. the implemented monitoring system with the raspberry pi 3 estimates the eegmac within 20 ms which is about thousand-fold faster than the bis estimation in literature.</td>\n",
       "      <td>[4 layers of convolutional neural, 2 dense layers  , 3 realizing a cost , 110    , 4.33    , 0.29    , 0.5 to   , 100 hz with the noise, 2.2    , 374 subjects administrated by inhalational, 0.048 and   , 0.05 respectively   , 3 estimates the eegmac within, 20 ms which is about]</td>\n",
       "      <td>[consists of 4, network and 2, raspberry pi 3, fabricated in 110, afe consumes 4.33, noise of 0.29, factor of 2.2, data from 374, errors of 0.048, raspberry pi 3, eegmac within 20]</td>\n",
       "      <td>[374 subjects administrated by inhalational]</td>\n",
       "      <td>[374.0]</td>\n",
       "      <td>374.0</td>\n",
       "      <td>[3 estimates the eegmac within]</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81580</th>\n",
       "      <td>diagnosis of multiple sclerosis from eeg signals using nonlinear methods. eeg signals have essential and important information about the brain and neural diseases. the main purpose of this study is classifying two groups of healthy volunteers and multiple sclerosis ms patients using nonlinear features of eeg signals while performing cognitive tasks. eeg signals were recorded when users were doing two different attentional tasks. one of the tasks was based on detecting a desired change in color luminance and the other task was based on detecting a desired change in direction of motion. eeg signals were analyzed in two ways: eeg signals analysis without rhythms decomposition and eeg sub-bands analysis. after recording and preprocessing time delay embedding method was used for state space reconstruction; embedding parameters were determined for original signals and their sub-bands. afterwards nonlinear methods were used in feature extraction phase. to reduce the feature dimension scalar feature selections were done by using t-test and bhattacharyya criteria. then the data were classified using linear support vector machines svm and k-nearest neighbor knn method. the best combination of the criteria and classifiers was determined for each task by comparing performances. for both tasks the best results were achieved by using t-test criterion and svm classifier. for the direction-based and the color-luminance-based tasks maximum classification performances were 93.08 and 79.79% respectively which were reached by using optimal set of features. our results show that the nonlinear dynamic features of eeg signals seem to be useful and effective in ms diseases diagnosis.</td>\n",
       "      <td>[2 groups of healthy volunteers, 2 different attentional tasks , 2 ways   , 93.08 and   , 79.79 percent respectively which were]</td>\n",
       "      <td>[is classifying 2, were doing 2, analyzed in 2, performances were 93.08]</td>\n",
       "      <td>[2 groups of healthy volunteers]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94910</th>\n",
       "      <td>non-invasive quantification of brain [¹¸f]-fdg uptake by combining medical health records and dynamic pet imaging data. quantification of regional cerebral metabolic rate of glucose rcmrglu via positron emission tomography pet imaging requires measuring the arterial input function aif via invasive arterial blood sampling. in this study we describe a non-invasive approach the non-invasive simultaneous estimation nsime for the estimation of rcmrglu that considers a pharmacokinetic input function model and constraints derived from machine learning applied to a fusion of individual medical health records and dynamic [ 18 f]-fdg-pet brain images data. the results obtained with our data indicate potential for future clinical application of nsime with correlation measures of 0.87 for rcmrglu compared to quantification with full arterial blood sampling.</td>\n",
       "      <td>[18 f   , 0.87 for rcmrglu compared to]</td>\n",
       "      <td>[measures of 0.87]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42824</th>\n",
       "      <td>adversarial representation learning for robust patient-independent epileptic seizure detection. epilepsy is a chronic neurological disorder characterized by the occurrence of spontaneous seizures which affects about one percent of the worlds population. most of the current seizure detection approaches strongly rely on patient history records and thus fail in the patient-independent situation of detecting the new patients. to overcome such limitation we propose a robust and explainable epileptic seizure detection model that effectively learns from seizure states while eliminates the inter-patient noises. a complex deep neural network model is proposed to learn the pure seizure-specific representation from the raw non-invasive electroencephalography eeg signals through adversarial training. furthermore to enhance the explainability we develop an attention mechanism to automatically learn the importance of each eeg channels in the seizure diagnosis procedure. the proposed approach is evaluated over the temple university hospital eeg tuh eeg database. the experimental results illustrate that our model outperforms the competitive state-of-the-art baselines with low latency. moreover the designed attention mechanism is demonstrated ables to provide fine-grained information for pathological analysis. we propose an effective and efficient patient-independent diagnosis approach of epileptic seizure based on raw eeg signals without manually feature engineering which is a step toward the development of large-scale deployment for real-life use.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143020</th>\n",
       "      <td>[possibility to reveal signs of occupational respiratory diseases through acoustic spiroanalyzer and probabilistic neuronal networks]. the authors described acoustic spiroanalyzer with data processing through probabilistic neuronal networks. application of the spiroanalyzer for respiratory diseases diagnosis proved possibility of occupational diseases identification: classification reliability was 78% for diseased and 77% for healthy miners.</td>\n",
       "      <td>[78 percent for diseased and, 77 percent for healthy miners]</td>\n",
       "      <td>[reliability was 78, diseased and 77]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78636</th>\n",
       "      <td>deep learning based classification of fdg-pet data for alzheimers disease categories. fluorodeoxyglucose fdg positron emission tomography pet measures the decline in the regional cerebral metabolic rate for glucose offering a reliable metabolic biomarker even on presymptomatic alzheimer's disease ad patients. pet scans provide functional information that is unique and unavailable using other types of imaging. however the computational efficacy of fdg-pet data alone for the classification of various alzheimers diagnostic categories has not been well studied. this motivates us to correctly discriminate various ad diagnostic categories using fdg-pet data. deep learning has improved state-of-the-art classification accuracies in the areas of speech signal image video text mining and recognition. we propose novel methods that involve probabilistic principal component analysis on max-pooled data and mean-pooled data for dimensionality reduction and multilayer feed forward neural network which performs binary classification. our experimental dataset consists of baseline data of subjects including 186 cognitively unimpaired cu subects 336 mild cognitive impairment mci subjects with 158 late mci and 178 early mci and 146 ad patients from alzheimer's disease neuroimaging initiative adni dataset. we measured f1-measure precision recall negative and positive predictive values with a 10-fold cross validation scheme. our results indicate that our designed classifiers achieve competitive results while max pooling achieves better classification performance compared to mean-pooled features. our deep model based research may advance fdg-pet analysis by demonstrating their potential as an effective imaging biomarker of ad.</td>\n",
       "      <td>[186 cognitively unimpaired cu subects, 336 mild cognitive impairment mci, 158 late mci and , 178 early mci and , 146 ad patients from alzheimer, 10    ]</td>\n",
       "      <td>[subjects including 186, cu subects 336, subjects with 158, mci and 178, mci and 146, with a 10]</td>\n",
       "      <td>[146 ad patients from alzheimer]</td>\n",
       "      <td>[146.0]</td>\n",
       "      <td>146.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68375</th>\n",
       "      <td>deep neural network improves fracture detection by clinicians. suspected fractures are among the most common reasons for patients to visit emergency departments eds and x-ray imaging is the primary diagnostic tool used by clinicians to assess patients for fractures. missing a fracture in a radiograph often has severe consequences for patients resulting in delayed treatment and poor recovery of function. nevertheless radiographs in emergency settings are often read out of necessity by emergency medicine clinicians who lack subspecialized expertise in orthopedics and misdiagnosed fractures account for upward of four of every five reported diagnostic errors in certain eds. in this work we developed a deep neural network to detect and localize fractures in radiographs. we trained it to accurately emulate the expertise of 18 senior subspecialized orthopedic surgeons by having them annotate 135409 radiographs. we then ran a controlled experiment with emergency medicine clinicians to evaluate their ability to detect fractures in wrist radiographs with and without the assistance of the deep learning model. the average clinician's sensitivity was 80.8% 95% ci 76.7-84.1% unaided and 91.5% 95% ci 89.3-92.9% aided and specificity was 87.5% 95 ci 85.3-89.5% unaided and 93.9% 95% ci 92.9-94.9% aided. the average clinician experienced a relative reduction in misinterpretation rate of 47.0% 95% ci 37.4-53.9% . the significant improvements in diagnostic accuracy that we observed in this study show that deep learning methods are a mechanism by which senior medical specialists can deliver their expertise to generalists on the front lines of medicine thereby providing substantial improvements to patient care.</td>\n",
       "      <td>[4 of every  , 5 reported diagnostic errors in, 18 senior subspecialized orthopedic surgeons, 135409 radiographs   , 80.8 percent   , 95 percent ci  , 76.7    , 91.5 percent   , 95 percent ci  , 89.3    , 87.5 percent   , 95 ci   , 85.3    , 93.9 percent   , 95 percent ci  , 92.9    , 47.0 percent   , 95 percent ci  , 37.4    ]</td>\n",
       "      <td>[upward of 4, of every 5, expertise of 18, them annotate 135409, sensitivity was 80.8, unaided and 91.5, specificity was 87.5, unaided and 93.9, rate of 47.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[135409 radiographs   ]</td>\n",
       "      <td>[135409.0]</td>\n",
       "      <td>135409.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>cycle-consistent generative adversarial network: effect on radiation dose reduction and image quality improvement in ultralow-dose ct for evaluation of pulmonary tuberculosis. to investigate the image quality of ultralow-dose ct uldct of the chest reconstructed using a cycle-consistent generative adversarial network cyclegan -based deep learning method in the evaluation of pulmonary tuberculosis.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14404</th>\n",
       "      <td>hybrid ensemble model for differential diagnosis between covid-19 and common viral pneumonia by chest x-ray radiograph. chest x-ray radiography cxr has been widely considered as an accessible feasible and convenient method to evaluate suspected patients' lung involvement during the covid-19 pandemic. however with the escalating number of suspected cases traditional diagnosis via cxr fails to deliver results within a short period of time. therefore it is crucial to employ artificial intelligence ai to enhance cxrs for obtaining quick and accurate diagnoses. previous studies have reported the feasibility of utilizing deep learning methods to screen for covid-19 using cxr and ct results. however these models only use a single deep learning network for chest radiograph detection; the accuracy of this approach required further improvement.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54623</th>\n",
       "      <td>validation of a cyclic algorithm to proxy number of lines of systemic cancer therapy using administrative data. researchers are automating the process for identifying the number of lines of systemic cancer therapy received by patients. to date algorithm development has involved manual modifications to predefined classification rules. in this study we propose a supervised learning algorithm for determining the best-performing proxy for number of lines of therapy and validate this approach in four patient groups.</td>\n",
       "      <td>[4 patient groups  ]</td>\n",
       "      <td>[approach in 4]</td>\n",
       "      <td>[4 patient groups  ]</td>\n",
       "      <td>[4.0]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16619</th>\n",
       "      <td>clinical outcome prediction from analysis of microelectrode recordings using deep learning in subthalamic deep brain stimulation for parkinson`s disease. deep brain stimulation dbs of the subthalamic nucleus stn is an effective treatment for improving the motor symptoms of advanced parkinson's disease pd . accurate positioning of the stimulation electrodes is necessary for better clinical outcomes.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29905</th>\n",
       "      <td>the eeg signal analysis for spatial cognitive ability evaluation based on multivariate permutation conditional mutual information-multi-spectral image. this study aims to find an effective method to evaluate the efficacy of cognitive training of spatial memory under a virtual reality environment by classifying the eeg signals of subjects in the early and late stages of spatial cognitive training. this study proposes a new eeg signal analysis method based on multivariate permutation conditional mutual information-multi-spectral image mpcmimsi . this method mainly considers the relationship between the coupled features of eeg signals in different channel pairs and transforms the multivariate permutation conditional mutual information features into multi-spectral images. then a convolutional neural networks cnn model classifies the resultant image data into different stages of cognitive training to objectively assess the efficacy of the training. compared to the multi-spectral image transformation method based on granger causality analysis gca and permutation conditional mutual information pcmi the mpcmimsi led to better classification performance which can be as high as 95% accuracy. more specifically the theta-beta2-gamma-band combination has the best accuracy. the proposed mpcmimsi method outperforms the multi-spectral image transformation methods based on gca and pcmi in terms of classification performance. the mpcmimsi feature in the theta-beta2-gamma band is an effective biomarker for assessing the efficacy of spatial memory training. the proposed eeg feature-extraction method based on mpcmimsi offers a new window to characterize spatial information of the noninvasive eeg recordings and might apply to assessing other brain functions.</td>\n",
       "      <td>[95 percent accuracy  ]</td>\n",
       "      <td>[high as 95]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44932</th>\n",
       "      <td>eyelid movement command classification using machine learning. the eyelid drive system eds is an assistive technology device intended to allow users to wirelessly control other devices such as power wheelchairs and personal computers using commands consisting only of blinking and winking. in this paper four machine learning classifiers are trained on data taken from one subject and validated offline on the training subject plus two additional subjects. the classifiers are assessed for accuracy computational and memory requirements and transferability from the \"training\" subject to the other two subjects. a support vector machine svm achieved the highest level of accuracy 97.5% while using a potentially prohibitive level of computational and memory resources. a logistic regression classifier also achieved excellent accuracy 96.5% while using two to three orders of magnitude fewer computational and memory resources than the svm.</td>\n",
       "      <td>[4 machine learning classifiers are, 2 subjects   , 97.5 percent while using a, 96.5 percent while using , 2 to   , 3 orders of magnitude fewer]</td>\n",
       "      <td>[this paper 4, the other 2, of accuracy 97.5, excellent accuracy 96.5, while using 2]</td>\n",
       "      <td>[2 subjects   ]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37654</th>\n",
       "      <td>real-time quality assessment of pediatric mri via semi-supervised deep nonlocal residual neural networks. in this paper we introduce an image quality assessment iqa method for pediatric t1- and t2-weighted mr images. iqa is first performed slice-wise using a nonlocal residual neural network nr-net and then volume-wise by agglomerating the slice qa results using random forest. our method requires only a small amount of quality-annotated images for training and is designed to be robust to annotation noise that might occur due to rater errors and the inevitable mix of good and bad slices in an image volume. using a small set of quality-assessed images we pre-train nr-net to annotate each image slice with an initial quality rating i.e. pass questionable fail which we then refine by semi-supervised learning and iterative self-training. experimental results demonstrate that our method trained using only samples of modest size exhibit great generalizability capable of real-time milliseconds per volume large-scale iqa with nearperfect accuracy.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143179</th>\n",
       "      <td>development of a computer-aided diagnostic scheme for detection of interval changes in successive whole-body bone scans. bone scintigraphy is the most frequent examination among various diagnostic nuclear medicine procedures. it is a well-established imaging modality for the diagnosis of osseous metastasis and for monitoring osseous tumor response to chemotherapy and radiation therapy. although the sensitivity of bone scan examinations for detection of bone abnormalities has been considered to be relatively high it is time consuming to identify multiple lesions such as bone metastases of prostate and breast cancers. in addition it is very difficult to detect subtle interval changes between two successive abnormal bone scans because of variations in patient conditions the accumulation of radioisotopes during each examination and the image quality of gamma cameras. therefore we developed a new computer-aided diagnostic cad scheme for the detection of interval changes in successive whole-body bone scans by use of a temporal subtraction image which was obtained with a nonlinear image-warping technique. we carried out 58 pairs of successive bone scans in which each scan included both posterior and anterior views. we determined 107 \"gold-standard\" interval changes among the 58 pairs based on the consensus of three radiologists. our computerized scheme consisted of seven steps i.e. initial image density normalization on each image image matching for the paired images temporal subtraction by use of the nonlinear image-warping technique initial detection of interval changes by use of temporal-subtraction images image feature extraction of candidates of interval changes rule-based tests by use of 16 image features for removing some false positives and display of the computer output for identified interval changes. one hundred seven gold standard interval changes included 71 hot lesions uptake was increased compared with the previous scan or there was new uptake in the current scan and 36 cold lesions uptake was decreased or disappeared for anterior and posterior views. the overall sensitivity in the detection of interval changes including both hot and cold lesions evaluated by use of the resubstitution and the leave-one-case-out methods were 95.3% with 5.97 false positives per view and 83.2% with 6.02 respectively. the temporal subtraction image for successive whole-body bone scans has the potential to enhance the interval changes between two images which also can be quantified. furthermore the cad scheme for the detection of interval changes by use of temporal subtraction images would be useful in assisting radiologists' interpretation on successive bone scan images.</td>\n",
       "      <td>[2 successive abnormal bone scans, 58 pairs of successive bone, 107    , 58 pairs based on the, 3 radiologists   , 7 steps i  , 16 image features for removing, 107 gold standard interval changes, 71 hot lesions uptake was, 36 cold lesions uptake was, 95.3 percent with  , 5.97 false positives per view, 83.2 percent with  , 6.02 respectively   , 2 images which also can]</td>\n",
       "      <td>[changes between 2, carried out 58, we determined 107, among the 58, consensus of 3, consisted of 7, use of 16, changes included 71, scan and 36, methods were 95.3, view and 83.2, changes between 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2 successive abnormal bone scans, 3 radiologists   , 16 image features for removing, 2 images which also can]</td>\n",
       "      <td>[2.0, 3.0, 16.0, 2.0]</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56109</th>\n",
       "      <td>introducing machine learning to detect personality faking-good in a male sample: a new model based on minnesota multiphasic personality inventory-2 restructured form scales and reaction times. background and purpose. the use of machine learning ml models in the detection of malingering has yielded encouraging results showing promising accuracy levels. we investigated the possible application of this methodology when trained on behavioral features such as response time rt and time pressure to identify faking behavior in self-report personality questionnaires. to do so we reintroduced the article of roma et al. 2018 which highlighted that rts and time pressure are useful variables in the detection of faking; we then extended the number of participants and applied an ml analysis. materials and methods. the sample was composed of 175 subjects of whom all were graduates having completed at least 17 years of instruction male and caucasian. subjects were randomly assigned to four groups: honest speeded faking-good speeded honest unspeeded and faking-good unspeeded. a software version of the minnesota multiphasic personality inventory-2 restructured form mmpi-2-rf was administered. results. results indicated that ml algorithms reached very high accuracies around 95% in detecting malingerers when subjects are instructed to respond under time pressure. the classifiers' performance was lower when the subjects responded with no time restriction to the mmpi-2-rf items with accuracies ranging from 75% to 85%. further analysis demonstrated that t-scores of validity scales are ineffective to detect fakers when participants were not under temporal pressure accuracies 55-65% whereas temporal features resulted to be more useful accuracies 70-75% . by contrast temporal features and t-scores of validity scales are equally effective in detecting fakers when subjects are under time pressure accuracies higher than 90% . discussion. to conclude results demonstrated that ml techniques are extremely valuable and reach high performance in detecting fakers in self-report personality questionnaires over more the traditional psychometric techniques. validity scales mmpi-2-rf manual criteria are very poor in identifying under-reported profiles. moreover temporal measures are useful tools in distinguishing honest from dishonest responders especially in a no time pressure condition. indeed time pressure brings out malingerers in clearer way than does no time pressure condition.</td>\n",
       "      <td>[2018 which highlighted that rts, 175 subjects of whom all, 17 years of instruction male, 4 groups   , 95 percent in detecting malingerers, 75 percent to  , 85 percent   , 55    , 70    , 90 percent   ]</td>\n",
       "      <td>[composed of 175, at least 17, assigned to 4, accuracies around 95, ranging from 75, pressure accuracies 55, useful accuracies 70, higher than 90]</td>\n",
       "      <td>[175 subjects of whom all, 17 years of instruction male]</td>\n",
       "      <td>[175.0, 17.0]</td>\n",
       "      <td>175.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35773</th>\n",
       "      <td>diagnosis of asthma based on routine blood biomarkers using machine learning. intelligent medical diagnosis has become common in the era of big data although this technique has been applied to asthma only in limited contexts. using routine blood biomarkers to identify asthma patients would make clinical diagnosis easier to implement and would enhance research of key asthma variables through data mining techniques. we used routine blood data from healthy individuals to construct a mahalanobis space ms . then we calculated mahalanobis distances of the training routine blood data from 355 asthma patients and 1480 healthy individuals to ensure the efficiency of ms. orthogonal arrays and signal-to-noise ratios were used to optimize blood biomarker variables. receiver operating characteristic roc curve was used to determine the threshold value. ultimately we validated the system on 182 individuals based on the threshold value. out of 35 patients with asthma mts correctly classified 94.15% of patients. in addition 97.20% of 147 healthy individuals were correctly classified. the system isolated 7 routine blood biomarkers. among these biomarkers platelet distribution width mean platelet volume white blood cell count eosinophil count and lymphocyte ratio performed well in asthma diagnosis. in brief mts shows promise as an accurate method to identify asthma patients based on 7 vital blood biomarker variables and threshold determined by the roc curve thus offering the potential to simplify diagnostic complexity and optimize clinical efficiency.</td>\n",
       "      <td>[355 asthma patients and , 1480 healthy individuals to ensure, 182 individuals based on the, 35 patients with asthma mts, 94.15 percent of patients , 97.20 percent of  , 147 healthy individuals were correctly, 7 routine blood biomarkers , 7 vital blood biomarker variables]</td>\n",
       "      <td>[data from 355, patients and 1480, system on 182, out of 35, correctly classified 94.15, in addition 97.20, system isolated 7, based on 7]</td>\n",
       "      <td>[355 asthma patients and , 1480 healthy individuals to ensure, 182 individuals based on the, 35 patients with asthma mts, 147 healthy individuals were correctly]</td>\n",
       "      <td>[355.0, 1480.0, 182.0, 35.0, 147.0]</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117887</th>\n",
       "      <td>artificial neural networks based early clinical prediction of mortality after spontaneous intracerebral hemorrhage. numerous outcome prediction models have been developed for mortality and functional outcome after spontaneous intracerebral haemorrhage ich . however no outcome prediction model for ich has considered the impact of care restriction. to develop and compare results of the artificial neural networks ann and logistic regression lr models based on initial clinical parameters for prediction of mortality after spontaneous ich. analysis has been conducted on consecutive dataset of patients with spontaneous ich over 5-year period in tertiary care academic hospital. patients older than 18 years were eligible for inclusion if they had been presented within 6 h from the start of symptoms and had evidence of spontaneous supratentorial ich on initial brain computed tomography within 24 h. initial clinical parameters have been used to develop lr and ann prediction models for hospital mortality as outcome measure. models have been accessed for discrimination and calibration abilities. we have analyzed 411 patients 199 males and 212 females with spontaneous ich medically treated and not withdrawn from therapy with average age of 67.35 years. from them 256 62.29% patients died during hospital treatment and 155 37.71% patients survived. in the observed dataset ann model overall correctly classified outcome in 93.55% of patients compared with 79.32% of correct classification for the lr model. discrimination and calibration parameters indicate that both models show an adequate fit of expected and observed values with superiority of ann model. our results favour the ann model for prediction of mortality after spontaneous ich. further studies of the strengths and limitations of this method are needed with larger prospective samples.</td>\n",
       "      <td>[5    , 18 years were eligible for, 6 h from the start, 24 h   , 411 patients   , 199 males and  , 212 females with spontaneous ich, 67.35 years   , 256    , 62.29 percent patients died during, 155    , 37.71 percent patients survived , 93.55 percent of patients compared, 79.32 percent of correct classification]</td>\n",
       "      <td>[ich over 5, older than 18, presented within 6, tomography within 24, have analyzed 411, males and 212, age of 67.35, from them 256, treatment and 155, outcome in 93.55, compared with 79.32]</td>\n",
       "      <td>[411 patients   , 199 males and  , 212 females with spontaneous ich]</td>\n",
       "      <td>[411.0, 199.0, 212.0]</td>\n",
       "      <td>411.0</td>\n",
       "      <td>[212 females with spontaneous ich]</td>\n",
       "      <td>[212.0]</td>\n",
       "      <td>212.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>low-dose ct urography using deep learning image reconstruction: a prospective study for comparison with conventional ct urography. to compare the image quality of low-dose ct urography ld-ctu using deep learning image reconstruction dlir with conventional ctu c-ctu using adaptive statistical iterative reconstruction asir-v .</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48648</th>\n",
       "      <td>a hybrid model for eeg-based gender recognition. the gender recognition is an important research field to study evidence regarding some personal characteristics in the information and data society. however some current traditional methods such as vision and sound have been exposed their own security weaknesses. recently biometric gender recognition based on electroencephalography eeg signals has been widely used in information safety and medical fields. it is necessary to explore potential of using eeg to present a more robust and accurate result with larger training data based on sophisticated machine learning approaches. in this contribution we present an automated gender recognition system by a hybrid model based on eeg data of resting state from twenty-eight subjects. these data are useful and handy to get insights into assessing the differences in personal gender. for achieving a good performance and a strong robustness the system develops a hybrid model of combining random forest and logistic regression and employs four common entropy measures to analyze the non-stationary eeg signals. result also suggests that the recognition performance achieve an improved progress with an accuracy of 0.9982 and auc of 0.9926 based on a nested tenfold cross-validation loop implying that show a significant potential applicability of the proposed approach and is capable of recognizing personal gender.</td>\n",
       "      <td>[28 subjects   , 4 common entropy measures to, 0.9982 and auc of , 0.9926 based on a nested]</td>\n",
       "      <td>[state from 28, and employs 4, accuracy of 0.9982, auc of 0.9926]</td>\n",
       "      <td>[28 subjects   ]</td>\n",
       "      <td>[28.0]</td>\n",
       "      <td>28.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37039</th>\n",
       "      <td>a cnn-lstm neural network for recognition of puffing in smoking episodes using wearable sensors. a detailed assessment of smoking behavior under free-living conditions is a key challenge for health behavior research. a number of methods using wearable sensors and puff topography devices have been developed for smoking and individual puff detection. in this paper we propose a novel algorithm for automatic detection of puffs in smoking episodes by using a combination of respiratory inductance plethysmography and inertial measurement unit sensors. the detection of puffs was performed by using a deep network containing convolutional and recurrent neural networks. convolutional neural networks cnn were utilized to automate feature learning from raw sensor streams. long short term memory lstm network layers were utilized to obtain the temporal dynamics of sensor signals and classify sequence of time segmented sensor streams. an evaluation was performed by using a large challenging dataset containing 467 smoking events from 40 participants under free-living conditions. the proposed approach achieved an f1-score of 78% in leave-one-subject-out cross-validation. the results suggest that cnn-lstm based neural network architecture sufficiently detect puffing episodes in free-living condition. the proposed model be used as a detection tool for smoking cessation programs and scientific research.</td>\n",
       "      <td>[467 smoking events from , 40 participants under free , 78 percent in leave ]</td>\n",
       "      <td>[dataset containing 467, events from 40]</td>\n",
       "      <td>[40 participants under free ]</td>\n",
       "      <td>[40.0]</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104650</th>\n",
       "      <td>brain state differentiation and behavioral inflexibility in autism. autism spectrum disorders asds are characterized by social impairments alongside cognitive and behavioral inflexibility. while social deficits in asds have extensively been characterized the neurobiological basis of inflexibility and its relation to core clinical symptoms of the disorder are unknown. we acquired functional neuroimaging data from 2 cohorts each consisting of 17 children with asds and 17 age- and iq-matched typically developing td children during stimulus-evoked brain states involving performance of social attention and numerical problem solving tasks as well as during intrinsic resting brain states. effective connectivity between key nodes of the salience network default mode network and central executive network was used to obtain indices of functional organization across evoked and intrinsic brain states. in both cohorts examined a machine learning algorithm was able to discriminate intrinsic resting and evoked task functional brain network configurations more accurately in td children than in children with asd. brain state discriminability was related to severity of restricted and repetitive behaviors indicating that weak modulation of brain states may contribute to behavioral inflexibility in asd. these findings provide novel evidence for a potential link between neurophysiological inflexibility and core symptoms of this complex neurodevelopmental disorder.</td>\n",
       "      <td>[2 cohorts each consisting of, 17 children with asds and, 17 age   ]</td>\n",
       "      <td>[data from 2, consisting of 17, asds and 17]</td>\n",
       "      <td>[17 children with asds and]</td>\n",
       "      <td>[17.0]</td>\n",
       "      <td>17.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56998</th>\n",
       "      <td>identification of 17 mrnas and a mirna as an integrated prognostic signature for lung squamous cell carcinoma. gene signatures for predicting the outcome of lung squamous cell carcinoma lusc have been employed for many years. however various signatures have been applied in clinical practice. therefore in the present study we aimed to filter out an effective lusc prognostic gene signature by simultaneously integrating mrna and microrna mirna .</td>\n",
       "      <td>[17 mrnas and a mirna]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>texture analysis of muscle mri: machine learning-based classifications in idiopathic inflammatory myopathies. to develop a machine learning ml model that predicts disease groups or autoantibodies in patients with idiopathic inflammatory myopathies iims using muscle mri radiomics features. twenty-two patients with dermatomyositis dm 14 with amyopathic dermatomyositis adm 19 with polymyositis pm and 19 with non-iim were enrolled. using 2d manual segmentation 93 original features as well as 93 local binary pattern lbp features were extracted from mri short-tau inversion recovery [stir] imaging of proximal limb muscles. to construct and compare ml models that predict disease groups using each set of features dimensional reductions were performed using a reproducibility analysis by inter-reader and intra-reader correlation coefficients collinearity analysis and the sequential feature selection sfs algorithm. models were created using the linear discriminant analysis lda quadratic discriminant analysis qda support vector machine svm k-nearest neighbors k-nn random forest rf and multi-layer perceptron mlp classifiers and validated using tenfold cross-validation repeated 100 times. we also investigated whether it was possible to construct models predicting autoantibody status. our ml-based mri radiomics models showed the potential to distinguish between pm dm and adm. models using lbp features provided better results with macro-average auc values of 0.767 and 0.714 accuracy of 61.2 and 61.4% and macro-average recall of 61.9 and 59.8% in the lda and k-nn classifiers respectively. in contrast the accuracies of radiomics models distinguishing between non-iim and iim disease groups were low. a subgroup analysis showed that classification models for anti-jo-1 and anti-ars antibodies provided auc values of 0.646-0.853 and 0.692-0.792 with accuracy of 71.5-81.0 and 65.8-78.3% respectively. ml-based ta of muscle mri may be used to predict disease groups or the autoantibody status in patients with iim and is useful in non-invasive assessments of disease mechanisms.</td>\n",
       "      <td>[22 patients with dermatomyositis dm, 14 with amyopathic dermatomyositis adm, 19 with polymyositis pm and, 19 with non  , 2 d manual segmentation , 93 original features as well, 93 local binary pattern lbp, 100 times   , 0.767 and   , 0.714 accuracy of  , 61.2 and   , 61.4 percent and macro , 61.9 and   , 59.8 percent in the lda, 0.646    , 0.692    , 71.5    , 65.8    ]</td>\n",
       "      <td>[dermatomyositis dm 14, dermatomyositis adm 19, pm and 19, manual segmentation 93, well as 93, values of 0.767, accuracy of 61.2, recall of 61.9, values of 0.646, accuracy of 71.5]</td>\n",
       "      <td>[22 patients with dermatomyositis dm]</td>\n",
       "      <td>[22.0]</td>\n",
       "      <td>22.0</td>\n",
       "      <td>[14 with amyopathic dermatomyositis adm]</td>\n",
       "      <td>[14.0]</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67625</th>\n",
       "      <td>predicting drug-resistant epilepsy - a machine learning approach based on administrative claims data. patients with drug-resistant epilepsy dre are at high risk of morbidity and mortality yet their referral to specialist care is frequently delayed. the ability to identify patients at high risk of dre at the time of treatment initiation and to subsequently steer their treatment pathway toward more personalized interventions has high clinical utility. here we aim to demonstrate the feasibility of developing algorithms for predicting dre using machine learning methods. longitudinal intersected data sourced from us pharmacy medical and adjudicated hospital claims from 1376756 patients from 2006 to 2015 were analyzed; 292892 met inclusion criteria for epilepsy and 38382 were classified as having dre using a proxy measure for drug resistance. patients were characterized using 1270 features reflecting demographics comorbidities medications procedures epilepsy status and payer status. data from 175735 randomly selected patients were used to train three algorithms and from the remainder to assess the trained models' predictive power. a model with only age and sex was used as a benchmark. the best model random forest achieved an area under the receiver operating characteristic curve 95% confidence interval [ci] of 0.764 0.759 0.770 compared with 0.657 0.651 0.663 for the benchmark model. moreover predicted probabilities for dre were well-calibrated with the observed frequencies in the data. the model predicted drug resistance approximately 2¯years before patients in the test dataset had failed two antiepileptic drugs aeds . machine learning models constructed using claims data predicted which patients are likely to fail ¥3 aeds and are at risk of developing dre at the time of the first aed prescription. the use of such models can ensure that patients with predicted dre receive specialist care with potentially more aggressive therapeutic interventions from diagnosis to help reduce the serious sequelae of dre.</td>\n",
       "      <td>[1376756 patients from  , 2006 to   , 2015 were analyzed  , 292892 met inclusion criteria for, 38382 were classified as having, 1270 features reflecting demographics comorbidities, 175735 randomly selected patients were, 3 algorithms and from the, 95 percent confidence interval , 0.764    , 0.759    , 0.770 compared with  , 0.657    , 0.651    , 0.663 for the benchmark model, 2    , 2 antiepileptic drugs aeds ]</td>\n",
       "      <td>[claims from 1376756, patients from 2006, epilepsy and 38382, characterized using 1270, data from 175735, to train 3, characteristic curve 95, compared with 0.657, resistance approximately 2, had failed 2]</td>\n",
       "      <td>[1376756 patients from  , 175735 randomly selected patients were]</td>\n",
       "      <td>[1376756.0, 175735.0]</td>\n",
       "      <td>1376756.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47003</th>\n",
       "      <td>utilizing machine learning for image quality assessment for reflectance confocal microscopy. in vivo reflectance confocal microscopy rcm enables clinicians to examine lesions' morphological and cytological information in epidermal and dermal layers while reducing the need for biopsies. as rcm is being adopted more widely the workflow is expanding from real-time diagnosis at the bedside to include a capture store and forward model with image interpretation and diagnosis occurring offsite similar to radiology. as the patient may no longer be present at the time of image interpretation quality assurance is key during image acquisition. herein we introduce a quality assurance process by means of automatically quantifying diagnostically uninformative areas within the lesional area by using rcm and coregistered dermoscopy images together. we trained and validated a pixel-level segmentation model on 117 rcm mosaics collected by international collaborators. the model delineates diagnostically uninformative areas with 82% sensitivity and 93% specificity. we further tested the model on a separate set of 372 coregistered rcm-dermoscopic image pairs and illustrate how the results of the rcm-only model can be improved via a multimodal rcm  dermoscopy approach which can help quantify the uninformative regions within the lesional area. our data suggest that machine learning-based automatic quantification offers a feasible objective quality control measure for rcm imaging.</td>\n",
       "      <td>[117 rcm mosaics collected by, 82 percent sensitivity and , 93 percent specificity  , 372 coregistered rcm  ]</td>\n",
       "      <td>[model on 117, areas with 82, sensitivity and 93, set of 372]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71310</th>\n",
       "      <td>tumor identification in colorectal histology images using a convolutional neural network. colorectal cancer crc is a major global health concern. its early diagnosis is extremely important as it determines treatment options and strongly influences the length of survival. histologic diagnosis can be made by pathologists based on images of tissues obtained from a colonoscopic biopsy. convolutional neural networks cnns -i.e. deep neural networks dnns specifically adapted to image data-have been employed to effectively classify or locate tumors in many types of cancer. colorectal histology images of 28 normal and 29 tumor samples were obtained from the national cancer center south korea and cropped into 6806 normal and 3474 tumor images. we developed five modifications of the system from the visual geometry group vgg the winning entry in the classification task in the 2014 imagenet large scale visual recognition competition ilsvrc and examined them in two experiments. in the first experiment we determined the best modified vgg configuration for our partial dataset resulting in accuracies of 82.50% 87.50% 87.50% 91.40% and 94.30% respectively. in the second experiment the best modified vgg configuration was applied to evaluate the performance of the cnn model. subsequently using the entire dataset on the modified vgg-e configuration the highest results for accuracy loss sensitivity and specificity respectively were 93.48% 0.4385 95.10% and 92.76% which equates to correctly classifying 294 normal images out of 309 and 667 tumor images out of 719.</td>\n",
       "      <td>[28 normal and  , 29 tumor samples were obtained, 6806 normal and  , 3474 tumor images  , 5 modifications of the system, 2014 imagenet large scale visual, 2 experiments   , 82.50 percent   , 87.50 percent   , 87.50 percent   , 91.40 percent and  , 94.30 percent respectively  , 93.48 percent   , 0.4385    , 95.10 percent and  , 92.76 percent which equates to, 294 normal images out of, 309 and   , 667 tumor images out of, 719    ]</td>\n",
       "      <td>[images of 28, normal and 29, cropped into 6806, normal and 3474, we developed 5, in the 2014, them in 2, accuracies of 82.50, respectively were 93.48, correctly classifying 294, out of 309, out of 719]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[29 tumor samples were obtained, 3474 tumor images  , 2014 imagenet large scale visual, 2014 imagenet large scale visual, 294 normal images out of, 667 tumor images out of]</td>\n",
       "      <td>[29.0, 3474.0, 2014.0, 2014.0, 294.0, 667.0]</td>\n",
       "      <td>3474.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114768</th>\n",
       "      <td>automated detection of instantaneous gait events using time frequency analysis and manifold embedding. accelerometry is a widely used sensing modality in human biomechanics due to its portability non-invasiveness and accuracy. however difficulties lie in signal variability and interpretation in relation to biomechanical events. in walking heel strike and toe off are primary gait events where robust and accurate detection is essential for gait-related applications. this paper describes a novel and generic event detection algorithm applicable to signals from tri-axial accelerometers placed on the foot ankle shank or waist. data from healthy subjects undergoing multiple walking trials on flat and inclined as well as smooth and tactile paving surfaces is acquired for experimentation. the benchmark timings at which heel strike and toe off occur are determined using kinematic data recorded from a motion capture system. the algorithm extracts features from each of the acceleration signals using a continuous wavelet transform over a wide range of scales. a locality preserving embedding method is then applied to reduce the high dimensionality caused by the multiple scales while preserving salient features for classification. a simple gaussian mixture model is then trained to classify each of the time samples into heel strike toe off or no event categories. results show good detection and temporal accuracies for different sensor locations and different walking terrains.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37681</th>\n",
       "      <td>augmented deep learning model for improved quantitative accuracy of mr-based pet attenuation correction in psma pet-mri prostate imaging. estimation of accurate attenuation maps for whole-body positron emission tomography pet imaging in simultaneous pet-mri systems is a challenging problem as it affects the quantitative nature of the modality. in this study we aimed to improve the accuracy of estimated attenuation maps from mri dixon contrast images by training an augmented generative adversarial network gans in a supervised manner. we augmented the gans by perturbing the non-linear deformation field during image registration between mri and the ground truth ct images.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68343</th>\n",
       "      <td>optimizing immune cell therapies with artificial intelligence. we determine an optimal injection pattern for anti-vascular endothelial growth factor vegf and for the combination of anti-vegf and unlicensed dendritic cells.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47109</th>\n",
       "      <td>usefulness of regional right ventricular and right atrial strain for prediction of early and late right ventricular failure following a left ventricular assist device implant: a machine learning approach. identifying candidates for left ventricular assist device surgery at risk of right ventricular failure remains difficult. the aim was to identify the most accurate predictors of right ventricular failure among clinical biological and imaging markers assessed by agreement of different supervised machine learning algorithms.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138233</th>\n",
       "      <td>ischemia detection with a self-organizing map supplemented by supervised learning. the problem of maximizing the performance of the detection of ischemia episodes is a difficult pattern classification problem. the motivation for developing the supervising network self-organizing map snet-som model is to exploit this fact for designing computationally effective solutions both for the particular ischemic detection problem and for other applications that share similar characteristics. specifically the snet-som utilizes unsupervised learning for the \"simple\" regions and supervised for the \"difficult\" ones in a two stage learning process. the unsupervised learning approach extends and adapts the self-organizing map som algorithm of kohonen. the basic som is modified with a dynamic expansion process controlled with an entropy based criterion that allows the adaptive formation of the proper som structure. this extension proceeds until the total number of training patterns that are mapped to neurons with high entropy reduces to a size manageable numerically with a capable supervised model. the second learning phase has the objective of constructing better decision boundaries at the ambiguous regions. at this phase a special supervised network is trained for the computationally reduced task of performing the classification at the ambiguous regions only. the utilization of snet-som with supervised learning based on the radial basis functions and support vector machines has resulted in an improved accuracy of ischemia detection especially in the last case. the highly disciplined design of the generalization performance of the support vector machine allows designing the proper model for the number of patterns transferred to the supervised expert.</td>\n",
       "      <td>[2 stage learning process ]</td>\n",
       "      <td>[in a 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48230</th>\n",
       "      <td>machine learning techniques applied to dose prediction in computed tomography tests. increasingly more patients exposed to radiation from computed axial tomography ct will have a greater risk of developing tumors or cancer that are caused by cell mutation in the future. a minor dose level would decrease the number of these possible cases. however this framework can result in medical specialists radiologists not being able to detect anomalies or lesions. this work explores a way of addressing these concerns achieving the reduction of unnecessary radiation without compromising the diagnosis. we contribute with a novel methodology in the ct area to predict the precise radiation that a patient should be given to accomplish this goal. specifically from a real dataset composed of the dose data of over fifty thousand patients that have been classified into standardized protocols skull abdomen thorax pelvis etc. we eliminate atypical information outliers to later generate regression curves employing diverse well-known machine learning techniques. as a result we have chosen the best analytical technique per protocol; a selection that was thoroughly carried out according to traditional dosimetry parameters to accurately quantify the dose level that the radiologist should apply in each ct test.</td>\n",
       "      <td>[50000 patients that have been]</td>\n",
       "      <td>[of over 50000]</td>\n",
       "      <td>[50000 patients that have been]</td>\n",
       "      <td>[50000.0]</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19333</th>\n",
       "      <td>a deep learning system for synthetic knee magnetic resonance imaging: is artificial intelligence-based fat-suppressed imaging feasible? this single-center study was approved by the institutional review board. artificial intelligence-based fs mri scans were created from non-fs images using a deep learning system with a modified convolutional neural network-based u-net that used a training set of 25920 images and validation set of 16416 images. three musculoskeletal radiologists reviewed 88 knee mr studies in 2 sessions the original proton density [pd] fspd and the synthetic pd afsmri . readers recorded afsmri quality diagnostic/nondiagnostic and the presence or absence of meniscal ligament and tendon tears; cartilage defects; and bone marrow abnormalities. contrast-to-noise rate measurements were made among subcutaneous fat fluid bone marrow cartilage and muscle. the original mri sequences were used as the reference standard to determine the diagnostic performance of afsmri combined with the original pd sequence . this is a fully balanced study design where all readers read all images the same number of times which allowed the determination of the interchangeability of the original and synthetic protocols. descriptive statistics intermethod agreement interobserver concordance and interchangeability tests were applied. a p value less than 0.01 was considered statistically significant for the likelihood ratio testing and p value less than 0.05 for all other statistical analyses.</td>\n",
       "      <td>[25920 images and validation set, 16416 images   , 3 musculoskeletal radiologists reviewed , 88 knee mr studies in, 2 sessions the original proton, 0.01 was considered statistically significant, 0.05 for all other statistical]</td>\n",
       "      <td>[set of 25920, set of 16416, radiologists reviewed 88, studies in 2, less than 0.01, less than 0.05]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[25920 images and validation set, 16416 images   , 3 musculoskeletal radiologists reviewed ]</td>\n",
       "      <td>[25920.0, 16416.0, 3.0]</td>\n",
       "      <td>25920.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91122</th>\n",
       "      <td>automated classification of epiphyses in the distal radius and ulna using a support vector machine. the aim of this study was to automatically classify epiphyses in the distal radius and ulna using a support vector machine svm and to examine the accuracy of the epiphyseal growth grades generated by the support vector machine. x-ray images of distal radii and ulnae were collected from 140 chinese teenagers aged between 11.0 and 19.0 years. epiphyseal growth of the two elements was classified into five grades. features of each element were extracted using a histogram of oriented gradient hog and models were established using support vector classification svc . the prediction results and the validity of the models were evaluated with a cross-validation test and independent test for accuracy pa . our findings suggest that this new technique for epiphyseal classification was successful and that an automated technique using an svm is reliable and feasible with a relative high accuracy for the models.</td>\n",
       "      <td>[140 chinese teenagers aged between, 11.0 and   , 19.0 years   , 2 elements was classified into, 5 grades   ]</td>\n",
       "      <td>[collected from 140, aged between 11.0, of the 2, classified into 5]</td>\n",
       "      <td>[140 chinese teenagers aged between]</td>\n",
       "      <td>[140.0]</td>\n",
       "      <td>140.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50196</th>\n",
       "      <td>[heartbeat-based end-to-end classification of arrhythmias]. we propose a heartbeat-based end-to-end classification of arrhythmias to improve the classification performance for supraventricular ectopic beat sveb and ventricular ectopic beat veb .</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26004</th>\n",
       "      <td>antibiotic treatment response in chronic lyme disease: why do some patients improve while others do not? there is considerable uncertainty regarding treatment of lyme disease patients who do not respond fully to initial short-term antibiotic therapy. choosing the best treatment approach and duration remains challenging because treatment response among these patients varies: some patients improve with treatment while others do not. a previous study examined treatment response variation in a sample of over 3500 patients enrolled in the mylymedata patient registry developed by lymedisease.org san ramon ca usa . that study used a validated global rating of change groc scale to identify three treatment response subgroups among lyme disease patients who remained ill: nonresponders low responders and high responders. the present study first characterizes the health status symptom severity and percentage of treatment response across these three patient subgroups together with a fourth subgroup patients who identify as well. we then employed machine learning techniques across these subgroups to determine features most closely associated with improved patient outcomes and we used traditional statistical techniques to examine how these features relate to treatment response of the four groups. high treatment response was most closely associated with 1 the use of antibiotics or a combination of antibiotics and alternative treatments 2 longer duration of treatment and 3 oversight by a clinician whose practice focused on the treatment of tick-borne diseases.</td>\n",
       "      <td>[3500 patients enrolled in the, 3 treatment response subgroups among, 3 patient subgroups together with, 4 th subgroup patients who, 4 groups   , 1 the use of antibiotics, 2 longer duration of treatment, 3 oversight by a clinician]</td>\n",
       "      <td>[of over 3500, to identify 3, across these 3, with a 4, of the 4, associated with 1, alternative treatments 2, treatment and 3]</td>\n",
       "      <td>[3500 patients enrolled in the, 3 patient subgroups together with, 4 th subgroup patients who]</td>\n",
       "      <td>[3500.0, 3.0, 4.0]</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>deephbv: a deep learning model to predict hepatitis b virus hbv integration sites. the hepatitis b virus hbv is one of the main causes of viral hepatitis and liver cancer. hbv integration is one of the key steps in the virus-promoted malignant transformation.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61442</th>\n",
       "      <td>risk stratification for short-term mortality at hospital admission for acute exacerbations of copd. exacerbations of chronic obstructive pulmonary disease ecopd are associated with increased in-hospital and short-term mortality. developing an easy-to-use model to predict adverse outcomes will be useful in daily clinical practice and will facilitate management decisions. we aimed to assess mortality rates and potential predictors for short-term mortality after severe ecopd. classification and regression tree cart model was used to identify predictors of adverse outcome.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139902</th>\n",
       "      <td>electrooculogram based system for computer control using a multiple feature classification model. this paper discusses the creation of a system for computer-aided communication through automated analysis and processing of electrooculogram signals. in situations of disease or trauma there may be an inability to communicate with others through standard means such as speech or typing. eye movement tends to be one of the last remaining active muscle capabilities for people with neurodegenerative disorders such as amyotrophic lateral sclerosis als also known as lou gehrig's disease. thus there is a need for eye movement based systems to enable communication. to meet this need the telepathix system was designed to accept eye movement commands denoted by looking to the left looking to the right and looking straight ahead to navigate a virtual keyboard. using a ternary virtual keyboard layout and a multiple feature classification model a typing speed of 6 letters per minute was achieved.</td>\n",
       "      <td>[6 letters per minute was]</td>\n",
       "      <td>[speed of 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29323</th>\n",
       "      <td>predicting covid-19 pneumonia severity on chest x-ray with deep learning. introduction the need to streamline patient management for coronavirus disease-19 covid-19 has become more pressing than ever. chest x-rays cxrs provide a non-invasive potentially bedside tool to monitor the progression of the disease. in this study we present a severity score prediction model for covid-19 pneumonia for frontal chest x-ray images. such a tool can gauge the severity of covid-19 lung infections and pneumonia in general that can be used for escalation or de-escalation of care as well as monitoring treatment efficacy especially in the icu. methods images from a public covid-19 database were scored retrospectively by three blinded experts in terms of the extent of lung involvement as well as the degree of opacity. a neural network model that was pre-trained on large non-covid-19 chest x-ray datasets is used to construct features for covid-19 images which are predictive for our task. results this study finds that training a regression model on a subset of the outputs from this pre-trained chest x-ray model predicts our geographic extent score range 0-8 with 1.14 mean absolute error mae and our lung opacity score range 0-6 with 0.78 mae. conclusions these results indicate that our model's ability to gauge the severity of covid-19 lung infections could be used for escalation or de-escalation of care as well as monitoring treatment efficacy especially in the icu. to enable follow up work we make our code labels and data available online.</td>\n",
       "      <td>[3 blinded experts in terms, 0    , 1.14 mean absolute error mae, 0    , 0.78 mae   ]</td>\n",
       "      <td>[retrospectively by 3, score range 0, score range 0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13910</th>\n",
       "      <td>evaluating performance of eeg data-driven machine learning for traumatic brain injury classification. big data analytics can potentially benefit the assessment and management of complex neurological conditions by extracting information that is difficult to identify manually. in this study we evaluated the performance of commonly used supervised machine learning algorithms in the classification of patients with traumatic brain injury tbi history from those with stroke history and/or normal eeg.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13923</th>\n",
       "      <td>deep learning whole-gland and zonal prostate segmentation on a public mri dataset. prostate volume as determined by magnetic resonance imaging mri is a useful biomarker both for distinguishing between benign and malignant pathology and can be used either alone or combined with other parameters such as prostate-specific antigen.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>serum raman spectroscopy combined with deep neural network for analysis and rapid screening of hyperthyroidism and hypothyroidism. hyperthyroidism and hypothyroidism may cause a series of clinical complications have a high incidence and early diagnosis is beneficial to treatment. based on raman spectroscopy and deep learning algorithms we propose a rapid screening method to distinguish serum samples of hyperthyroidism patients hypothyroidism patients and control subjects. we collected 99 serum samples including 38 cases from hyperthyroidism patients 32 cases from hypothyroidism patients and 29 cases from control subjects. by comparing and analyzing the raman spectra of the three we found differences in the peak intensity of the spectra indicating that raman spectra can be used for the subsequent identification of diseases. after collecting the spectral data vancouver raman algorithm vra was used to remove the fluorescence background of the data and kernel principal component analysis kpca was used to extract the spectral data features with a cumulative explained variance ratio of 0.9999. then five neural network models the adjusted alexnet lstm-cnn indrnncnn the adjusted googlenet and the adjusted resnet were constructed for classifications. the total accuracy was 91% 84% 82% 75% and 71% respectively. the results of our study show that it is feasible to use raman spectroscopy combined with deep learning to distinguish hyperthyroidism hypothyroidism and control subjects. after comparing the models we found that as the neural network deepens and the complexity of the model increases the classification effect of raman spectroscopy gradually deteriorates and we put forward three conjectures for this.</td>\n",
       "      <td>[99 serum samples including , 38 cases from hyperthyroidism patients, 32 cases from hypothyroidism patients, 29 cases from control subjects, 3 we found differences in, 0.9999    , 5 neural network models the, 91 percent   , 84 percent   , 82 percent   , 75 percent and  , 71 percent respectively  , 3 conjectures for this ]</td>\n",
       "      <td>[we collected 99, samples including 38, hyperthyroidism patients 32, patients and 29, of the 3, ratio of 0.9999, accuracy was 91, put forward 3]</td>\n",
       "      <td>[38 cases from hyperthyroidism patients, 38 cases from hyperthyroidism patients, 32 cases from hypothyroidism patients, 32 cases from hypothyroidism patients, 29 cases from control subjects, 29 cases from control subjects]</td>\n",
       "      <td>[38.0, 38.0, 32.0, 32.0, 29.0, 29.0]</td>\n",
       "      <td>38.0</td>\n",
       "      <td>[99 serum samples including ]</td>\n",
       "      <td>[99.0]</td>\n",
       "      <td>99.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47901</th>\n",
       "      <td>prospective prediction of suicide attempts in community adolescents and young adults using regression methods and machine learning. the use of machine learning ml algorithms to study suicidality has recently been recommended. our aim was to explore whether ml approaches have the potential to improve the prediction of suicide attempt sa risk. using the epidemiological multiwave prospective-longitudinal early developmental stages of psychopathology edsp data set we compared four algorithms-logistic regression lasso ridge and random forest-in predicting a future sa in a community sample of adolescents and young adults.</td>\n",
       "      <td>[4 algorithms   ]</td>\n",
       "      <td>[we compared 4]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18809</th>\n",
       "      <td>transfer learning for clinical sleep pose detection using a single 2d ir camera. sleep quality is an important determinant of human health and wellbeing. novel technologies that can quantify sleep quality at scale are required to enable the diagnosis and epidemiology of poor sleep. one important indicator of sleep quality is body posture. in this paper we present the design and implementation of a non-contact sleep monitoring system that analyses body posture and movement. supervised machine learning strategies applied to noncontact vision-based infrared camera data using a transfer learning approach successfully quantified sleep poses of participants covered by a blanket. this represents the first occasion that such a machine learning approach has been used to successfully detect four predefined poses and the empty bed state during 8-10 hour overnight sleep episodes representing a realistic domestic sleep situation. the methodology was evaluated against manually scored sleep poses and poses estimated using clinical polysomnography measurement technology. in a cohort of 12 healthy participants we find that a resnet-152 pre-trained network achieved the best performance compared with the standard de novo cnn network and other pre-trained networks. the performance of our approach was better than other video-based methods for sleep pose estimation and produced higher performance compared to the clinical standard for pose estimation using a polysomnography position sensor. it can be concluded that infrared video capture coupled with deep learning ai can be successfully used to quantify sleep poses as well as the transitions between poses in realistic nocturnal conditions and that this non-contact approach provides superior pose estimation compared to currently accepted clinical methods.</td>\n",
       "      <td>[2 d ir camera , 4 predefined poses and the, 8    , 12 healthy participants we find]</td>\n",
       "      <td>[a single 2, successfully detect 4, state during 8, cohort of 12]</td>\n",
       "      <td>[12 healthy participants we find]</td>\n",
       "      <td>[12.0]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483</th>\n",
       "      <td>realistic high-resolution lateral cephalometric radiography generated by progressive growing generative adversarial network and quality evaluations. realistic image generation is valuable in dental medicine but still challenging for generative adversarial networks gans which require large amounts of data to overcome the training instability. thus we generated lateral cephalogram x-ray images using a deep-learning-based progressive growing gan pggan . the quality of generated images was evaluated by three methods. first signal-to-noise ratios of real/synthesized images evaluated at the posterior arch region of the first cervical vertebra showed no statistically significant difference t-test p=0.211 . second the results of an image turing test conducted by non-orthodontists and orthodontists for 100 randomly chosen images indicated that they had difficulty in distinguishing whether the image was real or synthesized. third cephalometric tracing with 42 landmark points detection performed on real and synthesized images by two expert orthodontists showed consistency with mean difference of 2.08±1.02 mm. furthermore convolutional neural network-based classification tasks were used to classify skeletal patterns using a real dataset with class imbalance and a dataset balanced with synthesized images. the classification accuracy for the latter case was increased by 1.5%/3.3% at internal/external test sets respectively. thus the cephalometric images generated by pggan are sufficiently realistic and have potential to application in various fields of dental medicine.</td>\n",
       "      <td>[3 methods   , 100 randomly chosen images indicated, 42 landmark points detection performed, 2 expert orthodontists showed consistency, 2.08    , 1.5 percent   ]</td>\n",
       "      <td>[evaluated by 3, orthodontists for 100, tracing with 42, images by 2, difference of 2.08, increased by 1.5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[100 randomly chosen images indicated]</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73716</th>\n",
       "      <td>predicting depression among community residing older adults: a use of machine learning approch. the study demonstrated an application of machine learning techniques in building a depression prediction model. we used the nshap ii data 3377 subjects and 261 variables and built the models using a logistic regression with and without l1 regularization. depression prediction rates ranged 58.33% to 90.48% and 83.33% to 90.44% in the model with and without l1 regularization respectively. the moderate to high prediction rates imply that the machine learning algorithms built the prediction models successfully.</td>\n",
       "      <td>[3377 subjects and  , 261 variables and built the, 58.33 percent to  , 90.48 percent and  , 83.33 percent to  , 90.44 percent in the model]</td>\n",
       "      <td>[ii data 3377, subjects and 261, rates ranged 58.33]</td>\n",
       "      <td>[3377 subjects and  ]</td>\n",
       "      <td>[3377.0]</td>\n",
       "      <td>3377.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84733</th>\n",
       "      <td>personalized risk scoring for critical care prognosis using mixtures of gaussian processes. in this paper we develop a personalized real-time risk scoring algorithm that provides timely and granular assessments for the clinical acuity of ward patients based on their temporal lab tests and vital signs; the proposed risk scoring system ensures timely intensive care unit admissions for clinically deteriorating patients.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152438</th>\n",
       "      <td>sample classification from protein mass spectrometry by 'peak probability contrasts'. early cancer detection has always been a major research focus in solid tumor oncology. early tumor detection can theoretically result in lower stage tumors more treatable diseases and ultimately higher cure rates with less treatment-related morbidities. protein mass spectrometry is a potentially powerful tool for early cancer detection. we propose a novel method for sample classification from protein mass spectrometry data. when applied to spectra from both diseased and healthy patients the 'peak probability contrast' technique provides a list of all common peaks among the spectra their statistical significance and their relative importance in discriminating between the two groups. we illustrate the method on matrix-assisted laser desorption and ionization mass spectrometry data from a study of ovarian cancers.</td>\n",
       "      <td>[2 groups   ]</td>\n",
       "      <td>[between the 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44877</th>\n",
       "      <td>convolutional neural network based detection of atrial fibrillation combing r-r intervals and f-wave frequency spectrum. atrial fibrillation af is one of the arrhythmias that is common and serious in clinic. in this study a novel method of af classification with a convolutional neural network cnn was proposed and particularly two cardiac rhythm features of r-r intervals and f-wave frequency spectrum were combined into the cnn for a good applicability of mobile application. over 23 patients' ten-hours of electrocardiogram ecg records were collected from the mit-bih database and each of which was segmented into 10s-data fragments to train the designed cnn and evaluate the performance of the proposed method. specifically a total of 83461 fragments were collected 49952 fragments of which are the normal fragments type-n and the others are the af fragments. as results the obtained average accuracy of the proposed method combining the two proposed features is 97.3% which is shown a relative higher accuracy comparing with either that of the detection with the feature of r-r intervals 95.7% or that with the feature of f-wave frequency spectrum 93.9% . additionally the sensitivity and the specificity of the present method are both of a high level of 97.4% and 97.2% respectively. in conclusion the cnn based approach by combining the r-r interval series and the f-wave frequency spectrum would be effectively to improve the performance of af detection. moreover the proposed classification of af with 10s-data fragments also could be potentially useful for a wearable real-time monitoring application for a pre-hospital screening of af.</td>\n",
       "      <td>[2 cardiac rhythm features of, 23 patients   , 10 s   , 83461 fragments were collected , 49952 fragments of which are, 2 proposed features is , 97.3 percent which is shown, 95.7 percent or that with, 93.9 percent   , 97.4 percent and  , 97.2 percent respectively  , 10 s   ]</td>\n",
       "      <td>[and particularly 2, segmented into 10, total of 83461, were collected 49952, combining the 2, features is 97.3, frequency spectrum 93.9, level of 97.4, af with 10]</td>\n",
       "      <td>[23 patients   ]</td>\n",
       "      <td>[23.0]</td>\n",
       "      <td>23.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133419</th>\n",
       "      <td>feature extraction for analysis of ecg signals. the automated diagnostic systems employing diverse and composite features for electrocardiogram ecg signals were analyzed and their accuracies were determined. because of the importance of making the right decision classification procedures classifying the ecg signals with high accuracy were investigated. the classification accuracies of mixture of experts me trained on composite features and modified mixture of experts mme trained on diverse features were compared. the inputs of these automated diagnostic systems were composed of diverse or composite features power levels of the power spectral density estimates obtained by the eigenvector methods and were chosen according to the network structures. the conclusions of this study demonstrated that the mme trained on diverse features achieved accuracy rates which were higher than that of the me trained on composite features.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65431</th>\n",
       "      <td>cochlear implantation in postlingually deaf adults is time-sensitive towards positive outcome: prediction using advanced machine learning techniques. given our aging society and the prevalence of age-related hearing loss that often develops during adulthood hearing loss is a common public health issue affecting almost all older adults. moderate-to-moderately severe hearing loss can usually be corrected with hearing aids; however severe-to-profound hearing loss often requires a cochlear implant ci . however post-operative ci results vary and the performance of the previous prediction models is limited indicating that a new approach is needed. for postlingually deaf adults nde120 who received ci with full insertion we predicted ci outcomes using a random-forest regression rfr model and investigated the effect of preoperative factors on ci outcomes. postoperative word recognition scores wrs served as the dependent variable to predict. predictors included duration of deafness dod age at ci operation ageci duration of hearing-aid use doha preoperative hearing threshold and sentence recognition score. prediction accuracy was evaluated using mean absolute error mae and pearson's correlation coefficient r between the true wrs and predicted wrs. the fitting using a linear model resulted in prediction of wrs with r=0.7 and mae=15.6±9. rfr outperformed the linear model r=0.96 mae=6.1±4.7 p&lt;0.00001 . cross-hospital data validation showed reliable performance using rfr r=0.91 mae=9.6±5.2 . the contribution of dod to prediction was the highest mae increase when omitted: 14.8 followed by ageci 8.9 and doha 7.5 . after ci patients with dod&lt;10 years presented better wrss and smaller variations p&lt;0.01 than those with longer dod. better wrs was also explained by younger age at ci and longer-term doha. machine learning demonstrated a robust prediction performance for ci outcomes in postlingually deaf adults across different institutes providing a reference value for counseling patients considering ci. health care providers should be aware that the patients with severe-to-profound hearing loss who cannot have benefit from hearing aids need to proceed with ci as soon as possible and should continue using hearing aids until after ci operation.</td>\n",
       "      <td>[14.8 followed by ageci , 8.9 and doha  , 7.5    ]</td>\n",
       "      <td>[by ageci 8.9, and doha 7.5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26463</th>\n",
       "      <td>aa comparison of dynamic modeling approaches for epileptic eeg detection and classification. electroencephalogram eeg has been intensively used as a diagnosis tool for epilepsy. the traditional diagnostic procedure relies on a recording of eeg from several days up to a few weeks and the recordings are visually inspected by trained medical professionals. this procedure is time consuming with a high misdiagnosis rate. in recent years computer-aided techniques have been proposed to automate the epilepsy diagnosis by using machine learning methods to analyze eeg data. considering the time-varying nature of eeg the goal of this work is to characterize dynamic changes of eeg patterns for the detection and classification of epilepsy. four different dynamic bayesian modeling methods were evaluated using multi-subject epileptic eeg data. experimental results show that an accuracy of 98.0% can be achieved by one of the four methods. the same method also provides an overall accuracy of 87.7% for the classification of seven different seizure types.</td>\n",
       "      <td>[4 different dynamic bayesian modeling, 98.0 percent can be achieved, 4 methods   , 87.7 percent for the classification, 7 different seizure types ]</td>\n",
       "      <td>[accuracy of 98.0, of the 4, accuracy of 87.7, classification of 7]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10662</th>\n",
       "      <td>an ai-powered blood test to detect cancer using nanodsf. glioblastoma is the most frequent and aggressive primary brain tumor. its diagnosis is based on resection or biopsy that could be especially difficult and dangerous in the case of deep location or patient comorbidities. monitoring disease evolution and progression also requires repeated biopsies that are often not feasible. therefore there is an urgent need to develop biomarkers to diagnose and follow glioblastoma evolution in a minimally invasive way. in the present study we described a novel cancer detection method based on plasma denaturation profiles obtained by a non-conventional use of differential scanning fluorimetry. using blood samples from 84 glioma patients and 63 healthy controls we showed that their denaturation profiles can be automatically distinguished with the help of machine learning algorithms with 92% accuracy. proposed high throughput workflow can be applied to any type of cancer and could become a powerful pan-cancer diagnostic and monitoring tool requiring only a simple blood test.</td>\n",
       "      <td>[84 glioma patients and , 63 healthy controls we showed, 92 percent accuracy  ]</td>\n",
       "      <td>[samples from 84, patients and 63, algorithms with 92]</td>\n",
       "      <td>[84 glioma patients and ]</td>\n",
       "      <td>[84.0]</td>\n",
       "      <td>84.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77895</th>\n",
       "      <td>prediction of activation patterns preceding hallucinations in patients with schizophrenia using machine learning with structured sparsity. despite significant progress in the field the detection of fmri signal changes during hallucinatory events remains difficult and time-consuming. this article first proposes a machine-learning algorithm to automatically identify resting-state fmri periods that precede hallucinations versus periods that do not. when applied to whole-brain fmri data state-of-the-art classification methods such as support vector machines svm yield dense solutions that are difficult to interpret. we proposed to extend the existing sparse classification methods by taking the spatial structure of brain images into account with structured sparsity using the total variation penalty. based on this approach we obtained reliable classifying performances associated with interpretable predictive patterns composed of two clearly identifiable clusters in speech-related brain regions. the variation in transition-to-hallucination functional patterns not only from one patient to another but also from one occurrence to the next e.g. also depending on the sensory modalities involved appeared to be the major difficulty when developing effective classifiers. consequently second this article aimed to characterize the variability within the prehallucination patterns using an extension of principal component analysis with spatial constraints. the principal components pcs and the associated basis patterns shed light on the intrinsic structures of the variability present in the dataset. such results are promising in the scope of innovative fmri-guided therapy for drug-resistant hallucinations such as fmri-based neurofeedback.</td>\n",
       "      <td>[2 clearly identifiable clusters in]</td>\n",
       "      <td>[composed of 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34682</th>\n",
       "      <td>risk factors for chronic diabetes patients. specific predictive models for diabetes polyneuropathy based on screening methods for example nerve conduction studies ncs can reach up to auc 65.8-84.7 % for the conditional diagnosis of dpn in primary care. prediction methods that utilize data from personal health records deal with large non-specific datasets with different prediction methods. it was demonstrated that the machine learning methods allow to achieve up to 0.7982 precision 0.8152 recall 0.8064 f1-score 0.8261 accuracy and 0.8988 auc using the neural network classifier.</td>\n",
       "      <td>[65.8    , 0.7982 precision   , 0.8152 recall   , 0.8064 f   , 0.8261 accuracy and  , 0.8988 auc using the neural]</td>\n",
       "      <td>[to auc 65.8, up to 0.7982, accuracy and 0.8988]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19158</th>\n",
       "      <td>segmentation of chronic subdural hematomas using 3d convolutional neural networks. chronic subdural hematomas csdhs are an increasingly prevalent neurologic disease that often requires surgical intervention to alleviate compression of the brain. management of csdhs relies heavily on computed tomography ct imaging and serial imaging is frequently obtained to help direct management. the volume of hematoma provides critical information in guiding therapy and evaluating new methods of management. we set out to develop an automated program to compute the volume of hematoma on ct scans for both pre- and postoperative images.</td>\n",
       "      <td>[3 d convolutional neural networks]</td>\n",
       "      <td>[hematomas using 3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>a novel deep autoencoder based survival analysis approach for microarray dataset. breast cancer is one of the major causes of mortality globally. therefore different machine learning ml techniques were deployed for computing survival and diagnosis. survival analysis methods are used to compute survival probability and the most important factors affecting that probability. most survival analysis methods are used to deal with clinical features up to hundreds hence applying survival analysis methods like cox regression on rnaseq microarray data with many features up to thousands is considered a major challenge.</td>\n",
       "      <td>[100 hence applying survival analysis, 1000 is considered a major]</td>\n",
       "      <td>[up to 100, up to 1000]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106469</th>\n",
       "      <td>a new approach for clustered mcs classification with sparse features learning and twsvm. in digital mammograms an early sign of breast cancer is the existence of microcalcification clusters mcs which is very important to the early breast cancer detection. in this paper a new approach is proposed to classify and detect mcs. we formulate this classification problem as sparse feature learning based classification on behalf of the test samples with a set of training samples which are also known as a \"vocabulary\" of visual parts. a visual information-rich vocabulary of training samples is manually built up from a set of samples which include mcs parts and no-mcs parts. with the prior ground truth of mcs in mammograms the sparse feature learning is acquired by the l p -regularized least square approach with the interior-point method. then we designed the sparse feature learning based mcs classification algorithm using twin support vector machines twsvms . to investigate its performance the proposed method is applied to ddsm datasets and compared with support vector machines svms with the same dataset. experiments have shown that performance of the proposed method is more efficient or better than the state-of-art methods.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126748</th>\n",
       "      <td>an efficient automated algorithm to detect ocular surface temperature on sequence of thermograms using snake and target tracing function. functional infrared ir imaging is widely adopted in medical field nowadays with more emphasis on breast cancer and ocular abnormalities. in this article an algorithm is presented to accurately locate the eye and cornea in ocular thermographic sequences which were recorded utilizing functional infrared imaging. the localization is achieved by snake algorithm coupled with a newly proposed target tracing function. the target tracing function enables automated localization allows the absence of any manual assistance before the algorithm runs. genetic algorithm is used to perform the search for global minimum on the function to produce desired localization. on all the cases we have studied in average the region encircled by the algorithm covers 92% of the true ocular region. as for the non-ocular region covered it only accounts for less than 5% of the encircled region.</td>\n",
       "      <td>[92 percent of the true, 5 percent of the encircled]</td>\n",
       "      <td>[algorithm covers 92, less than 5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136647</th>\n",
       "      <td>identification of ischemic heart disease via machine learning analysis on magnetocardiograms. ischemic heart disease ihd is predominantly the leading cause of death worldwide. early detection of ihd may effectively prevent severity and reduce mortality rate. recently magnetocardiography mcg has been developed for the detection of heart malfunction. although mcg is capable of monitoring the abnormal patterns of magnetic field as emitted by physiologically defective heart data interpretation is time-consuming and requires highly trained professional. hence we propose an automatic method for the interpretation of ihd pattern of mcg recordings using machine learning approaches. two types of machine learning techniques namely back-propagation neural network bnn and direct kernel self-organizing map dk-som were applied to explore the ihd pattern recorded by mcg. data sets were obtained by sequential measurement of magnetic field emitted by cardiac muscle of 125 individuals. data were divided into training set and testing set of 74 cases and 51 cases respectively. predictive performance was obtained by both machine learning approaches. the bnn exhibited sensitivity of 89.7% specificity of 54.5% and accuracy of 74.5% while the dk-som provided relatively higher prediction performance with a sensitivity specificity and accuracy of 86.2% 72.7% and 80.4% respectively. this finding suggests a high potential of applying machine learning approaches for high-throughput detection of ihd from mcg data.</td>\n",
       "      <td>[2 types of machine learning, 125 individuals   , 74 cases and  , 51 cases respectively  , 89.7 percent specificity of , 54.5 percent and accuracy of, 74.5 percent while the dk, 86.2 percent   , 72.7 percent and  , 80.4 percent respectively  ]</td>\n",
       "      <td>[muscle of 125, set of 74, cases and 51, sensitivity of 89.7, specificity of 54.5, accuracy of 74.5, accuracy of 86.2]</td>\n",
       "      <td>[125 individuals   , 74 cases and  , 51 cases respectively  ]</td>\n",
       "      <td>[125.0, 74.0, 51.0]</td>\n",
       "      <td>125.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92278</th>\n",
       "      <td>a framework for the automatic detection and characterization of brain malformations: validation on the corpus callosum. in this paper we extend the one-class support vector machine svm and the regularized discriminative direction analysis to the multiple kernel mk framework providing an effective analysis pipeline for the detection and characterization of brain malformations in particular those affecting the corpus callosum. the detection of the brain malformations is currently performed by visual inspection of mri images making the diagnostic process sensible to the operator experience and subjectiveness. the method we propose addresses these problems by automatically reproducing the neuroradiologist's approach. one-class svms are appropriate to cope with heterogeneous brain abnormalities that are considered outliers. the mk framework allows to efficiently combine the different geometric features that can be used to describe brain structures. moreover the regularized discriminative direction analysis is exploited to highlight the specific malformative patterns for each patient. we performed two different experiments. firstly we tested the proposed method to detect the malformations of the corpus callosum on a 104 subject dataset. results showed that the proposed pipeline can classify the subjects with an accuracy larger than 90% and that the discriminative direction analysis can highlight a wide range of malformative patterns e.g. local diffuse and complex abnormalities . secondly we compared the diagnosis of four neuroradiologists on a dataset of 128 subjects. the diagnosis was performed both in blind condition and using the classifier and the discriminative direction outputs. results showed that the use of the proposed pipeline as an assisted diagnosis tool improves the inter-subject variability of the diagnosis. finally a graphical representation of the discriminative direction analysis was proposed to enhance the interpretability of the results and provide the neuroradiologist with a tool to fully and clearly characterize the patient malformations at single-subject level.</td>\n",
       "      <td>[2 different experiments  , 104 subject dataset  , 90 percent and that the, 4 neuroradiologists on a dataset, 128 subjects   ]</td>\n",
       "      <td>[we performed 2, on a 104, larger than 90, diagnosis of 4, dataset of 128]</td>\n",
       "      <td>[104 subject dataset  , 128 subjects   ]</td>\n",
       "      <td>[104.0, 128.0]</td>\n",
       "      <td>128.0</td>\n",
       "      <td>[104 subject dataset  , 4 neuroradiologists on a dataset]</td>\n",
       "      <td>[104.0, 4.0]</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40051</th>\n",
       "      <td>primage project: predictive in silico multiscale analytics to support childhood cancer personalised evaluation empowered by imaging biomarkers. primage is one of the largest and more ambitious research projects dealing with medical imaging artificial intelligence and cancer treatment in children. it is a 4-year european commission-financed project that has 16 european partners in the consortium including the european society for paediatric oncology two imaging biobanks and three prominent european paediatric oncology units. the project is constructed as an observational in silico study involving high-quality anonymised datasets imaging clinical molecular and genetics for the training and validation of machine learning and multiscale algorithms. the open cloud-based platform will offer precise clinical assistance for phenotyping diagnosis treatment allocation prediction and patient endpoints prognosis based on the use of imaging biomarkers tumour growth simulation advanced visualisation of confidence scores and machine-learning approaches. the decision support prototype will be constructed and validated on two paediatric cancers: neuroblastoma and diffuse intrinsic pontine glioma. external validation will be performed on data recruited from independent collaborative centres. final results will be available for the scientific community at the end of the project and ready for translation to other malignant solid tumours.</td>\n",
       "      <td>[4    , 16 european partners in the, 2 imaging biobanks and , 3 prominent european paediatric oncology, 2 paediatric cancers  ]</td>\n",
       "      <td>[is a 4, that has 16, paediatric oncology 2, biobanks and 3, validated on 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2 imaging biobanks and ]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26404</th>\n",
       "      <td>end-to-end deep learning model for cardiac cycle synchronization from multi-view angiographic sequences. dynamic reconstructions 3dt of coronary arteries could give important perfusion details to clinicians. temporal matching of the different views which may not be acquired simultaneously is a prerequisite for an accurate stereo-matching of the coronary segments. in this paper we show how a neural network can be trained from angiographic sequences to synchronize different views during the cardiac cycle using raw x-ray angiography videos exclusively. first we train a neural network model with angiographic sequences to extract features describing the progression of the cardiac cycle. then we compute the distance between the feature vectors of every frame from the first view with those from the second view to generate distance maps that display stripe patterns. using pathfinding we extract the best temporally coherent associations between each frame of both videos. finally we compare the synchronized frames of an evaluation set with the ecg signals to show an alignment with 96.04% accuracy.</td>\n",
       "      <td>[3 dt of coronary arteries, 96.04 percent accuracy  ]</td>\n",
       "      <td>[dynamic reconstructions 3, alignment with 96.04]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49833</th>\n",
       "      <td>rapid muscle volume prediction using anthropometric measurements and population-derived statistical models. knowledge of subject-specific muscle volumes may be used as surrogates for evaluating muscle strength and power generated by 'fat-free' muscle mass. this study presents population-based statistical learning approaches for predicting 'fat-free' muscle volume from known anthropometric measurements. using computed tomography ct imaging data to obtain lower-limb muscle volumes from 50 men and women this study evaluated six statistical learning methods for predicting muscle volumes from anthropometric measurements: i stepwise regression ii linear support vector machine svm  iii 2nd-order polynomial svm iv linear partial least squares regression plsr  v quadratic plsr and vi 3rd-order spline fit plsr. these techniques have successfully been demonstrated in bioengineering applications and freely available in open-source toolkits. analysis revealed that separating a general population into sexes and/or cohorts based on adipose level may improve prediction accuracies. the most important measures that statistically influence muscle volume predictions were shank girth followed by sex and finally leg length as identified using stepwise regression. svm learning predicted muscle volume with an accuracy of 85±4% when using linear interpolation but performed poorly with an accuracy of 59±6% using polynomial interpolation. the simpler linear plsr exhibited muscle volume prediction accuracy of 87±2% while quadratic plsr was slightly reduced at 82±3%. for the spline fit plsr high accuracy was observed on the training data set ~99% but over-fitting a drawback of high-interpolation methods resulted in erroneous predictions on testing data and hence the model was deemed unsuitable. in conclusion use of linear plsr models with variables of sex leg length and shank girth is a useful tool for predicting 'fat-free' muscle volume.</td>\n",
       "      <td>[50 men and women this, 6 statistical learning methods for, 2 nd   , 3 rd   , 85    , 59    , 87    , 82    ]</td>\n",
       "      <td>[volumes from 50, study evaluated 6, svm iii 2, and vi 3, accuracy of 85, accuracy of 59, accuracy of 87, reduced at 82]</td>\n",
       "      <td>[50 men and women this, 50 men and women this]</td>\n",
       "      <td>[50.0, 50.0]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79244</th>\n",
       "      <td>artificial neural network: a method for prediction of surgery-related pressure injury in cardiovascular surgical patients. the aim of this study was to build an artificial neural network ann model for predicting surgery-related pressure injury srpi in cardiovascular surgical patients.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8453</th>\n",
       "      <td>fatty liver disease prediction model based on big data of electronic physical examination records. fatty liver disease fld is a common liver disease which poses a great threat to people's health but there is still no optimal method that can be used on a large-scale screening. this research is based on machine learning algorithms using electronic physical examination records in the health database as data support to a predictive model for fld. the model has shown good predictive ability on the test set with its auc reaching 0.89. since there are a large number of electronic physical examination records in most of health database this model might be used as a non-invasive diagnostic tool for fld for large-scale screening.</td>\n",
       "      <td>[0.89    ]</td>\n",
       "      <td>[auc reaching 0.89]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>deepprog: an ensemble of deep-learning and machine-learning models for prognosis prediction using multi-omics data. multi-omics data are good resources for prognosis and survival prediction; however these are difficult to integrate computationally. we introduce deepprog a novel ensemble framework of deep-learning and machine-learning approaches that robustly predicts patient survival subtypes using multi-omics data. it identifies two optimal survival subtypes in most cancers and yields significantly better risk-stratification than other multi-omics integration methods. deepprog is highly predictive exemplified by two liver cancer c-index 0.73-0.80 and five breast cancer datasets c-index 0.68-0.73 . pan-cancer analysis associates common genomic signatures in poor survival subtypes with extracellular matrix modeling immune deregulation and mitosis processes. deepprog is freely available at https://github.com/lanagarmire/deepprog.</td>\n",
       "      <td>[2 optimal survival subtypes in, 2 liver cancer c , 0.73    , 5 breast cancer datasets c, 0.68    ]</td>\n",
       "      <td>[it identifies 2, exemplified by 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76598</th>\n",
       "      <td>ensemble of shape functions and support vector machines for the estimation of discrete arm muscle activation from external biceps 3d point clouds. muscle activation level is currently being captured using impractical and expensive devices which make their use in telemedicine settings extremely difficult. to address this issue a prototype is presented of a non-invasive easy-to-install system for the estimation of a discrete level of muscle activation of the biceps muscle from 3d point clouds captured with rgb-d cameras.</td>\n",
       "      <td>[3 d point clouds , 3 d point clouds captured]</td>\n",
       "      <td>[external biceps 3, muscle from 3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64981</th>\n",
       "      <td>machine learning-based radiomic models to predict intensity-modulated radiation therapy response gleason score and stage in prostate cancer. to develop different radiomic models based on the magnetic resonance imaging mri radiomic features and machine learning methods to predict early intensity-modulated radiation therapy imrt response gleason scores gs and prostate cancer pca stages.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47354</th>\n",
       "      <td>computer-aided diagnosis of multiple sclerosis using a support vector machine and optical coherence tomography features. the purpose of this paper is to evaluate the feasibility of diagnosing multiple sclerosis ms using optical coherence tomography oct data and a support vector machine svm as an automatic classifier. forty-eight ms patients without symptoms of optic neuritis and forty-eight healthy control subjects were selected. swept-source optical coherence tomography ss-oct was performed using a dri deep-range imaging triton oct device topcon corp. tokyo japan . mean values right and left eye for macular thickness retinal and choroidal layers and peripapillary area retinal nerve fibre layer retinal ganglion cell layer-gcl and choroidal layers were compared between both groups. based on the analysis of the area under the receiver operator characteristic curve auc the 3 variables with the greatest discriminant capacity were selected to form the feature vector. a svm was used as an automatic classifier obtaining the confusion matrix using leave-one-out cross-validation. classification performance was assessed with matthew's correlation coefficient mcc and the aucclassifier. the most discriminant variables were found to be the total gcl thickness between inner limiting membrane to inner nuclear layer boundaries evaluated in the peripapillary area and macular retina thickness in the nasal quadrant of the outer and inner rings. using the svm classifier we obtained the following values: mcc = 0.81 sensitivity = 0.89 specificity = 0.92 accuracy = 0.91 and aucclassifier = 0.97. our findings suggest that it is possible to classify control subjects and ms patients without previous optic neuritis by applying machine-learning techniques to study the structural neurodegeneration in the retina.</td>\n",
       "      <td>[48 ms patients without symptoms, 48 healthy control subjects were, 3 variables with the greatest, 0.81 sensitivity   , 0.89 specificity   , 0.92 accuracy   , 0.91 and aucclassifier  , 0.97    ]</td>\n",
       "      <td>[neuritis and 48, auc the 3, mcc = 0.81, sensitivity = 0.89, specificity = 0.92, accuracy = 0.91, aucclassifier = 0.97]</td>\n",
       "      <td>[48 ms patients without symptoms, 48 healthy control subjects were]</td>\n",
       "      <td>[48.0, 48.0]</td>\n",
       "      <td>48.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98850</th>\n",
       "      <td>breast cancer detection with reduced feature set. this paper explores feature reduction properties of independent component analysis ica on breast cancer decision support system. wisconsin diagnostic breast cancer wdbc dataset is reduced to one-dimensional feature vector computing an independent component ic . the original data with 30 features and reduced one feature ic are used to evaluate diagnostic accuracy of the classifiers such as k-nearest neighbor k-nn artificial neural network ann radial basis function neural network rbfnn and support vector machine svm . the comparison of the proposed classification using the ic with original feature set is also tested on different validation 5/10-fold cross-validations and partitioning 20%-40% methods. these classifiers are evaluated how to effectively categorize tumors as benign and malignant in terms of specificity sensitivity accuracy f-score youden's index discriminant power and the receiver operating characteristic roc curve with its criterion values including area under curve auc and 95% confidential interval ci . this represents an improvement in diagnostic decision support system while reducing computational complexity.</td>\n",
       "      <td>[30 features and reduced one, 5    , 20 percent   , 95 percent confidential interval ci]</td>\n",
       "      <td>[data with 30, different validation 5, and partitioning 20, auc and 95]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59288</th>\n",
       "      <td>deep learning in the prediction of ischaemic stroke thrombolysis functional outcomes: a pilot study. intravenous thrombolysis decision-making and obtaining of consent would be assisted by an individualized risk-benefit ratio. deep learning dl models may be able to assist with this patient selection.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>characterizing brain tumor regions using texture analysis in magnetic resonance imaging. to extract texture features from magnetic resonance imaging mri scans of patients with brain tumors and use them to train a classification model for supporting an early diagnosis.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33698</th>\n",
       "      <td>texture synthesis based thyroid nodule detection from medical ultrasound images: interpreting and suppressing the adversarial effect of in-place manual annotation. deep learning method have been offering promising solutions for medical image processing but failing to understand what features in the input image are captured and whether certain artifacts are mistakenly included in the model thus create crucial problems in generalizability of the model. we targeted a common issue of this kind caused by manual annotations appeared in medical image. these annotations are usually made by the doctors at the spot of medical interest and have adversarial effect on many computer vision ai tasks. we developed an inpainting algorithm to remove the annotations and recover the original images. besides we applied variational information bottleneck method in order to filter out the unwanted features and enhance the robustness of the model. our impaiting algorithm is extensively tested in object detection in thyroid ultrasound image data. the map mean average precision with iou = 0.3 is 27% without the annotation removal. the map is 83% if manually removed the annotations using photoshop and is enhanced to 90% using our inpainting algorithm. our work can be utilized in future development and evaluation of artificial intelligence models based on medical images with defects.</td>\n",
       "      <td>[0.3 is   , 27 percent without the annotation, 83 percent if manually removed, 90 percent using our inpainting]</td>\n",
       "      <td>[iou = 0.3, map is 83, enhanced to 90]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31508</th>\n",
       "      <td>psa-based machine learning model improves prostate cancer risk stratification in a screening population. the majority of prostate cancer diagnoses are facilitated by testing serum prostate specific antigen psa levels. despite this there are limitations to the diagnostic accuracy of psa. consideration of patient demographic factors and biochemical adjuncts to psa may improve prostate cancer risk stratification. we aimed to develop a contemporary accurate and cost-effective model based on objective measures to improve the accuracy of prostate cancer risk stratification.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32519</th>\n",
       "      <td>predictive value of the texture analysis of enhanced computed tomographic images for preoperative pancreatic carcinoma differentiation. to assess the utility of texture analysis for predicting the pathological degree of differentiation of pancreatic carcinoma pc .</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14576</th>\n",
       "      <td>eliminating indefiniteness of clinical spectrum for better screening covid-19. the coronavirus disease 2019 covid-19 has swept all over the world. due to the limited detection facilities especially in developing countries a large number of suspected cases can only receive common clinical diagnosis rather than more effective detections like reverse transcription polymerase chain reaction rt-pcr tests or ct scans. this motivates us to develop a quick screening method via common clinical diagnosis results. however the diagnostic items of different patients may vary greatly and there is a huge variation in the dimension of the diagnosis data among different suspected patients it is hard to process these indefinite dimension data via classical classification algorithms. to resolve this problem we propose an indefiniteness elimination network ie-net to eliminate the influence of the varied dimensions and make predictions about the covid-19 cases. the ie-net is in an encoder-decoder framework fashion and an indefiniteness elimination operation is proposed to transfer the indefinite dimension feature into a fixed dimension feature. comprehensive experiments were conducted on the public available covid-19 clinical spectrum dataset. experimental results show that the proposed indefiniteness elimination operation greatly improves the classification performance the ie-net achieves 94.80% accuracy 92.79% recall 92.97% precision and 94.93% auc for distinguishing covid-19 cases from non-covid-19 cases with only common clinical diagnose data. we further compared our methods with 3 classical classification algorithms: random forest gradient boosting and multi-layer perceptron mlp . to explore each clinical test item's specificity we further analyzed the possible relationship between each clinical test item and covid-19.</td>\n",
       "      <td>[2019 covid   , 94.80 percent accuracy  , 92.79 percent recall  , 92.97 percent precision and , 94.93 percent auc for distinguishing, 3 classical classification algorithms ]</td>\n",
       "      <td>[coronavirus disease 2019, precision and 94.93, methods with 3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14483</th>\n",
       "      <td>predicting cardiovascular risk using social media data: performance evaluation of machine-learning models. current atherosclerotic cardiovascular disease ascvd predictive models have limitations; thus efforts are underway to improve the discriminatory power of ascvd models.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78319</th>\n",
       "      <td>precision cohort finding with outcome-driven similarity analytics: a case study of patients with atrial fibrillation. dividing patients into similar groups plays a significant role in implementing personalized care. clinicians and researchers have been applying patient grouping techniques in disease phenotyping risk stratification and personalized medicine. however the current approaches are either based on pure domain knowledge where the underlying patient similarity cannot be precisely quantified or based on unsupervised clustering techniques which completely ignore the clinical context of measuring patient similarity. in the study we propose an outcome-driven approach to identify clinically similar patients which are grouped together as a precision cohort. the approach quantitatively measures the similarity between patients in terms of a particular clinical outcome of interest thus patients who have a similar clinical outcome tend to be grouped into the same group. we demonstrate the effectiveness of the approach in a real-world case study: from an atrial fibrillation patient cohort that is usually considered to be at high risk for ischemic stroke is according to current clinical guidelines. our approach successfully identified a precision cohort of patients with truly low risk of is.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>deep convolutional neural network for the automated detection of subthalamic nucleus using mer signals. deep brain stimulation dbs surgery has been extensively conducted for treating advanced parkinson's disease pd patient's symptoms. dbs hinges on the localization of the subthalamic nucleus stn in which a permanent electrode should be accurately placed to produce electrical current. microelectrode recording mer signals are routinely recorded in the procedure of dbs surgery to validate the planned trajectories. however manual mer signals interpretation with the goal of detecting stn borders requires expertise and prone to inter-observer variability. therefore a computerized aided system would be beneficial to automatic detection of the dorsal and ventral borders of the stn in mer.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55642</th>\n",
       "      <td>wearable sensors for parkinson's disease: which data are worth collecting for training symptom detection models. machine learning algorithms that use data streams captured from soft wearable sensors have the potential to automatically detect pd symptoms and inform clinicians about the progression of disease. however these algorithms must be trained with annotated data from clinical experts who can recognize symptoms and collecting such data are costly. understanding how many sensors and how much labeled data are required is key to successfully deploying these models outside of the clinic. here we recorded movement data using 6 flexible wearable sensors in 20 individuals with pd over the course of multiple clinical assessments conducted on 1 day and repeated 2 weeks later. participants performed 13 common tasks such as walking or typing and a clinician rated the severity of symptoms bradykinesia and tremor . we then trained convolutional neural networks and statistical ensembles to detect whether a segment of movement showed signs of bradykinesia or tremor based on data from tasks performed by other individuals. our results show that a single wearable sensor on the back of the hand is sufficient for detecting bradykinesia and tremor in the upper extremities whereas using sensors on both sides does not improve performance. increasing the amount of training data by adding other individuals can lead to improved performance but repeating assessments with the same individuals-even at different medication states-does not substantially improve detection across days. our results suggest that pd symptoms can be detected during a variety of activities and are best modeled by a dataset incorporating many individuals.</td>\n",
       "      <td>[6 flexible wearable sensors in, 20 individuals with pd over, 1 day and repeated , 2 weeks later  , 13 common tasks such as]</td>\n",
       "      <td>[data using 6, sensors in 20, conducted on 1, and repeated 2, participants performed 13]</td>\n",
       "      <td>[20 individuals with pd over]</td>\n",
       "      <td>[20.0]</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>handheld briefcase optical coherence tomography with real-time machine learning classifier for middle ear infections. a middle ear infection is a prevalent inflammatory disease most common in the pediatric population and its financial burden remains substantial. current diagnostic methods are highly subjective relying on visual cues gathered by an otoscope. to address this shortcoming optical coherence tomography oct has been integrated into a handheld imaging probe. this system can non-invasively and quantitatively assess middle ear effusions and identify the presence of bacterial biofilms in the middle ear cavity during ear infections. furthermore the complete oct system is housed in a standard briefcase to maximize its portability as a diagnostic device. nonetheless interpreting oct images of the middle ear more often requires expertise in oct as well as middle ear infections making it difficult for an untrained user to operate the system as an accurate stand-alone diagnostic tool in clinical settings. here we present a briefcase oct system implemented with a real-time machine learning platform for middle ear infections. a random forest-based classifier can categorize images based on the presence of middle ear effusions and biofilms. this study demonstrates that our briefcase oct system coupled with machine learning can provide user-invariant classification results of middle ear conditions which may greatly improve the utility of this technology for the diagnosis and management of middle ear infections.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115260</th>\n",
       "      <td>neuroanatomical pattern classification in a population-based sample of first-episode schizophrenia. recent neuroanatomical pattern classification studies have attempted to individually classify cases with psychotic disorders using morphometric mri data in an automated fashion. however this approach has not been tested in population-based samples in which variable patterns of comorbidity and disease course are typically found. we aimed to evaluate the diagnostic accuracy da of the above technique to discriminate between incident cases of first-episode schizophrenia identified in a circumscribed geographical region over a limited period of time in comparison with next-door healthy controls. sixty-two cases of first-episode schizophrenia or schizophreniform disorder and 62 age gender and educationally-matched controls underwent 1.5 t mri scanning at baseline and were naturalistically followed-up over 1 year. t1-weighted images were used to train a high-dimensional multivariate classifier and to generate both spatial maps of the discriminative morphological patterns between groups and roc curves. the spatial map discriminating first-episode schizophrenia patients from healthy controls revealed a complex pattern of regional volumetric abnormalities in the former group affecting fronto-temporal-occipital gray and white matter regions bilaterally including the inferior fronto-occipital fasciculus as well as the third and lateral ventricles. however an overall modest da 73.4% was observed for the individual discrimination between first-episode schizophrenia patients and controls and the classifier failed to predict 1-year prognosis remitting versus non-remitting course of first-episode schizophrenia da=58.3% . in conclusion using a \"real world\" sample recruited with epidemiological methods the application of a neuroanatomical pattern classifier afforded only modest da to classify first-episode schizophrenia subjects and next-door healthy controls and poor discriminative power to predict the 1-year prognosis of first-episode schizophrenia.</td>\n",
       "      <td>[62 cases of first , 62 age gender and educationally, 1.5 t mri scanning at, 1 year   , 73.4 percent was observed for, 1    , 1    ]</td>\n",
       "      <td>[disorder and 62, controls underwent 1.5, modest da 73.4, to predict 1, predict the 1]</td>\n",
       "      <td>[62 cases of first ]</td>\n",
       "      <td>[62.0]</td>\n",
       "      <td>62.0</td>\n",
       "      <td>[62 age gender and educationally, 1.5 t mri scanning at, 1.5 t mri scanning at]</td>\n",
       "      <td>[62.0, 1.5, 1.5]</td>\n",
       "      <td>62.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122817</th>\n",
       "      <td>characterization of groups using composite kernels and multi-source fmri analysis data: application to schizophrenia. pattern classification of brain imaging data can enable the automatic detection of differences in cognitive processes of specific groups of interest. furthermore it can also give neuroanatomical information related to the regions of the brain that are most relevant to detect these differences by means of feature selection procedures which are also well-suited to deal with the high dimensionality of brain imaging data. this work proposes the application of recursive feature elimination using a machine learning algorithm based on composite kernels to the classification of healthy controls and patients with schizophrenia. this framework which evaluates nonlinear relationships between voxels analyzes whole-brain fmri data from an auditory task experiment that is segmented into anatomical regions and recursively eliminates the uninformative ones based on their relevance estimates thus yielding the set of most discriminative brain areas for group classification. the collected data was processed using two analysis methods: the general linear model glm and independent component analysis ica . glm spatial maps as well as ica temporal lobe and default mode component maps were then input to the classifier. a mean classification accuracy of up to 95% estimated with a leave-two-out cross-validation procedure was achieved by doing multi-source data classification. in addition it is shown that the classification accuracy rate obtained by using multi-source data surpasses that reached by using single-source data hence showing that this algorithm takes advantage of the complimentary nature of glm and ica.</td>\n",
       "      <td>[2 analysis methods  , 95 percent estimated with a]</td>\n",
       "      <td>[processed using 2, up to 95]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145427</th>\n",
       "      <td>risk factor identification and mortality prediction in cardiac surgery using artificial neural networks. the artificial neural network model is a nonlinear technology useful for complex pattern recognition problems. this study aimed to develop a method to select risk variables and predict mortality after cardiac surgery by using artificial neural networks.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>hub gene identification and prognostic model construction for isocitrate dehydrogenase mutation in glioma. our study attempted to identify hub genes related to isocitrate dehydrogenase idh mutation in glioma and develop a prognostic model for idh-mutant glioma patients. in a first step ten hub genes significantly associated with the idh status were identified by weighted gene coexpression analysis wgcna . the functional enrichment analysis demonstrated that the most enriched terms of these hub genes were cadherin binding and glutathione metabolism. three of these hub genes were significantly linked with the survival of glioma patients. 328 samples of idh-mutant glioma were separated into two datasets: a training set n¯=¯228 and a test set n¯=¯100 . based on the training set we identified two idh-mutant subtypes with significantly different pathological features by using consensus clustering. a 31 gene-signature was identified by the least absolute shrinkage and selection operator lasso algorithm and used for establishing a differential prognostic model for idh-mutant patients. in addition the test set was employed for validating the prognostic model and the model was proven to be of high value in classifying prognostic information of samples. the functional annotation revealed that the genes related to the model were mainly enriched in nuclear division dna replication and cell cycle. collectively this study provided novel insights into the molecular mechanism of idh mutation in glioma and constructed a prognostic model which can be effective for predicting prognosis of glioma patients with idh-mutation which might promote the development of idh target agents in glioma therapies and contribute to accurate prognostication and management in idh-mutant glioma patients.</td>\n",
       "      <td>[10 hub genes significantly associated, 3 of these hub genes, 328 samples of idh , 2 datasets   , 2 idh   , 31 gene   ]</td>\n",
       "      <td>[first step 10, separated into 2, we identified 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[10 hub genes significantly associated, 3 of these hub genes, 328 samples of idh , 31 gene   ]</td>\n",
       "      <td>[10.0, 3.0, 328.0, 31.0]</td>\n",
       "      <td>328.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31644</th>\n",
       "      <td>deep learning-based classification of posttraumatic stress disorder and depression following trauma utilizing visual and auditory markers of arousal and mood. visual and auditory signs of patient functioning have long been used for clinical diagnosis treatment selection and prognosis. direct measurement and quantification of these signals can aim to improve the consistency sensitivity and scalability of clinical assessment. currently we investigate if machine learning-based computer vision cv semantic and acoustic analysis can capture clinical features from free speech responses to a brief interview 1 month post-trauma that accurately classify major depressive disorder mdd and posttraumatic stress disorder ptsd .</td>\n",
       "      <td>[1 month post  ]</td>\n",
       "      <td>[brief interview 1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107242</th>\n",
       "      <td>detection of systolic ejection click using time growing neural network. in this paper we present a novel neural network for classification of short-duration heart sounds: the time growing neural network tgnn . the input to the network is the spectral power in adjacent frequency bands as computed in time windows of growing length. children with heart systolic ejection click sec and normal children are the two groups subjected to analysis. the performance of the tgnn is compared to that of a time delay neural network tdnn and a multi-layer perceptron mlp using training and test datasets of similar sizes with a total of 614 normal and abnormal cardiac cycles. from the test dataset the classification rate/sensitivity is found to be 97.0%/98.1% for the tgnn 85.1%/76.4% for the tdnn and 92.7%/85.7% for the mlp. the results show that the tgnn performs better than do tdnn and mlp when frequency band power is used as classifier input. the performance of tgnn is also found to exhibit better immunity to noise.</td>\n",
       "      <td>[2 groups subjected to analysis, 614 normal and abnormal cardiac, 97.0 percent   , 85.1 percent   , 92.7 percent   ]</td>\n",
       "      <td>[are the 2, total of 614, to be 97.0, the tgnn 85.1, tdnn and 92.7]</td>\n",
       "      <td>[2 groups subjected to analysis]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158091</th>\n",
       "      <td>automatic detection and classification of abnormalities for artificial hearts using a hierarchical self-organizing map. a hierarchical self-organizing map som has been developed for automatic detection and classification of abnormalities for artificial hearts. the hierarchical som has been applied to the monitoring and analysis of an aortic pressure aop signal measured from an adult goat equipped with a total artificial heart. the architecture of the network actually consists of 2 different soms. the first som clusters the aop beat patterns in an unsupervised way. afterward the outputs of the first som combined with the original time-domain features of beat-to-beat data are fed to the second som for final classification. each input vector of the second som is associated with a class vector. this class vector is assigned to every node in the second map as an output weight and learned according to kohonen's learning rule. some experimental results revealed that a certain abnormality caused by breakage of sensors could be identified and detected correctly and that the change in the state of the circulatory system could be recognized and predicted to some extent.</td>\n",
       "      <td>[2 different soms  ]</td>\n",
       "      <td>[consists of 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112982</th>\n",
       "      <td>functional activity maps based on significance measures and independent component analysis. the use of functional imaging has been proven very helpful for the process of diagnosis of neurodegenerative diseases such as alzheimer's disease ad . in many cases the analysis of these images is performed by manual reorientation and visual interpretation. therefore new statistical techniques to perform a more quantitative analysis are needed. in this work a new statistical approximation to the analysis of functional images based on significance measures and independent component analysis ica is presented. after the images preprocessing voxels that allow better separation of the two classes are extracted using significance measures such as the mann-whitney-wilcoxon u-test mww and relative entropy re . after this feature selection step the voxels vector is modelled by means of ica extracting a few independent components which will be used as an input to the classifier. naive bayes and support vector machine svm classifiers are used in this work. the proposed system has been applied to two different databases. a 96-subjects single photon emission computed tomography spect database from the \"virgen de las nieves\" hospital in granada spain and a 196-subjects positron emission tomography pet database from the alzheimer's disease neuroimaging initiative adni . values of accuracy up to 96.9% and 91.3% for spect and pet databases are achieved by the proposed system which has yielded many benefits over methods proposed on recent works.</td>\n",
       "      <td>[2 classes are extracted using, 2 different databases  , 96    , 196    , 96.9 percent and  , 91.3 percent for spect and]</td>\n",
       "      <td>[of the 2, applied to 2, and a 196, up to 96.9]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19683</th>\n",
       "      <td>a tool for patient-specific prediction of delivery discrepancies in machine parameters using trajectory log files. multileaf collimator mlc delivery discrepancy between planned and actual delivered positions have detrimental effect on the accuracy of dose distributions for both imrt and vmat. in this study we evaluated the consistency of mlc delivery discrepancies over the course of treatment and over time to verify that a predictive machine learning model would be applicable throughout the course of treatment. next the mlc and gantry positions recorded in prior trajectory log files were analyzed to build a machine learning algorithm to predict mlc positional discrepancies during delivery for a new treatment plan. an open source tool was developed and released to predict the mlc positional discrepancies at treatment delivery for any given plan.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127417</th>\n",
       "      <td>co-morbidity analysis and decision support on transplanted patients using machine learning techniques. the a coruã±a university hospital complex is developing an expert system to improve the decision support for transplanted patients. the system will access the data collected during the monitoring of patients and generate a database of statistics that will aid health professionals in several stages of the transplant process. all historical data will be revised to give an estimation of the patient's parameters evolution depending on his medical record and his actual treatment. we will use two different machine learning techniques to do both clustering and classification.</td>\n",
       "      <td>[2 different machine learning techniques]</td>\n",
       "      <td>[will use 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11431</th>\n",
       "      <td>time-frequency time-space lstm for robust classification of physiological signals. automated analysis of physiological time series is utilized for many clinical applications in medicine and life sciences. long short-term memory lstm is a deep recurrent neural network architecture used for classification of time-series data. here time-frequency and time-space properties of time series are introduced as a robust tool for lstm processing of long sequential data in physiology. based on classification results obtained from two databases of sensor-induced physiological signals the proposed approach has the potential for 1 achieving very high classification accuracy 2 saving tremendous time for data learning and 3 being cost-effective and user-comfortable for clinical trials by reducing multiple wearable sensors for data recording.</td>\n",
       "      <td>[2 databases of sensor , 1 achieving very high classification, 2 saving tremendous time for, 3 being cost  ]</td>\n",
       "      <td>[obtained from 2, potential for 1, classification accuracy 2, learning and 3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2 saving tremendous time for, 2 saving tremendous time for]</td>\n",
       "      <td>[2.0, 2.0]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102714</th>\n",
       "      <td>a combined segmenting and non-segmenting approach to signal quality estimation for ambulatory photoplethysmography. continuous cardiac monitoring of healthy and unhealthy patients can help us understand the progression of heart disease and enable early treatment. optical pulse sensing is an excellent candidate for continuous mobile monitoring of cardiovascular health indicators but optical pulse signals are susceptible to corruption from a number of noise sources including motion artifact. therefore before higher-level health indicators can be reliably computed corrupted data must be separated from valid data. this is an especially difficult task in the presence of artifact caused by ambulation e.g. walking or jogging which shares significant spectral energy with the true pulsatile signal. in this manuscript we present a machine-learning-based system for automated estimation of signal quality of optical pulse signals that performs well in the presence of periodic artifact. we hypothesized that signal processing methods that identified individual heart beats segmenting approaches would be more error-prone than methods that did not non-segmenting approaches when applied to data contaminated by periodic artifact. we further hypothesized that a fusion of segmenting and non-segmenting approaches would outperform either approach alone. therefore we developed a novel non-segmenting approach to signal quality estimation that we then utilized in combination with a traditional segmenting approach. using this system we were able to robustly detect differences in signal quality as labeled by expert human raters pearson's r = 0.9263 . we then validated our original hypotheses by demonstrating that our non-segmenting approach outperformed the segmenting approach in the presence of contaminated signal and that the combined system outperformed either individually. lastly as an example we demonstrated the utility of our signal quality estimation system in evaluating the trustworthiness of heart rate measurements derived from optical pulse signals.</td>\n",
       "      <td>[0.9263    ]</td>\n",
       "      <td>[r = 0.9263]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29857</th>\n",
       "      <td>a combined deep cnn-lstm network for the detection of novel coronavirus covid-19 using x-ray images. nowadays automatic disease detection has become a crucial issue in medical science due to rapid population growth. an automatic disease detection framework assists doctors in the diagnosis of disease and provides exact consistent and fast results and reduces the death rate. coronavirus covid-19 has become one of the most severe and acute diseases in recent times and has spread globally. therefore an automated detection system as the fastest diagnostic option should be implemented to impede covid-19 from spreading. this paper aims to introduce a deep learning technique based on the combination of a convolutional neural network cnn and long short-term memory lstm to diagnose covid-19 automatically from x-ray images. in this system cnn is used for deep feature extraction and lstm is used for detection using the extracted feature. a collection of 4575 x-ray images including 1525 images of covid-19 were used as a dataset in this system. the experimental results show that our proposed system achieved an accuracy of 99.4% auc of 99.9% specificity of 99.2% sensitivity of 99.3% and f1-score of 98.9%. the system achieved desired results on the currently available dataset which can be further improved when more covid-19 images become available. the proposed system can help doctors to diagnose and treat covid-19 patients easily.</td>\n",
       "      <td>[4575 x   , 1525 images of covid , 99.4 percent auc of , 99.9 percent specificity of , 99.2 percent sensitivity of , 99.3 percent and f , 98.9 percent   ]</td>\n",
       "      <td>[collection of 4575, images including 1525, accuracy of 99.4, auc of 99.9, specificity of 99.2, sensitivity of 99.3]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1525 images of covid ]</td>\n",
       "      <td>[1525.0]</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60729</th>\n",
       "      <td>early prediction of critical events for infants with single-ventricle physiology in critical care using routinely collected data. critical events are common and difficult to predict among infants with congenital heart disease and are associated with mortality and long-term sequelae. we aimed to achieve early prediction of critical events that is cardiopulmonary resuscitation emergency endotracheal intubation and extracorporeal membrane oxygenation in infants with single-ventricle physiology before second-stage surgery. we hypothesized that naã¯ve bayesian models learned from expert knowledge and clinical data can predict critical events early and accurately.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100709</th>\n",
       "      <td>ultrasound-based characterization of prostate cancer using joint independent component analysis. this paper presents the results of a new approach for selection of rf time series features based on joint independent component analysis for in vivo characterization of prostate cancer.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13855</th>\n",
       "      <td>multiparametric mri-based radiomics approaches for preoperative prediction of egfr mutation status in spinal bone metastases in patients with lung adenocarcinoma. preoperative prediction of epidermal growth factor receptor egfr mutation status in patients with spinal bone metastases sbm from primary lung adenocarcinoma is potentially important for treatment decisions.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106809</th>\n",
       "      <td>disease prediction based on functional connectomes using a scalable and spatially-informed support vector machine. substantial evidence indicates that major psychiatric disorders are associated with distributed neural dysconnectivity leading to a strong interest in using neuroimaging methods to accurately predict disorder status. in this work we are specifically interested in a multivariate approach that uses features derived from whole-brain resting state functional connectomes. however functional connectomes reside in a high dimensional space which complicates model interpretation and introduces numerous statistical and computational challenges. traditional feature selection techniques are used to reduce data dimensionality but are blind to the spatial structure of the connectomes. we propose a regularization framework where the 6-d structure of the functional connectome defined by pairs of points in 3-d space is explicitly taken into account via the fused lasso or the graphnet regularizer. our method only restricts the loss function to be convex and margin-based allowing non-differentiable loss functions such as the hinge-loss to be used. using the fused lasso or graphnet regularizer with the hinge-loss leads to a structured sparse support vector machine svm with embedded feature selection. we introduce a novel efficient optimization algorithm based on the augmented lagrangian and the classical alternating direction method which can solve both fused lasso and graphnet regularized svm with very little modification. we also demonstrate that the inner subproblems of the algorithm can be solved efficiently in analytic form by coupling the variable splitting strategy with a data augmentation scheme. experiments on simulated data and resting state scans from a large schizophrenia dataset show that our proposed approach can identify predictive regions that are spatially contiguous in the 6-d \"connectome space\" offering an additional layer of interpretability that could provide new insights about various disease processes.</td>\n",
       "      <td>[6    , 3    , 6    ]</td>\n",
       "      <td>[where the 6, points in 3, in the 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126596</th>\n",
       "      <td>movement deviation profile: a measure of distance from normality using a self-organizing neural network. we introduce the movement deviation profile mdp which is a single curve showing the deviation of an individual's movement from normality. joint angles recorded from typically developing children over one gait cycle were used to train a self-organizing map som which then generated mdp curves for patients with gait problems. the mean mdp over the gait cycle showed a high correlation r 2 = .927 with the gait deviation index gdi a statistically significant difference between groups of patients with a range of functional levels gillette functional assessment questionnaire walking scale 7-10 and a trend of increasing values for patients with cerebral palsy through hemiplegia i-iv diplegia triplegia and quadriplegia. the small difference between the mdp and gdi can be explained by the som's method of operation comparing biomechanical patterns to the nearest abstract reference pattern and its flexibility to compensate for temporal shifts in movement data. the mdp is an alternative method of processing complex biomechanical data potentially supporting clinical interpretation. the electronic addendum accompanying this article is a standalone program which can be used to calculate the mdp from gait data and can also be used in other applications where the deviation of multi-channel temporal data from a reference is required.</td>\n",
       "      <td>[2    , .927 with the gait deviation, 7    ]</td>\n",
       "      <td>[correlation r 2, walking scale 7]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38305</th>\n",
       "      <td>an open-source computer vision tool for automated vocal fold tracking from videoendoscopy. contemporary clinical assessment of vocal fold adduction and abduction is qualitative and subjective. herein is described a novel computer vision tool for automated quantitative tracking of vocal fold motion from videolaryngoscopy. the potential of this software as a diagnostic aid in unilateral vocal fold paralysis is demonstrated.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39678</th>\n",
       "      <td>invertible network for classification and biomarker selection for asd. determining biomarkers for autism spectrum disorder asd is crucial to understanding its mechanisms. recently deep learning methods have achieved success in the classification task of asd using fmri data. however due to the black-box nature of most deep learning models it's hard to perform biomarker selection and interpret model decisions. the recently proposed invertible networks can accurately reconstruct the input from its output and have the potential to unravel the black-box representation. therefore we propose a novel method to classify asd and identify biomarkers for asd using the connectivity matrix calculated from fmri as the input. specifically with invertible networks we explicitly determine the decision boundary and the projection of data points onto the boundary. like linear classifiers the difference between a point and its projection onto the decision boundary can be viewed as the explanation. we then define the importance as the explanation weighted by the gradient of prediction w.r.t the input and identify biomarkers based on this importance measure. we perform a regression task to further validate our biomarker selection: compared to using all edges in the connectivity matrix using the top 10% important edges we generate a lower regression error on 6 different severity scores. our experiments show that the invertible network is both effective at asd classification and interpretable allowing for discovery of reliable biomarkers.</td>\n",
       "      <td>[10 percent important edges we, 6 different severity scores ]</td>\n",
       "      <td>[the top 10, error on 6]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>a method for enhancing speech and warning signals based on parallel convolutional neural networks in a noisy environment. digital hearing aids are based on technology that amplifies sound and removes noise according to the frequency of hearing loss in hearing loss patients. however within the noise removed is a warning sound that alert the listener; the listener may be exposed to danger because the warning sound is not recognized.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>feature selection and machine learning methods for optimal identification and prediction of subtypes in parkinson's disease. the present work focuses on assessment of parkinson's disease pd including both pd subtype identification unsupervised task and prediction supervised task . we specifically investigate optimal feature selection and machine learning algorithms for these tasks.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16556</th>\n",
       "      <td>clinicopathological features of fibrosarcomatous dermatofibrosarcoma protuberans and the construction of a back-propagation neural network recognition model. fibrosarcomatous dermatofibrosarcoma protuberans fs-dfsp is a form of tumor progression of dermatofibrosarcoma protuberans dfsp with an increased risk of metastasis and recurrence. few studies have compared the clinicopathological features of fs-dfsp and conventional dfsp c-dfsp .</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99096</th>\n",
       "      <td>recurrence quantification analysis and support vector machines for golf handicap and low back pain emg classification. the quantification of non-linear characteristics of electromyography emg must contain information allowing to discriminate neuromuscular strategies during dynamic skills. there are a lack of studies about muscle coordination under motor constrains during dynamic contractions. in golf both handicap hc and low back pain lbp are the main factors associated with the occurrence of injuries. the aim of this study was to analyze the accuracy of support vector machines svm on emg-based classification to discriminate hc low and high handicap and lbp with and without lpb in the main phases of golf swing. for this purpose recurrence quantification analysis rqa features of the trunk and the lower limb muscles were used to feed a svm classifier. recurrence rate rr and the ratio between determinism det and rr showed a high discriminant power. the hc accuracy for the swing backswing and downswing were 94.4±2.7% 97.1±2.3% and 95.3±2.6% respectively. for lbp the accuracy was 96.9±3.8% for the swing and 99.7±0.4% in the backswing. external oblique eo biceps femoris bf semitendinosus st and rectus femoris rf showed high accuracy depending on the laterality within the phase. rqa features and svm showed a high muscle discriminant capacity within swing phases by hc and by lbp. low back pain golfers showed different neuromuscular coordination strategies when compared with asymptomatic.</td>\n",
       "      <td>[94.4    , 97.1    , 95.3    , 96.9    , 99.7    ]</td>\n",
       "      <td>[downswing were 94.4, accuracy was 96.9, swing and 99.7]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47915</th>\n",
       "      <td>prospective validation of a machine learning model that uses provider notes to identify candidates for resective epilepsy surgery. delay to resective epilepsy surgery results in avoidable disease burden and increased risk of mortality. the objective was to prospectively validate a natural language processing nlp application that uses provider notes to assign epilepsy surgery candidacy scores.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59936</th>\n",
       "      <td>binary tree-like network with two-path fusion attention feature for cervical cell nucleus segmentation. early detection of cervical lesion is of great significance in reducing mortality from cervical cancer and segmentation of cervical cell nuclei plays an important role in screening for cervical lesion. compared with traditional algorithms several deep learning methods can improve the segmentation; however due to blurred boundaries and complex gradients of medical images the segmentation remains unsatisfactory. in addition the existing datasets used by cervical cell nucleus segmentation research are lacking in terms of both quantity and diversity so methods based on those datasets cannot effectively cope with challenging cases. this paper releases a new cervical cell dataset and proposes a network named binary tree-like network with two-path fusion attention feature bttfa . the simplified diagram of bttfa is similar to a binary tree structure and combines resnext's last four layers of information by integrating adjacent pairs of layers each time; therefore the information of multilayers can be fully integrated and the information lost by the pooling layers can be recovered. bttfa also applies a two-path fusion attention to selectively utilize information close to the root nodes thereby taking full advantage of low-level detail and high-level semantic information and selectively emphasizing important features while suppressing less useful ones. meanwhile at some nodes of the binary tree-like network focal loss is imposed to calculate the loss between the ground truth and the feature map during the training process. experiments demonstrate that bttfa performs better than the existing technology on our dataset and another public dataset.</td>\n",
       "      <td>[4 layers of information by]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33766</th>\n",
       "      <td>prediction of inter-fractional radiotherapy dose plans with domain translation in spatiotemporal embeddings. external beam radiation therapy fractions have become extremely complex and tedious procedures to plan due to stringent requirements of delivering the highest radiation dose to the tumor while maximally avoiding organs at risk. however due to anatomic and/or biological changes between fractions dose re-optimization may be needed. re-optimization is a time-consuming task which is typically triggered based on subjective visual assessment by an experienced physician. to address limitations in this process we introduce a predictive framework which learns the evolution of tumor anatomy as well as inter-fractional dose delivery variations for head and neck cancers. first joint low-dimensional discriminant embeddings maximizing the separation between responsive and non-responsive groups to external beam radiotherapy plans are constructed from deep neural networks in order to capture patient-specific dose modulations with respect to anatomical variations. then latent representations are fed to a domain-level adversarial network to translate observed anatomical changes into dosimetric variations which aims to enforce local semantic consistency in the overall translation. dose distribution trajectories are represented in a group-average piecewise-geodesic setting to handle anatomical variations during therapy using a quadratic optimization to perform curve regression. at test time an annotated baseline ct is projected onto the latent space and translated to dose domain from which a spatiotemporal regression model is constructed using parallel transport trajectories defined from closest samples. this allows to predict dosimetry changes during the course of treatment. the model was trained on 337 cases and tested on 50 separate patients using sequential ct and associated dosimetry data with the probabilistic framework yielding a dice score of 92% and an overall dose difference of 1.2 gy in organs at risk and tumor volume over the course of multi-day treatment course with a 5% reduction in delivered fraction segments.</td>\n",
       "      <td>[337 cases and tested on, 50 separate patients using sequential, 92 percent and an overall, 1.2 gy in organs at, 5 percent reduction in delivered]</td>\n",
       "      <td>[trained on 337, tested on 50, score of 92, difference of 1.2, with a 5]</td>\n",
       "      <td>[337 cases and tested on, 50 separate patients using sequential]</td>\n",
       "      <td>[337.0, 50.0]</td>\n",
       "      <td>337.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14150</th>\n",
       "      <td>machine learning-based decision model to distinguish between covid-19 and influenza: a retrospective two-centered diagnostic study. considering the current situation of the novel coronavirus disease covid-19 epidemic control it is highly likely that covid-19 and influenza may coincide during the approaching winter season. however there is no available tool that can rapidly and precisely distinguish between these two diseases in the absence of laboratory evidence of specific pathogens.</td>\n",
       "      <td>[2 diseases in the absence]</td>\n",
       "      <td>[between these 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140094</th>\n",
       "      <td>spiculation-preserving polygonal modeling of contours of breast tumors. malignant breast tumors typically appear in mammograms with rough spiculated or microlobulated contours whereas most benign masses have smooth round oval or macrolobulated contours. several studies have shown that shape factors that incorporate differences as above can provide high accuracies in distinguishing between malignant tumors and benign masses based upon their contours only. however global measures of roughness such as compactness are less effective than specially designed features based upon spicularity and concavity. we propose a method to derive polygonal models of contours that preserve spicules and details of diagnostic importance. we show that an index of spiculation derived from the turning functions of the polygonal models obtained by the proposed method yields better classification accuracy than a similar measure derived using a previously published method. the methods were tested with a set of 111 contours of 65 benign masses and 46 malignant tumors. a high classification accuracy of 0.93 in terms of the area under the receiver operating characteristics curve was obtained.</td>\n",
       "      <td>[111 contours of  , 65 benign masses and , 46 malignant tumors  , 0.93 in terms of the]</td>\n",
       "      <td>[set of 111, contours of 65, masses and 46, accuracy of 0.93]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30848</th>\n",
       "      <td>deep learning for risk prediction in patients with nasopharyngeal carcinoma using multi-parametric mris. magnetic resonance images mri is the main diagnostic tool for risk stratification and treatment decision in nasopharyngeal carcinoma npc . however the holistic feature information of multi-parametric mris has not been fully exploited by clinicians to accurately evaluate patients.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28475</th>\n",
       "      <td>automatic deep learning-based colorectal adenoma detection system and its similarities with pathologists. the microscopic evaluation of slides has been gradually moving towards all digital in recent years leading to the possibility for computer-aided diagnosis. it is worthwhile to know the similarities between deep learning models and pathologists before we put them into practical scenarios. the simple criteria of colorectal adenoma diagnosis make it to be a perfect testbed for this study.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19327</th>\n",
       "      <td>predicting the development of surgery-related pressure injury using a machine learning algorithm model. surgery-related pressure injury srpi is a serious problem in patients who undergo cardiovascular surgery. identifying patients at a high risk of srpi is important for clinicians to recognize and prevent it expeditiously. machine learning ml has been widely used in the field of healthcare and is well suited to predictive analysis.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58269</th>\n",
       "      <td>a new diagnostic approach for the identification of patients with neurodegenerative cognitive complaints. neurodegenerative diseases causing dementia are known to affect a person's speech and language. part of the expert assessment in memory clinics therefore routinely focuses on detecting such features. the current outpatient procedures examining patients' verbal and interactional abilities mainly focus on verbal recall word fluency and comprehension. by capturing neurodegeneration-associated characteristics in a person's voice the incorporation of novel methods based on the automatic analysis of speech signals may give us more information about a person's ability to interact which could contribute to the diagnostic process. in this proof-of-principle study we demonstrate that purely acoustic features extracted from recordings of patients' answers to a neurologist's questions in a specialist memory clinic can support the initial distinction between patients presenting with cognitive concerns attributable to progressive neurodegenerative disorders nd or functional memory disorder fmd i.e. subjective memory concerns unassociated with objective cognitive deficits or a risk of progression . the study involved 15 fmd and 15 nd patients where a total of 51 acoustic features were extracted from the recordings. feature selection was used to identify the most discriminating features which were then used to train five different machine learning classifiers to differentiate between the fmd/nd classes achieving a mean classification accuracy of 96.2%. the discriminative power of purely acoustic approaches could be integrated into diagnostic pathways for patients presenting with memory concerns and are computationally less demanding than methods focusing on linguistic elements of speech and language that require automatic speech recognition and understanding.</td>\n",
       "      <td>[15 fmd and  , 15 nd patients where a, 51 acoustic features were extracted, 5 different machine learning classifiers, 96.2 percent   ]</td>\n",
       "      <td>[study involved 15, fmd and 15, total of 51, to train 5, accuracy of 96.2]</td>\n",
       "      <td>[15 nd patients where a]</td>\n",
       "      <td>[15.0]</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79418</th>\n",
       "      <td>functional brain dynamic analysis of adhd and control children using nonlinear dynamical features of eeg signals. attention deficit hyperactivity disorder is a neurodevelopmental condition associated with varying levels of hyperactivity inattention and impulsivity. this study investigates brain function in children with attention deficit hyperactivity disorder using measures of nonlinear dynamics in eeg signals during rest. during eyes-closed resting 19 channel eeg signals were recorded from 12 adhd and 12 normal age-matched children. we used the multifractal singularity spectrum the largest lyapunov exponent and approximate entropy to quantify the chaotic nonlinear dynamics of these eeg signals. as confirmed by wilcoxon rank sum test largest lyapunov exponent over left frontal-central cortex exhibited a significant difference between adhd and the age-matched control groups. further mean approximate entropy was significantly lower in adhd subjects in prefrontal cortex. the singularity spectrum was also considerably altered in adhd compared to control children. evaluation of these features was performed by two classifiers: a support vector machine and a radial basis function neural network. for better comparison subject classification based on frequency band power was assessed using the same types of classifiers. nonlinear features provided better discrimination between adhd and control than band power features. under four-fold cross validation testing support vector machine gave 83.33% accurate classification results.</td>\n",
       "      <td>[19 channel eeg signals were, 12 adhd and  , 12 normal age  , 2 classifiers   , 83.33 percent accurate classification results]</td>\n",
       "      <td>[recorded from 12, adhd and 12, performed by 2, machine gave 83.33]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[19 channel eeg signals were]</td>\n",
       "      <td>[19.0]</td>\n",
       "      <td>19.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113272</th>\n",
       "      <td>automatic generation of case-detection algorithms to identify children with asthma from large electronic health record databases. most electronic health record databases contain unstructured free-text narratives which cannot be easily analyzed. case-detection algorithms are usually created manually and often rely only on using coded information such as international classification of diseases version 9 codes. we applied a machine-learning approach to generate and evaluate an automated case-detection algorithm that uses both free-text and coded information to identify asthma cases.</td>\n",
       "      <td>[9 codes   ]</td>\n",
       "      <td>[diseases version 9]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94548</th>\n",
       "      <td>model comparison for breast cancer prognosis based on clinical data. we compared the performance of several prediction techniques for breast cancer prognosis based on au-roc performance area under roc for different prognosis periods. the analyzed dataset contained 1981 patients and from an initial 25 variables the 11 most common clinical predictors were retained. we compared eight models from a wide spectrum of predictive models namely; generalized linear model glm glm-net partial least square pls support vector machines svm random forests rf neural networks k-nearest neighbors k-nn and boosted trees. in order to compare these models paired t-test was applied on the model performance differences obtained from data resampling. random forests boosted trees partial least square and glmnet have superior overall performance however they are only slightly higher than the other models. the comparative analysis also allowed us to define a relative variable importance as the average of variable importance from the different models. two sets of variables are identified from this analysis. the first includes number of positive lymph nodes tumor size cancer grade and estrogen receptor all has an important influence on model predictability. the second set incudes variables related to histological parameters and treatment types. the short term vs long term contribution of the clinical variables are also analyzed from the comparative models. from the various cancer treatment plans the combination of chemo/radio therapy leads to the largest impact on cancer prognosis.</td>\n",
       "      <td>[1981 patients and from an, 25 variables the  , 11 most common clinical predictors, 8 models from a wide, 2 sets of variables are]</td>\n",
       "      <td>[dataset contained 1981, an initial 25, variables the 11, we compared 8]</td>\n",
       "      <td>[1981 patients and from an]</td>\n",
       "      <td>[1981.0]</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104960</th>\n",
       "      <td>a food recognition system for diabetic patients based on an optimized bag-of-features model. computer vision-based food recognition could be used to estimate a meal's carbohydrate content for diabetic patients. this study proposes a methodology for automatic food recognition based on the bag-of-features bof model. an extensive technical investigation was conducted for the identification and optimization of the best performing components involved in the bof architecture as well as the estimation of the corresponding parameters. for the design and evaluation of the prototype system a visual dataset with nearly 5000 food images was created and organized into 11 classes. the optimized system computes dense local features using the scale-invariant feature transform on the hsv color space builds a visual dictionary of 10000 visual words by using the hierarchical k-means clustering and finally classifies the food images with a linear support vector machine classifier. the system achieved classification accuracy of the order of 78% thus proving the feasibility of the proposed approach in a very challenging image dataset.</td>\n",
       "      <td>[5000 food images was created, 11 classes   , 10000 visual words by using, 78 percent thus proving the]</td>\n",
       "      <td>[with nearly 5000, organized into 11, dictionary of 10000, order of 78]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[5000 food images was created]</td>\n",
       "      <td>[5000.0]</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21600</th>\n",
       "      <td>accuracy of machine learning-based prediction of medication adherence in clinical research. medication non-adherence represents a significant barrier to treatment efficacy. remote real-time measurement of medication dosing can facilitate dynamic prediction of risk for medication non-adherence which in-turn allows for proactive clinical intervention to optimize health outcomes. we examine the accuracy of dynamic prediction of non-adherence using data from remote real-time measurements of medication dosing. participants across a large set of clinical trials n = 4182 were observed via a smartphone application that video records patients taking their prescribed medication. the patients' primary diagnosis demographics and prior indication of observed adherence/non-adherence were utilized to predict 1 adherence rates ¥ 80% across the clinical trial 2 adherence ¥ 80% for the subsequent week and 3 adherence the subsequent day using machine learning-based classification models. empirically observed adherence was demonstrated to be the strongest predictor of future adherence/non-adherence. collectively the classification models accurately predicted adherence across the trial auc = 0.83 the subsequent week auc = 0.87 and the subsequent day auc = 0.87 . real-time measurement of dosing can be utilized to dynamically predict medication adherence with high accuracy.</td>\n",
       "      <td>[4182 were observed via a, 1 adherence rates  , 80 percent across the clinical, 2 adherence   , 80 percent for the subsequent, 3 adherence the subsequent day, 0.83 the subsequent week auc, 0.87 and the subsequent day, 0.87    ]</td>\n",
       "      <td>[n = 4182, to predict 1, clinical trial 2, week and 3, auc = 0.83, auc = 0.87, auc = 0.87]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[n = 4182]</td>\n",
       "      <td>[4182.0]</td>\n",
       "      <td>4182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126118</th>\n",
       "      <td>automatic detection and segmentation of axillary lymph nodes. lymph node detection and measurement is a difficult and important part of cancer treatment. in this paper we present a robust and effective learning-based method for the automatic detection of solid lymph nodes from computed tomography data. the contributions of the paper are the following. first it presents a learning based approach to lymph node detection based on marginal space learning. second it presents an efficient mrf-based segmentation method for solid lymph nodes. third it presents two new sets of features one set self-aligning to the local gradients and another set based on the segmentation result. an extensive evaluation on 101 volumes containing 362 lymph nodes shows that this method obtains a 82.3% detection rate at 1 false positive per volume with an average running time of 5-20 seconds per volume.</td>\n",
       "      <td>[2 new sets of features, 101 volumes containing  , 362 lymph nodes shows that, 82.3 percent detection rate at, 1 false positive per volume, 5    ]</td>\n",
       "      <td>[it presents 2, evaluation on 101, volumes containing 362, obtains a 82.3, rate at 1, time of 5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84388</th>\n",
       "      <td>defining a multimodal signature of remote sports concussions. sports-related concussions lead to persistent anomalies of the brain structure and function that interact with the effects of normal ageing. although post-mortem investigations have proposed a bio-signature of remote concussions there is still no clear in vivo signature. in the current study we characterized white matter integrity in retired athletes with a history of remote concussions by conducting a full-brain diffusion-based connectivity analysis. next we combined mri diffusion markers with mr spectroscopic mri volumetric neurobehavioral and genetic markers to identify a multidimensional in vivo signature of remote concussions. machine learning classifiers trained to detect remote concussions using this signature achieved detection accuracies up to 90% sensitivity: 93% specificity: 87% . these automated classifiers identified white matter integrity as the hallmark of remote concussions and could provide following further validation a preliminary unbiased detection tool to help medical and legal experts rule out concussion history in patients presenting or complaining about late-life abnormal cognitive decline.</td>\n",
       "      <td>[90 percent sensitivity  , 93 percent specificity  , 87 percent   ]</td>\n",
       "      <td>[up to 90]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100344</th>\n",
       "      <td>multi-scale textural feature extraction and particle swarm optimization based model selection for false positive reduction in mammography. the high number of false positives and the resulting number of avoidable breast biopsies are the major problems faced by current mammography computer aided detection cad systems. false positive reduction is not only a requirement for mass but also for calcification cad systems which are currently deployed for clinical use. this paper tackles two problems related to reducing the number of false positives in the detection of all lesions and masses respectively. firstly textural patterns of breast tissue have been analyzed using several multi-scale textural descriptors based on wavelet and gray level co-occurrence matrix. the second problem addressed in this paper is the parameter selection and performance optimization. for this we adopt a model selection procedure based on particle swarm optimization pso for selecting the most discriminative textural features and for strengthening the generalization capacity of the supervised learning stage based on a support vector machine svm classifier. for evaluating the proposed methods two sets of suspicious mammogram regions have been used. the first one obtained from digital database for screening mammography ddsm contains 1494 regions 1000 normal and 494 abnormal samples . the second set of suspicious regions was obtained from database of mammographic image analysis society mini-mias and contains 315 207 normal and 108 abnormal samples. results from both datasets demonstrate the efficiency of using pso based model selection for optimizing both classifier hyper-parameters and parameters respectively. furthermore the obtained results indicate the promising performance of the proposed textural features and more specifically those based on co-occurrence matrix of wavelet image representation technique.</td>\n",
       "      <td>[2 problems related to reducing, 2 sets of suspicious mammogram, 1494 regions   , 1000 normal and  , 494 abnormal samples  , 315    , 207 normal and  , 108 abnormal samples  ]</td>\n",
       "      <td>[paper tackles 2, proposed methods 2, ddsm contains 1494, normal and 494, and contains 315, normal and 108]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2 sets of suspicious mammogram, 2 sets of suspicious mammogram, 494 abnormal samples  , 108 abnormal samples  ]</td>\n",
       "      <td>[2.0, 2.0, 494.0, 108.0]</td>\n",
       "      <td>494.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94794</th>\n",
       "      <td>feature extraction using time-frequency analysis for monophonic-polyphonic wheeze discrimination. the aim of this study is monophonic-polyphonic wheeze episode discrimination rather than the conventional wheeze versus non-wheeze episode detection. we used two different methods for feature extraction to discriminate monophonic and polyphonic wheeze episodes. one of the methods is based on frequency analysis and the other is based on time analysis. frequency analysis based method uses ratios of quartile frequencies to exploit the difference in the power spectrum. time analysis based method uses mean crossing irregularity to exploit the difference in periodicity in the time domain. both methods are applied on the data before and after an image processing based preprocessing step. calculated features are used in classification both individually and in combinations. support vector machine k-nearest neighbor and naive bayesian classifiers are adopted in leave-one-out scheme. a total of 121 monophonic and 110 polyphonic wheeze episodes are used in the experiments where the best classification performances are 71.45% for time domain based features 68.43% for frequency domain based features and 75.78% for a combination of selected best features.</td>\n",
       "      <td>[2 different methods for feature, 121 monophonic and  , 110 polyphonic wheeze episodes are, 71.45 percent for time domain, 68.43 percent for frequency domain, 75.78 percent for a combination]</td>\n",
       "      <td>[we used 2, total of 121, monophonic and 110, performances are 71.45, based features 68.43, features and 75.78]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13819</th>\n",
       "      <td>mass image synthesis in mammogram with contextual information based on gans. in medical imaging the scarcity of labeled lesion data has hindered the application of many deep learning algorithms. to overcome this problem the simulation of diverse lesions in medical images is proposed. however synthesizing labeled mass images in mammograms is still challenging due to the lack of consistent patterns in shape margin and contextual information. therefore we aim to generate various labeled medical images based on contextual information in mammograms.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139895</th>\n",
       "      <td>characterization of carotid atherosclerotic plaques using frequency-based texture analysis and bootstrap. texture analysis of b-mode ultrasound images of carotid atheromatous plaque can be valuable for the accurate diagnosis of atherosclerosis. in this paper two frequency-based texture analysis methods based on the fourier power spectrum and the wavelet transform were used to characterize atheromatous plaques. b-mode ultrasound images of 10 symptomatic and 9 asymptomatic plaques were interrogated. a total of 109 texture features were estimated for each plaque. the bootstrap method was used to compare the mean values of the texture features extracted from the two groups. after bootstrapping three features were found to be significantly different between the two types of plaques: the average value of the angular distribution corresponding to the wedge centered at 90 degrees the standard deviation at scale 1 derived from the horizontal detail image and the standard deviation at scale 2 derived from the horizontal detail image. it is concluded that frequency-based texture analysis in combination with a powerful statistical technique such as bootstrapping may provide valuable information about the plaque tissue type.</td>\n",
       "      <td>[2 frequency   , 10 symptomatic and  , 9 asymptomatic plaques were interrogated, 109 texture features were estimated, 2 groups   , 3 features were found to, 2 types of plaques , 90 degrees the standard deviation, 1 derived from the horizontal, 2 derived from the horizontal]</td>\n",
       "      <td>[this paper 2, images of 10, symptomatic and 9, total of 109, from the 2, after bootstrapping 3, between the 2, centered at 90, at scale 1, at scale 2]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47655</th>\n",
       "      <td>application of preoperative artificial neural network based on blood biomarkers and clinicopathological parameters for predicting long-term survival of patients with gastric cancer. because of the powerful abilities of self-learning and handling complex biological information artificial neural network ann models have been widely applied to disease diagnosis imaging analysis and prognosis prediction. however there has been no trained preoperative ann preope-ann model to preoperatively predict the prognosis of patients with gastric cancer gc .</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92009</th>\n",
       "      <td>diagnostic classification of adhd versus control: support vector machine classification using brief neuropsychological assessment. objective: common methods for clinical diagnosis include clinical interview behavioral questionnaires and neuropsychological assessment. these methods rely on clinical interpretation and have variable reliability sensitivity and specificity. the goal of this study was to evaluate the utility of machine learning in the prediction and classification of children with adhd-combined presentation adhd-c using brief neuropsychological measures d2 test of attention children with adhd-c and typically developing control children completed semi-structured clinical interviews and measures of attention/concentration and parents completed symptom severity questionnaires. method: we used a forward feature selection method to identify the most informative neuropsychological features for support vector machine svm classification and a decision tree model to derive a rule-based model. results: the svm model yielded excellent classification accuracy 100% of individual children with and without adhd 1.0 . decision tree algorithms identified individuals with and without adhd-c with 100% sensitivity and specificity. conclusion:this study observed highly accurate statistical diagnostic classification at the individual level in a sample of children with adhd-c. the findings suggest data-driven behavioral algorithms based on brief neuropsychological data may present an efficient and accurate diagnostic tool for clinicians.</td>\n",
       "      <td>[100 percent of individual children, 1.0    , 100 percent sensitivity and specificity]</td>\n",
       "      <td>[classification accuracy 100, without adhd 1.0]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>detection of lung cancer on computed tomography using artificial intelligence applications developed by deep learning methods and the contribution of deep learning to the classification of lung carcinoma. in every year lung cancer is an important cause of deaths in the world. early detection of lung cancer is important for treatment and non-invasive rapid methods are needed for diagnosis.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "134590                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     evaluation of a dynamic bayesian belief network to predict osteoarthritic knee pain using data from the osteoarthritis initiative. the most common cause of disability in older adults in the united states is osteoarthritis. to address the problem of early disease prediction we have constructed a bayesian belief network bbn composed of knee oa-related symptoms to support prognostic queries. the purpose of this study is to evaluate a static and dynamic bbn--based on the nih osteoarthritis initiative oai data--in predicting the likelihood of a patient being diagnosed with knee oa. initial validation results are promising: our model outperforms a logistic regression model in several designed studies. we can conclude that our model can effectively predict the symptoms that are commonly associated with the presence of knee oa.   \n",
       "121837                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                a cellular neural network methodology for the automated segmentation of multiple sclerosis lesions. we present a new application based on genetic algorithms gas that evolves a cellular neural network cnn capable of automatically determining the lesion load in multiple sclerosis ms patients from magnetic resonance imaging mri . in particular it seeks to identify brain areas affected by lesions whose presence is revealed by areas of higher intensity if compared to healthy tissue. the performance of the cnn algorithm has been quantitatively evaluated by comparing the cnn output with the expert's manual delineation of ms lesions. the cnn algorithm was run on a data set of 11 ms patients; for each one a single dataset of mri images matrix resolution of 256ã—256 pixels was acquired. our automated approach gives satisfactory results showing that after the learning process the cnn is capable of detecting ms lesions with different shapes and intensities mean dice coefficient=0.64 . the system could provide a useful support tool for the evaluation of lesions in ms patients although it needs to be evolved and developed in the future.   \n",
       "89006                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     evaluating stability of histomorphometric features across scanner and staining variations: prostate cancer diagnosis from whole slide images. quantitative histomorphometry qh is the process of computerized feature extraction from digitized tissue slide images to predict disease presence behavior and outcome. feature stability between sites may be compromised by laboratory-specific variables including dye batch slice thickness and the whole slide scanner used. we present two new measures preparation-induced instability score and latent instability score to quantify feature instability across and within datasets. in a use case involving prostate cancer we examined qh features which may detect cancer on whole slide images. using our method we found that five feature families graph shape co-occurring gland tensor sub-graph and texture were different between datasets in 19.7% to 48.6% of comparisons while the values expected without site variation were 4.2% to 4.6%. color normalizing all images to a template did not reduce instability. scanning the same 34 slides on three scanners demonstrated that haralick features were most substantively affected by scanner variation being unstable in 62% of comparisons. we found that unstable feature families performed significantly worse in inter- than intrasite classification. our results appear to suggest qh features should be evaluated across sites to assess robustness and class discriminability alone should not represent the benchmark for digital pathology feature selection.   \n",
       "8982                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      sell and ifi44 as potential biomarkers of sjã¶gren's syndrome and their correlation with immune cell infiltration. the onset of sjã¶gren's syndrome ss is hidden early diagnosis is difficult and the disorder seriously endangers the physical and mental health of affected people. this study aims to identify potential biomarkers of ss and to investigate the characteristics of immune cell infiltration. we used four ss gene expression profile data series from the gene expression omnibus database and applied bioinformatics analysis and machine learning algorithms to screen two biomarkers sell l-selectin and ifi44 interferon-induced protein 44 from 101 differentially expressed genes. the two-gene model comprising sell and ifi44 showed good diagnostic ability for ss in the training set auc = 0.992 and verification set auc = 0.917 . analysis of infiltrating immune cells in ss identified naive b cells resting cd4 memory t cells activated cd4 memory t cells gamma delta t cells m0 macrophages m1 macrophages plasma cells cd8 t cells activated nk cells and monocytes as candidate participants in the ss process. furthermore sell was associated with m2 macrophages activated cd4 memory t cells gamma delta t cells resting nk cells and plasma cells while ifi44 was associated with activated mast cells resting nk cells resting mast cells and cd8 t cells. this study demonstrates that sell and ifi44 can serve as good diagnostic markers for ss and may also be new diagnostic and therapeutic targets for ss.   \n",
       "14701                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                prospective development and validation of a liquid immune profile-based signature lips to predict response of patients with recurrent/metastatic cancer to immune checkpoint inhibitors. the predictive power of novel biological markers for treatment response to immune checkpoint inhibitors ici is still not satisfactory for the majority of patients with cancer. one should identify valid predictive markers in the peripheral blood as this is easily available before and during treatment. the current interim analysis of patients of the st-ici cohort therefore focuses on the development and validation of a liquid immune profile-based signature lips to predict response of patients with metastatic cancer to ici targeting the programmed cell death protein 1 pd-1 /programmed cell death-ligand 1 pd-l1 axis.   \n",
       "20454                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              covid-19 mortality risk assessment: an international multi-center study. timely identification of covid-19 patients at high risk of mortality can significantly improve patient management and resource allocation within hospitals. this study seeks to develop and validate a data-driven personalized mortality risk calculator for hospitalized covid-19 patients. de-identified data was obtained for 3927 covid-19 positive patients from six independent centers comprising 33 different hospitals. demographic clinical and laboratory variables were collected at hospital admission. the covid-19 mortality risk cmr tool was developed using the xgboost algorithm to predict mortality. its discrimination performance was subsequently evaluated on three validation cohorts. the derivation cohort of 3062 patients has an observed mortality rate of 26.84%. increased age decreased oxygen saturation ¤ 93% elevated levels of c-reactive protein ¥ 130 mg/l blood urea nitrogen ¥ 18 mg/dl and blood creatinine ¥ 1.2 mg/dl were identified as primary risk factors validating clinical findings. the model obtains out-of-sample aucs of 0.90 95% ci 0.87-0.94 on the derivation cohort. in the validation cohorts the model obtains aucs of 0.92 95% ci 0.88-0.95 on seville patients 0.87 95% ci 0.84-0.91 on hellenic covid-19 study group patients and 0.81 95% ci 0.76-0.85 on hartford hospital patients. the cmr tool is available as an online application at covidanalytics.io/mortality_calculator and is currently in clinical use. the cmr model leverages machine learning to generate accurate mortality predictions using commonly available clinical features. this is the first risk score trained and validated on a cohort of covid-19 patients from europe and the united states.   \n",
       "94867                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     effects of prosthesis use on the capability to control myoelectric robotic prosthetic hands. the natural control of robotic prosthetic hands with non-invasive techniques is still a challenge: myoelectric prostheses currently give some control capabilities; the application of pattern recognition techniques is promising and recently started to be applied in practice but still many questions are open in the field. in particular the effects of clinical factors on movement classification accuracy and the capability to control myoelectric prosthetic hands are analyzed in very few studies. the effect of regularly using prostheses on movement classification accuracy has been previously studied showing differences between users of myoelectric and cosmetic prostheses. in this paper we compare users of myoelectric and body-powered prostheses and intact subjects. 36 machine-learning methods are applied on 6 amputees and 40 intact subjects performing 40 movements. then statistical analyses are performed in order to highlight significant differences between the groups of subjects. the statistical analyses do not show significant differences between the two groups of amputees while significant differences are obtained between amputees and intact subjects. these results constitute new information in the field and suggest new interpretations to previous hypotheses thus adding precious information towards natural control of robotic prosthetic hands.    \n",
       "39213                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         automated detection of vestibular schwannoma growth using a two-dimensional u-net convolutional neural network. to determine if an automated vestibular schwannoma vs segmentation model has comparable performance to using the greatest linear dimension to detect growth.   \n",
       "82669                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     spinenet: automated classification and evidence visualization in spinal mris. the objective of this work is to automatically produce radiological gradings of spinal lumbar mris and also localize the predicted pathologies. we show that this can be achieved via a convolutional neural network cnn framework that takes intervertebral disc volumes as inputs and is trained only on disc-specific class labels. our contributions are: i a cnn architecture that predicts multiple gradings at once and we propose variants of the architecture including using 3d convolutions; ii showing that this architecture can be trained using a multi-task loss function without requiring segmentation level annotation; and iii a localization method that clearly shows pathological regions in the disc volumes. we compare three visualization methods for the localization. the network is applied to a large corpus of mri t2 sagittal spinal mris using a standard clinical scan protocol acquired from multiple machines and is used to automatically compute disk and vertebra gradings for each mri. these are: pfirrmann grading disc narrowing upper/lower endplate defects upper/lower marrow changes spondylolisthesis and central canal stenosis. we report near human performances across the eight gradings and also visualize the evidence for these gradings localized on the original scans.   \n",
       "30146                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         a deep-learning approach for automated oct en-face retinal vessel segmentation in cases of optic disc swelling using multiple en-face images as input. in cases of optic disc swelling segmentation of projected retinal blood vessels from optical coherence tomography oct volumes is challenging due to swelling-based shadowing artifacts. based on our hypothesis that simultaneously considering vessel information from multiple projected retinal layers can substantially increase vessel visibility in this work we propose a deep-learning-based approach to segment vessels involving the simultaneous use of three oct en-face images as input.   \n",
       "72715                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    deep learning models to remix music for cochlear implant users. the severe hearing loss problems that some people suffer can be treated by providing them with a surgically implanted electrical device called cochlear implant ci . ci users struggle to perceive complex audio signals such as music; however previous studies show that ci recipients find music more enjoyable when the vocals are enhanced with respect to the background music. in this manuscript source separation ss algorithms are used to remix pop songs by applying gain to the lead singing voice. this work uses deep convolutional auto-encoders a deep recurrent neural network a multilayer perceptron mlp and non-negative matrix factorization to be evaluated objectively and subjectively through two different perceptual experiments which involve normal hearing subjects and ci recipients. the evaluation assesses the relevance of the artifacts introduced by the ss algorithms considering their computation time as this study aims at proposing one of the algorithms for real-time implementation. results show that the mlp performs in a robust way throughout the tested data while providing levels of distortions and artifacts which are not perceived by ci users. thus an mlp is proposed to be implemented for real-time monaural audio ss to remix music for ci users.   \n",
       "122198                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             seven-days-ahead forecasting of childhood asthma admissions using artificial neural networks in athens greece. artificial neural network ann models were developed and applied in order to predict the total weekly number of childhood asthma admission caa at the greater athens area gaa in greece. hourly meteorological data from the national observatory of athens and ambient air pollution data from seven different areas within the gaa for the period 2001-2004 were used. asthma admissions for the same period were obtained from hospital registries of the three main children's hospitals of athens. three different ann models were developed and trained in order to forecast the caa for the subgroups of 0-4 5-14-year olds and for the whole study population. the results of this work have shown that anns could give an adequate forecast of the total weekly number of caa in relation to the bioclimatic and air pollution conditions. the forecasted numbers are in very good agreement with the observed real total weekly numbers of caa.   \n",
       "24232                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    internet of things and machine learning for healthy ageing: identifying the early signs of dementia. identifying the symptoms of the early stages of dementia is a difficult task particularly for older adults living in residential care. internet of things iot and smart environments can assist with the early detection of dementia by nonintrusive monitoring of the daily activities of the older adults. in this work we focus on the daily life activities of adults in a smart home setting to discover their potential cognitive anomalies using a public dataset. after analysing the dataset extracting the features and selecting distinctive features based on dynamic ranking a classification model is built. we compare and contrast several machine learning approaches for developing a reliable and efficient model to identify the cognitive status of monitored adults. using our predictive model and our approach of distinctive feature selection we have achieved 90.74% accuracy in detecting the onset of dementia.   \n",
       "60238                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     passenger mutations accurately classify human tumors. determining the cancer type and molecular subtype has important clinical implications. the primary site is however unknown for some malignancies discovered in the metastatic stage. moreover liquid biopsies may be used to screen for tumoral dna which upon detection needs to be assigned to a site-of-origin. classifiers based on genomic features are a promising approach to prioritize the tumor anatomical site type and subtype. we examined the predictive ability of causal driver somatic mutations in this task comparing it against global patterns of non-selected passenger mutations including features based on regional mutation density rmd . in the task of distinguishing 18 cancer types the driver mutations-mutated oncogenes or tumor suppressors pathways and hotspots-classified 36% of the patients to the correct cancer type. in contrast the features based on passenger mutations did so at 92% accuracy with similar contribution from the rmd and the trinucleotide mutation spectra. the rmd and the spectra covered distinct sets of patients with predictions. in particular introducing the rmd features into a combined classification model increased the fraction of diagnosed patients by 50 percentage points at 20% fdr . furthermore rmd was able to discriminate molecular subtypes and/or anatomical site of six major cancers. the advantage of passenger mutations was upheld under high rates of false negative mutation calls and with exome sequencing even though overall accuracy decreased. we suggest whole genome sequencing is valuable for classifying tumors because it captures global patterns emanating from mutational processes which are informative of the underlying tumor biology.   \n",
       "123814                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               clinical data do not improve artificial neural network interpretation of myocardial perfusion scintigraphy. artificial neural networks interpretation of myocardial perfusion scintigraphy mps has so far been based on image data alone. physicians reporting mps often combine image and clinical data. the aim was to evaluate whether neural network interpretation would be improved by adding clinical data to image data. four hundred and eighteen patients were used for training and 532 patients for testing the neural networks. first the network was trained with image data alone and thereafter with image data in combination with clinical parameters age gender previous infarction percutaneous coronary intervention coronary artery bypass grafting typical chest pain present smoker hypertension hyperlipidaemia diabetes peripheral vascular disease and positive family history . expert interpretation was used as gold standard. receiver operating characteristic roc curves were calculated and the roc areas for the networks trained with and without clinical data were compared for the diagnosis of myocardial infarction and ischaemia. there was no statistically significant difference in roc area for the diagnosis of myocardial infarction between the neural network trained with the combination of clinical and image data 95.8% and with image data alone 95.2% . for the diagnosis of ischaemia there was no statistically significant difference in roc area between the neural network trained with the combination of clinical and image data 87.9% and with image data alone 88.0% . neural network interpretation of mps is not improved when clinical data are added to perfusion and functional data. one reason for this could be that experts base their interpretations of mps mainly on the images and to a lesser degree on clinical data.   \n",
       "61636                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    prediction of cancer using customised fuzzy rough machine learning approaches. this letter proposes a customised approach for attribute selection applied to the fuzzy rough quick reduct algorithm. the unbalanced data is balanced using synthetic minority oversampling technique. the huge dimensionality of the cancer data is reduced using a correlation-based filter. the dimensionality reduced balanced attribute gene subset is used to compute the final minimal reduct set using a customised fuzzy triangular norm operator on the fuzzy rough quick reduct algorithm. the customised fuzzy triangular norm operator is used with a lukasiewicz fuzzy implicator to compute the fuzzy approximation. the customised operator selects the least number of informative feature genes from the dimensionality reduced datasets. classification accuracy using leave-one-out cross validation of 94.85 76.54 98.11 and 99.13% is obtained using a customised function for lukasiewicz triangular norm operator on leukemia central nervous system lung and ovarian datasets respectively. performance analysis of the conventional fuzzy rough quick reduct and the proposed method are performed using parameters such as classification accuracy precision recall f-measure scatter plots receiver operating characteristic area mcnemar test chi-squared test matthew's correlation coefficient and false discovery rate that are used to prove that the proposed approach performs better than available methods in the literature.   \n",
       "29550                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        radiomics based on cect in differentiating kimura disease from lymph node metastases in head and neck: a non-invasive and reliable method. background: kimura disease may be easily misdiagnosed as malignant tumors such as lymph node metastases based on imaging and clinical symptoms. the aim of this article is to investigate whether the radiomic features and the model based on the features on venous-phase contrast-enhanced ct cect images can distinguish kimura disease from lymph node metastases in the head and neck. methods: a retrospective analysis of 14 patients of head and neck kimura disease a total of 38 enlarged lymph nodes and 39 patients with head and neck lymph node metastases a total of 39 enlarged lymph nodes confirmed by biopsy or surgery resection was conducted. all patients accepted cect within 10 days before biopsy or surgery resection. radiomic features based on venous-phase cect were generated automatically from artificial-intelligence kit ak software. all lymph nodes were randomly divided into the training set n = 54 and testing set n = 23 in a ratio of 7:3. anova mann-whitney spearman correlation least absolute shrinkage and selection operator and gradient descent were introduced for the reduction of the highly redundant features. binary logistic regression model was constructed based on the selected features. receiver operating characteristic was used to evaluate the diagnostic performance of the features and the model. finally a nomogram was established for model application. results: seven features were screened out at the end. significant difference was found between the two groups for all the features with area under the curves aucs ranging from 0.759 to 0.915. the auc of the model's identification performance was 0.970 in the training group and 0.977 in the testing group. the disease discrimination efficiency of the model was better than that of any single feature. conclusions: the radiomic features and the model based on these features on venous-phase cect images had very good performance for the discrimination between kimura disease and lymph node metastases in the head and neck.   \n",
       "25257                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     dyspnea effort and muscle pain during exercise in lung transplant recipients: an analysis of their association with cardiopulmonary function parameters using machine learning. despite improvement in lung function most lung transplant ltx recipients show an unexpectedly reduced exercise capacity that could be explained by persisting peripheral muscle dysfunction of multifactorial origin. we analyzed the course of symptoms including dyspnea muscle effort and muscle pain and its relation with cardiac and pulmonary function parameters during an incremental exercise testing.   \n",
       "56291                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  artificial intelligence estimates the importance of baseline factors in predicting response to anti-pd1 in metastatic melanoma. prognosis of patients with metastatic melanoma has dramatically improved over recent years because of the advent of antibodies targeting programmed cell death protein-1 pd1 . however the response rate is ~40% and baseline biomarkers for the outcome are yet to be identified. here we aimed to determine whether artificial intelligence might be useful in weighting the importance of baseline variables in predicting response to anti-pd1.   \n",
       "31541                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   a real-time depth of anesthesia monitoring system based on deep neural network with large edo tolerant eeg analog front-end. in this article we present a real-time electroencephalogram eeg based depth of anesthesia doa monitoring system in conjunction with a deep learning framework anesnet. an eeg analog front-end afe that can compensate ±380-mv electrode dc offset using a coarse digital dc servo loop is implemented in the proposed system. the eeg-based mac eegmac is introduced as a novel index to accurately predict the doa which is designed for applying to patients anesthetized by both volatile and intravenous agents. the proposed deep learning protocol consists of four layers of convolutional neural network and two dense layers. in addition we optimize the complexity of the deep neural network dnn to operate on a microcomputer such as the raspberry pi 3 realizing a cost-effective small-size doa monitoring system. fabricated in 110-nm cmos the prototype afe consumes 4.33 î¼w per channel and has the input-referred noise of 0.29 î¼vrms from 0.5 to 100 hz with the noise efficiency factor of 2.2. the proposed dnn was evaluated with pre-recorded eeg data from 374 subjects administrated by inhalational anesthetics under surgery achieving an average squared and absolute errors of 0.048 and 0.05 respectively. the eegmac with subjects anesthetized by an intravenous agent also showed a good agreement with the bispectral index value confirming the proposed doa index is applicable to both anesthetics. the implemented monitoring system with the raspberry pi 3 estimates the eegmac within 20 ms which is about thousand-fold faster than the bis estimation in literature.   \n",
       "81580                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             diagnosis of multiple sclerosis from eeg signals using nonlinear methods. eeg signals have essential and important information about the brain and neural diseases. the main purpose of this study is classifying two groups of healthy volunteers and multiple sclerosis ms patients using nonlinear features of eeg signals while performing cognitive tasks. eeg signals were recorded when users were doing two different attentional tasks. one of the tasks was based on detecting a desired change in color luminance and the other task was based on detecting a desired change in direction of motion. eeg signals were analyzed in two ways: eeg signals analysis without rhythms decomposition and eeg sub-bands analysis. after recording and preprocessing time delay embedding method was used for state space reconstruction; embedding parameters were determined for original signals and their sub-bands. afterwards nonlinear methods were used in feature extraction phase. to reduce the feature dimension scalar feature selections were done by using t-test and bhattacharyya criteria. then the data were classified using linear support vector machines svm and k-nearest neighbor knn method. the best combination of the criteria and classifiers was determined for each task by comparing performances. for both tasks the best results were achieved by using t-test criterion and svm classifier. for the direction-based and the color-luminance-based tasks maximum classification performances were 93.08 and 79.79% respectively which were reached by using optimal set of features. our results show that the nonlinear dynamic features of eeg signals seem to be useful and effective in ms diseases diagnosis.   \n",
       "94910                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          non-invasive quantification of brain [¹¸f]-fdg uptake by combining medical health records and dynamic pet imaging data. quantification of regional cerebral metabolic rate of glucose rcmrglu via positron emission tomography pet imaging requires measuring the arterial input function aif via invasive arterial blood sampling. in this study we describe a non-invasive approach the non-invasive simultaneous estimation nsime for the estimation of rcmrglu that considers a pharmacokinetic input function model and constraints derived from machine learning applied to a fusion of individual medical health records and dynamic [ 18 f]-fdg-pet brain images data. the results obtained with our data indicate potential for future clinical application of nsime with correlation measures of 0.87 for rcmrglu compared to quantification with full arterial blood sampling.    \n",
       "42824                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               adversarial representation learning for robust patient-independent epileptic seizure detection. epilepsy is a chronic neurological disorder characterized by the occurrence of spontaneous seizures which affects about one percent of the worlds population. most of the current seizure detection approaches strongly rely on patient history records and thus fail in the patient-independent situation of detecting the new patients. to overcome such limitation we propose a robust and explainable epileptic seizure detection model that effectively learns from seizure states while eliminates the inter-patient noises. a complex deep neural network model is proposed to learn the pure seizure-specific representation from the raw non-invasive electroencephalography eeg signals through adversarial training. furthermore to enhance the explainability we develop an attention mechanism to automatically learn the importance of each eeg channels in the seizure diagnosis procedure. the proposed approach is evaluated over the temple university hospital eeg tuh eeg database. the experimental results illustrate that our model outperforms the competitive state-of-the-art baselines with low latency. moreover the designed attention mechanism is demonstrated ables to provide fine-grained information for pathological analysis. we propose an effective and efficient patient-independent diagnosis approach of epileptic seizure based on raw eeg signals without manually feature engineering which is a step toward the development of large-scale deployment for real-life use.   \n",
       "143020                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [possibility to reveal signs of occupational respiratory diseases through acoustic spiroanalyzer and probabilistic neuronal networks]. the authors described acoustic spiroanalyzer with data processing through probabilistic neuronal networks. application of the spiroanalyzer for respiratory diseases diagnosis proved possibility of occupational diseases identification: classification reliability was 78% for diseased and 77% for healthy miners.   \n",
       "78636                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 deep learning based classification of fdg-pet data for alzheimers disease categories. fluorodeoxyglucose fdg positron emission tomography pet measures the decline in the regional cerebral metabolic rate for glucose offering a reliable metabolic biomarker even on presymptomatic alzheimer's disease ad patients. pet scans provide functional information that is unique and unavailable using other types of imaging. however the computational efficacy of fdg-pet data alone for the classification of various alzheimers diagnostic categories has not been well studied. this motivates us to correctly discriminate various ad diagnostic categories using fdg-pet data. deep learning has improved state-of-the-art classification accuracies in the areas of speech signal image video text mining and recognition. we propose novel methods that involve probabilistic principal component analysis on max-pooled data and mean-pooled data for dimensionality reduction and multilayer feed forward neural network which performs binary classification. our experimental dataset consists of baseline data of subjects including 186 cognitively unimpaired cu subects 336 mild cognitive impairment mci subjects with 158 late mci and 178 early mci and 146 ad patients from alzheimer's disease neuroimaging initiative adni dataset. we measured f1-measure precision recall negative and positive predictive values with a 10-fold cross validation scheme. our results indicate that our designed classifiers achieve competitive results while max pooling achieves better classification performance compared to mean-pooled features. our deep model based research may advance fdg-pet analysis by demonstrating their potential as an effective imaging biomarker of ad.   \n",
       "68375                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               deep neural network improves fracture detection by clinicians. suspected fractures are among the most common reasons for patients to visit emergency departments eds and x-ray imaging is the primary diagnostic tool used by clinicians to assess patients for fractures. missing a fracture in a radiograph often has severe consequences for patients resulting in delayed treatment and poor recovery of function. nevertheless radiographs in emergency settings are often read out of necessity by emergency medicine clinicians who lack subspecialized expertise in orthopedics and misdiagnosed fractures account for upward of four of every five reported diagnostic errors in certain eds. in this work we developed a deep neural network to detect and localize fractures in radiographs. we trained it to accurately emulate the expertise of 18 senior subspecialized orthopedic surgeons by having them annotate 135409 radiographs. we then ran a controlled experiment with emergency medicine clinicians to evaluate their ability to detect fractures in wrist radiographs with and without the assistance of the deep learning model. the average clinician's sensitivity was 80.8% 95% ci 76.7-84.1% unaided and 91.5% 95% ci 89.3-92.9% aided and specificity was 87.5% 95 ci 85.3-89.5% unaided and 93.9% 95% ci 92.9-94.9% aided. the average clinician experienced a relative reduction in misinterpretation rate of 47.0% 95% ci 37.4-53.9% . the significant improvements in diagnostic accuracy that we observed in this study show that deep learning methods are a mechanism by which senior medical specialists can deliver their expertise to generalists on the front lines of medicine thereby providing substantial improvements to patient care.   \n",
       "11991                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      cycle-consistent generative adversarial network: effect on radiation dose reduction and image quality improvement in ultralow-dose ct for evaluation of pulmonary tuberculosis. to investigate the image quality of ultralow-dose ct uldct of the chest reconstructed using a cycle-consistent generative adversarial network cyclegan -based deep learning method in the evaluation of pulmonary tuberculosis.   \n",
       "14404                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       hybrid ensemble model for differential diagnosis between covid-19 and common viral pneumonia by chest x-ray radiograph. chest x-ray radiography cxr has been widely considered as an accessible feasible and convenient method to evaluate suspected patients' lung involvement during the covid-19 pandemic. however with the escalating number of suspected cases traditional diagnosis via cxr fails to deliver results within a short period of time. therefore it is crucial to employ artificial intelligence ai to enhance cxrs for obtaining quick and accurate diagnoses. previous studies have reported the feasibility of utilizing deep learning methods to screen for covid-19 using cxr and ct results. however these models only use a single deep learning network for chest radiograph detection; the accuracy of this approach required further improvement.   \n",
       "54623                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 validation of a cyclic algorithm to proxy number of lines of systemic cancer therapy using administrative data. researchers are automating the process for identifying the number of lines of systemic cancer therapy received by patients. to date algorithm development has involved manual modifications to predefined classification rules. in this study we propose a supervised learning algorithm for determining the best-performing proxy for number of lines of therapy and validate this approach in four patient groups.   \n",
       "16619                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    clinical outcome prediction from analysis of microelectrode recordings using deep learning in subthalamic deep brain stimulation for parkinson`s disease. deep brain stimulation dbs of the subthalamic nucleus stn is an effective treatment for improving the motor symptoms of advanced parkinson's disease pd . accurate positioning of the stimulation electrodes is necessary for better clinical outcomes.   \n",
       "29905                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               the eeg signal analysis for spatial cognitive ability evaluation based on multivariate permutation conditional mutual information-multi-spectral image. this study aims to find an effective method to evaluate the efficacy of cognitive training of spatial memory under a virtual reality environment by classifying the eeg signals of subjects in the early and late stages of spatial cognitive training. this study proposes a new eeg signal analysis method based on multivariate permutation conditional mutual information-multi-spectral image mpcmimsi . this method mainly considers the relationship between the coupled features of eeg signals in different channel pairs and transforms the multivariate permutation conditional mutual information features into multi-spectral images. then a convolutional neural networks cnn model classifies the resultant image data into different stages of cognitive training to objectively assess the efficacy of the training. compared to the multi-spectral image transformation method based on granger causality analysis gca and permutation conditional mutual information pcmi the mpcmimsi led to better classification performance which can be as high as 95% accuracy. more specifically the theta-beta2-gamma-band combination has the best accuracy. the proposed mpcmimsi method outperforms the multi-spectral image transformation methods based on gca and pcmi in terms of classification performance. the mpcmimsi feature in the theta-beta2-gamma band is an effective biomarker for assessing the efficacy of spatial memory training. the proposed eeg feature-extraction method based on mpcmimsi offers a new window to characterize spatial information of the noninvasive eeg recordings and might apply to assessing other brain functions.   \n",
       "44932                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         eyelid movement command classification using machine learning. the eyelid drive system eds is an assistive technology device intended to allow users to wirelessly control other devices such as power wheelchairs and personal computers using commands consisting only of blinking and winking. in this paper four machine learning classifiers are trained on data taken from one subject and validated offline on the training subject plus two additional subjects. the classifiers are assessed for accuracy computational and memory requirements and transferability from the \"training\" subject to the other two subjects. a support vector machine svm achieved the highest level of accuracy 97.5% while using a potentially prohibitive level of computational and memory resources. a logistic regression classifier also achieved excellent accuracy 96.5% while using two to three orders of magnitude fewer computational and memory resources than the svm.   \n",
       "37654                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         real-time quality assessment of pediatric mri via semi-supervised deep nonlocal residual neural networks. in this paper we introduce an image quality assessment iqa method for pediatric t1- and t2-weighted mr images. iqa is first performed slice-wise using a nonlocal residual neural network nr-net and then volume-wise by agglomerating the slice qa results using random forest. our method requires only a small amount of quality-annotated images for training and is designed to be robust to annotation noise that might occur due to rater errors and the inevitable mix of good and bad slices in an image volume. using a small set of quality-assessed images we pre-train nr-net to annotate each image slice with an initial quality rating i.e. pass questionable fail which we then refine by semi-supervised learning and iterative self-training. experimental results demonstrate that our method trained using only samples of modest size exhibit great generalizability capable of real-time milliseconds per volume large-scale iqa with nearperfect accuracy.   \n",
       "143179  development of a computer-aided diagnostic scheme for detection of interval changes in successive whole-body bone scans. bone scintigraphy is the most frequent examination among various diagnostic nuclear medicine procedures. it is a well-established imaging modality for the diagnosis of osseous metastasis and for monitoring osseous tumor response to chemotherapy and radiation therapy. although the sensitivity of bone scan examinations for detection of bone abnormalities has been considered to be relatively high it is time consuming to identify multiple lesions such as bone metastases of prostate and breast cancers. in addition it is very difficult to detect subtle interval changes between two successive abnormal bone scans because of variations in patient conditions the accumulation of radioisotopes during each examination and the image quality of gamma cameras. therefore we developed a new computer-aided diagnostic cad scheme for the detection of interval changes in successive whole-body bone scans by use of a temporal subtraction image which was obtained with a nonlinear image-warping technique. we carried out 58 pairs of successive bone scans in which each scan included both posterior and anterior views. we determined 107 \"gold-standard\" interval changes among the 58 pairs based on the consensus of three radiologists. our computerized scheme consisted of seven steps i.e. initial image density normalization on each image image matching for the paired images temporal subtraction by use of the nonlinear image-warping technique initial detection of interval changes by use of temporal-subtraction images image feature extraction of candidates of interval changes rule-based tests by use of 16 image features for removing some false positives and display of the computer output for identified interval changes. one hundred seven gold standard interval changes included 71 hot lesions uptake was increased compared with the previous scan or there was new uptake in the current scan and 36 cold lesions uptake was decreased or disappeared for anterior and posterior views. the overall sensitivity in the detection of interval changes including both hot and cold lesions evaluated by use of the resubstitution and the leave-one-case-out methods were 95.3% with 5.97 false positives per view and 83.2% with 6.02 respectively. the temporal subtraction image for successive whole-body bone scans has the potential to enhance the interval changes between two images which also can be quantified. furthermore the cad scheme for the detection of interval changes by use of temporal subtraction images would be useful in assisting radiologists' interpretation on successive bone scan images.   \n",
       "56109                                                                                                                                                                                                                             introducing machine learning to detect personality faking-good in a male sample: a new model based on minnesota multiphasic personality inventory-2 restructured form scales and reaction times. background and purpose. the use of machine learning ml models in the detection of malingering has yielded encouraging results showing promising accuracy levels. we investigated the possible application of this methodology when trained on behavioral features such as response time rt and time pressure to identify faking behavior in self-report personality questionnaires. to do so we reintroduced the article of roma et al. 2018 which highlighted that rts and time pressure are useful variables in the detection of faking; we then extended the number of participants and applied an ml analysis. materials and methods. the sample was composed of 175 subjects of whom all were graduates having completed at least 17 years of instruction male and caucasian. subjects were randomly assigned to four groups: honest speeded faking-good speeded honest unspeeded and faking-good unspeeded. a software version of the minnesota multiphasic personality inventory-2 restructured form mmpi-2-rf was administered. results. results indicated that ml algorithms reached very high accuracies around 95% in detecting malingerers when subjects are instructed to respond under time pressure. the classifiers' performance was lower when the subjects responded with no time restriction to the mmpi-2-rf items with accuracies ranging from 75% to 85%. further analysis demonstrated that t-scores of validity scales are ineffective to detect fakers when participants were not under temporal pressure accuracies 55-65% whereas temporal features resulted to be more useful accuracies 70-75% . by contrast temporal features and t-scores of validity scales are equally effective in detecting fakers when subjects are under time pressure accuracies higher than 90% . discussion. to conclude results demonstrated that ml techniques are extremely valuable and reach high performance in detecting fakers in self-report personality questionnaires over more the traditional psychometric techniques. validity scales mmpi-2-rf manual criteria are very poor in identifying under-reported profiles. moreover temporal measures are useful tools in distinguishing honest from dishonest responders especially in a no time pressure condition. indeed time pressure brings out malingerers in clearer way than does no time pressure condition.   \n",
       "35773                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               diagnosis of asthma based on routine blood biomarkers using machine learning. intelligent medical diagnosis has become common in the era of big data although this technique has been applied to asthma only in limited contexts. using routine blood biomarkers to identify asthma patients would make clinical diagnosis easier to implement and would enhance research of key asthma variables through data mining techniques. we used routine blood data from healthy individuals to construct a mahalanobis space ms . then we calculated mahalanobis distances of the training routine blood data from 355 asthma patients and 1480 healthy individuals to ensure the efficiency of ms. orthogonal arrays and signal-to-noise ratios were used to optimize blood biomarker variables. receiver operating characteristic roc curve was used to determine the threshold value. ultimately we validated the system on 182 individuals based on the threshold value. out of 35 patients with asthma mts correctly classified 94.15% of patients. in addition 97.20% of 147 healthy individuals were correctly classified. the system isolated 7 routine blood biomarkers. among these biomarkers platelet distribution width mean platelet volume white blood cell count eosinophil count and lymphocyte ratio performed well in asthma diagnosis. in brief mts shows promise as an accurate method to identify asthma patients based on 7 vital blood biomarker variables and threshold determined by the roc curve thus offering the potential to simplify diagnostic complexity and optimize clinical efficiency.   \n",
       "117887                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     artificial neural networks based early clinical prediction of mortality after spontaneous intracerebral hemorrhage. numerous outcome prediction models have been developed for mortality and functional outcome after spontaneous intracerebral haemorrhage ich . however no outcome prediction model for ich has considered the impact of care restriction. to develop and compare results of the artificial neural networks ann and logistic regression lr models based on initial clinical parameters for prediction of mortality after spontaneous ich. analysis has been conducted on consecutive dataset of patients with spontaneous ich over 5-year period in tertiary care academic hospital. patients older than 18 years were eligible for inclusion if they had been presented within 6 h from the start of symptoms and had evidence of spontaneous supratentorial ich on initial brain computed tomography within 24 h. initial clinical parameters have been used to develop lr and ann prediction models for hospital mortality as outcome measure. models have been accessed for discrimination and calibration abilities. we have analyzed 411 patients 199 males and 212 females with spontaneous ich medically treated and not withdrawn from therapy with average age of 67.35 years. from them 256 62.29% patients died during hospital treatment and 155 37.71% patients survived. in the observed dataset ann model overall correctly classified outcome in 93.55% of patients compared with 79.32% of correct classification for the lr model. discrimination and calibration parameters indicate that both models show an adequate fit of expected and observed values with superiority of ann model. our results favour the ann model for prediction of mortality after spontaneous ich. further studies of the strengths and limitations of this method are needed with larger prospective samples.   \n",
       "15168                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               low-dose ct urography using deep learning image reconstruction: a prospective study for comparison with conventional ct urography. to compare the image quality of low-dose ct urography ld-ctu using deep learning image reconstruction dlir with conventional ctu c-ctu using adaptive statistical iterative reconstruction asir-v .   \n",
       "48648                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                a hybrid model for eeg-based gender recognition. the gender recognition is an important research field to study evidence regarding some personal characteristics in the information and data society. however some current traditional methods such as vision and sound have been exposed their own security weaknesses. recently biometric gender recognition based on electroencephalography eeg signals has been widely used in information safety and medical fields. it is necessary to explore potential of using eeg to present a more robust and accurate result with larger training data based on sophisticated machine learning approaches. in this contribution we present an automated gender recognition system by a hybrid model based on eeg data of resting state from twenty-eight subjects. these data are useful and handy to get insights into assessing the differences in personal gender. for achieving a good performance and a strong robustness the system develops a hybrid model of combining random forest and logistic regression and employs four common entropy measures to analyze the non-stationary eeg signals. result also suggests that the recognition performance achieve an improved progress with an accuracy of 0.9982 and auc of 0.9926 based on a nested tenfold cross-validation loop implying that show a significant potential applicability of the proposed approach and is capable of recognizing personal gender.   \n",
       "37039                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        a cnn-lstm neural network for recognition of puffing in smoking episodes using wearable sensors. a detailed assessment of smoking behavior under free-living conditions is a key challenge for health behavior research. a number of methods using wearable sensors and puff topography devices have been developed for smoking and individual puff detection. in this paper we propose a novel algorithm for automatic detection of puffs in smoking episodes by using a combination of respiratory inductance plethysmography and inertial measurement unit sensors. the detection of puffs was performed by using a deep network containing convolutional and recurrent neural networks. convolutional neural networks cnn were utilized to automate feature learning from raw sensor streams. long short term memory lstm network layers were utilized to obtain the temporal dynamics of sensor signals and classify sequence of time segmented sensor streams. an evaluation was performed by using a large challenging dataset containing 467 smoking events from 40 participants under free-living conditions. the proposed approach achieved an f1-score of 78% in leave-one-subject-out cross-validation. the results suggest that cnn-lstm based neural network architecture sufficiently detect puffing episodes in free-living condition. the proposed model be used as a detection tool for smoking cessation programs and scientific research.   \n",
       "104650                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        brain state differentiation and behavioral inflexibility in autism. autism spectrum disorders asds are characterized by social impairments alongside cognitive and behavioral inflexibility. while social deficits in asds have extensively been characterized the neurobiological basis of inflexibility and its relation to core clinical symptoms of the disorder are unknown. we acquired functional neuroimaging data from 2 cohorts each consisting of 17 children with asds and 17 age- and iq-matched typically developing td children during stimulus-evoked brain states involving performance of social attention and numerical problem solving tasks as well as during intrinsic resting brain states. effective connectivity between key nodes of the salience network default mode network and central executive network was used to obtain indices of functional organization across evoked and intrinsic brain states. in both cohorts examined a machine learning algorithm was able to discriminate intrinsic resting and evoked task functional brain network configurations more accurately in td children than in children with asd. brain state discriminability was related to severity of restricted and repetitive behaviors indicating that weak modulation of brain states may contribute to behavioral inflexibility in asd. these findings provide novel evidence for a potential link between neurophysiological inflexibility and core symptoms of this complex neurodevelopmental disorder.    \n",
       "56998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       identification of 17 mrnas and a mirna as an integrated prognostic signature for lung squamous cell carcinoma. gene signatures for predicting the outcome of lung squamous cell carcinoma lusc have been employed for many years. however various signatures have been applied in clinical practice. therefore in the present study we aimed to filter out an effective lusc prognostic gene signature by simultaneously integrating mrna and microrna mirna .   \n",
       "7057                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  texture analysis of muscle mri: machine learning-based classifications in idiopathic inflammatory myopathies. to develop a machine learning ml model that predicts disease groups or autoantibodies in patients with idiopathic inflammatory myopathies iims using muscle mri radiomics features. twenty-two patients with dermatomyositis dm 14 with amyopathic dermatomyositis adm 19 with polymyositis pm and 19 with non-iim were enrolled. using 2d manual segmentation 93 original features as well as 93 local binary pattern lbp features were extracted from mri short-tau inversion recovery [stir] imaging of proximal limb muscles. to construct and compare ml models that predict disease groups using each set of features dimensional reductions were performed using a reproducibility analysis by inter-reader and intra-reader correlation coefficients collinearity analysis and the sequential feature selection sfs algorithm. models were created using the linear discriminant analysis lda quadratic discriminant analysis qda support vector machine svm k-nearest neighbors k-nn random forest rf and multi-layer perceptron mlp classifiers and validated using tenfold cross-validation repeated 100 times. we also investigated whether it was possible to construct models predicting autoantibody status. our ml-based mri radiomics models showed the potential to distinguish between pm dm and adm. models using lbp features provided better results with macro-average auc values of 0.767 and 0.714 accuracy of 61.2 and 61.4% and macro-average recall of 61.9 and 59.8% in the lda and k-nn classifiers respectively. in contrast the accuracies of radiomics models distinguishing between non-iim and iim disease groups were low. a subgroup analysis showed that classification models for anti-jo-1 and anti-ars antibodies provided auc values of 0.646-0.853 and 0.692-0.792 with accuracy of 71.5-81.0 and 65.8-78.3% respectively. ml-based ta of muscle mri may be used to predict disease groups or the autoantibody status in patients with iim and is useful in non-invasive assessments of disease mechanisms.   \n",
       "67625                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    predicting drug-resistant epilepsy - a machine learning approach based on administrative claims data. patients with drug-resistant epilepsy dre are at high risk of morbidity and mortality yet their referral to specialist care is frequently delayed. the ability to identify patients at high risk of dre at the time of treatment initiation and to subsequently steer their treatment pathway toward more personalized interventions has high clinical utility. here we aim to demonstrate the feasibility of developing algorithms for predicting dre using machine learning methods. longitudinal intersected data sourced from us pharmacy medical and adjudicated hospital claims from 1376756 patients from 2006 to 2015 were analyzed; 292892 met inclusion criteria for epilepsy and 38382 were classified as having dre using a proxy measure for drug resistance. patients were characterized using 1270 features reflecting demographics comorbidities medications procedures epilepsy status and payer status. data from 175735 randomly selected patients were used to train three algorithms and from the remainder to assess the trained models' predictive power. a model with only age and sex was used as a benchmark. the best model random forest achieved an area under the receiver operating characteristic curve 95% confidence interval [ci] of 0.764 0.759 0.770 compared with 0.657 0.651 0.663 for the benchmark model. moreover predicted probabilities for dre were well-calibrated with the observed frequencies in the data. the model predicted drug resistance approximately 2¯years before patients in the test dataset had failed two antiepileptic drugs aeds . machine learning models constructed using claims data predicted which patients are likely to fail ¥3 aeds and are at risk of developing dre at the time of the first aed prescription. the use of such models can ensure that patients with predicted dre receive specialist care with potentially more aggressive therapeutic interventions from diagnosis to help reduce the serious sequelae of dre.   \n",
       "47003                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            utilizing machine learning for image quality assessment for reflectance confocal microscopy. in vivo reflectance confocal microscopy rcm enables clinicians to examine lesions' morphological and cytological information in epidermal and dermal layers while reducing the need for biopsies. as rcm is being adopted more widely the workflow is expanding from real-time diagnosis at the bedside to include a capture store and forward model with image interpretation and diagnosis occurring offsite similar to radiology. as the patient may no longer be present at the time of image interpretation quality assurance is key during image acquisition. herein we introduce a quality assurance process by means of automatically quantifying diagnostically uninformative areas within the lesional area by using rcm and coregistered dermoscopy images together. we trained and validated a pixel-level segmentation model on 117 rcm mosaics collected by international collaborators. the model delineates diagnostically uninformative areas with 82% sensitivity and 93% specificity. we further tested the model on a separate set of 372 coregistered rcm-dermoscopic image pairs and illustrate how the results of the rcm-only model can be improved via a multimodal rcm  dermoscopy approach which can help quantify the uninformative regions within the lesional area. our data suggest that machine learning-based automatic quantification offers a feasible objective quality control measure for rcm imaging.   \n",
       "71310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       tumor identification in colorectal histology images using a convolutional neural network. colorectal cancer crc is a major global health concern. its early diagnosis is extremely important as it determines treatment options and strongly influences the length of survival. histologic diagnosis can be made by pathologists based on images of tissues obtained from a colonoscopic biopsy. convolutional neural networks cnns -i.e. deep neural networks dnns specifically adapted to image data-have been employed to effectively classify or locate tumors in many types of cancer. colorectal histology images of 28 normal and 29 tumor samples were obtained from the national cancer center south korea and cropped into 6806 normal and 3474 tumor images. we developed five modifications of the system from the visual geometry group vgg the winning entry in the classification task in the 2014 imagenet large scale visual recognition competition ilsvrc and examined them in two experiments. in the first experiment we determined the best modified vgg configuration for our partial dataset resulting in accuracies of 82.50% 87.50% 87.50% 91.40% and 94.30% respectively. in the second experiment the best modified vgg configuration was applied to evaluate the performance of the cnn model. subsequently using the entire dataset on the modified vgg-e configuration the highest results for accuracy loss sensitivity and specificity respectively were 93.48% 0.4385 95.10% and 92.76% which equates to correctly classifying 294 normal images out of 309 and 667 tumor images out of 719.   \n",
       "114768                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       automated detection of instantaneous gait events using time frequency analysis and manifold embedding. accelerometry is a widely used sensing modality in human biomechanics due to its portability non-invasiveness and accuracy. however difficulties lie in signal variability and interpretation in relation to biomechanical events. in walking heel strike and toe off are primary gait events where robust and accurate detection is essential for gait-related applications. this paper describes a novel and generic event detection algorithm applicable to signals from tri-axial accelerometers placed on the foot ankle shank or waist. data from healthy subjects undergoing multiple walking trials on flat and inclined as well as smooth and tactile paving surfaces is acquired for experimentation. the benchmark timings at which heel strike and toe off occur are determined using kinematic data recorded from a motion capture system. the algorithm extracts features from each of the acceleration signals using a continuous wavelet transform over a wide range of scales. a locality preserving embedding method is then applied to reduce the high dimensionality caused by the multiple scales while preserving salient features for classification. a simple gaussian mixture model is then trained to classify each of the time samples into heel strike toe off or no event categories. results show good detection and temporal accuracies for different sensor locations and different walking terrains.    \n",
       "37681                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                augmented deep learning model for improved quantitative accuracy of mr-based pet attenuation correction in psma pet-mri prostate imaging. estimation of accurate attenuation maps for whole-body positron emission tomography pet imaging in simultaneous pet-mri systems is a challenging problem as it affects the quantitative nature of the modality. in this study we aimed to improve the accuracy of estimated attenuation maps from mri dixon contrast images by training an augmented generative adversarial network gans in a supervised manner. we augmented the gans by perturbing the non-linear deformation field during image registration between mri and the ground truth ct images.   \n",
       "68343                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       optimizing immune cell therapies with artificial intelligence. we determine an optimal injection pattern for anti-vascular endothelial growth factor vegf and for the combination of anti-vegf and unlicensed dendritic cells.   \n",
       "47109                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    usefulness of regional right ventricular and right atrial strain for prediction of early and late right ventricular failure following a left ventricular assist device implant: a machine learning approach. identifying candidates for left ventricular assist device surgery at risk of right ventricular failure remains difficult. the aim was to identify the most accurate predictors of right ventricular failure among clinical biological and imaging markers assessed by agreement of different supervised machine learning algorithms.   \n",
       "138233                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ischemia detection with a self-organizing map supplemented by supervised learning. the problem of maximizing the performance of the detection of ischemia episodes is a difficult pattern classification problem. the motivation for developing the supervising network self-organizing map snet-som model is to exploit this fact for designing computationally effective solutions both for the particular ischemic detection problem and for other applications that share similar characteristics. specifically the snet-som utilizes unsupervised learning for the \"simple\" regions and supervised for the \"difficult\" ones in a two stage learning process. the unsupervised learning approach extends and adapts the self-organizing map som algorithm of kohonen. the basic som is modified with a dynamic expansion process controlled with an entropy based criterion that allows the adaptive formation of the proper som structure. this extension proceeds until the total number of training patterns that are mapped to neurons with high entropy reduces to a size manageable numerically with a capable supervised model. the second learning phase has the objective of constructing better decision boundaries at the ambiguous regions. at this phase a special supervised network is trained for the computationally reduced task of performing the classification at the ambiguous regions only. the utilization of snet-som with supervised learning based on the radial basis functions and support vector machines has resulted in an improved accuracy of ischemia detection especially in the last case. the highly disciplined design of the generalization performance of the support vector machine allows designing the proper model for the number of patterns transferred to the supervised expert.   \n",
       "48230                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             machine learning techniques applied to dose prediction in computed tomography tests. increasingly more patients exposed to radiation from computed axial tomography ct will have a greater risk of developing tumors or cancer that are caused by cell mutation in the future. a minor dose level would decrease the number of these possible cases. however this framework can result in medical specialists radiologists not being able to detect anomalies or lesions. this work explores a way of addressing these concerns achieving the reduction of unnecessary radiation without compromising the diagnosis. we contribute with a novel methodology in the ct area to predict the precise radiation that a patient should be given to accomplish this goal. specifically from a real dataset composed of the dose data of over fifty thousand patients that have been classified into standardized protocols skull abdomen thorax pelvis etc. we eliminate atypical information outliers to later generate regression curves employing diverse well-known machine learning techniques. as a result we have chosen the best analytical technique per protocol; a selection that was thoroughly carried out according to traditional dosimetry parameters to accurately quantify the dose level that the radiologist should apply in each ct test.   \n",
       "19333                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         a deep learning system for synthetic knee magnetic resonance imaging: is artificial intelligence-based fat-suppressed imaging feasible? this single-center study was approved by the institutional review board. artificial intelligence-based fs mri scans were created from non-fs images using a deep learning system with a modified convolutional neural network-based u-net that used a training set of 25920 images and validation set of 16416 images. three musculoskeletal radiologists reviewed 88 knee mr studies in 2 sessions the original proton density [pd] fspd and the synthetic pd afsmri . readers recorded afsmri quality diagnostic/nondiagnostic and the presence or absence of meniscal ligament and tendon tears; cartilage defects; and bone marrow abnormalities. contrast-to-noise rate measurements were made among subcutaneous fat fluid bone marrow cartilage and muscle. the original mri sequences were used as the reference standard to determine the diagnostic performance of afsmri combined with the original pd sequence . this is a fully balanced study design where all readers read all images the same number of times which allowed the determination of the interchangeability of the original and synthetic protocols. descriptive statistics intermethod agreement interobserver concordance and interchangeability tests were applied. a p value less than 0.01 was considered statistically significant for the likelihood ratio testing and p value less than 0.05 for all other statistical analyses.   \n",
       "91122                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   automated classification of epiphyses in the distal radius and ulna using a support vector machine. the aim of this study was to automatically classify epiphyses in the distal radius and ulna using a support vector machine svm and to examine the accuracy of the epiphyseal growth grades generated by the support vector machine. x-ray images of distal radii and ulnae were collected from 140 chinese teenagers aged between 11.0 and 19.0 years. epiphyseal growth of the two elements was classified into five grades. features of each element were extracted using a histogram of oriented gradient hog and models were established using support vector classification svc . the prediction results and the validity of the models were evaluated with a cross-validation test and independent test for accuracy pa . our findings suggest that this new technique for epiphyseal classification was successful and that an automated technique using an svm is reliable and feasible with a relative high accuracy for the models.    \n",
       "50196                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [heartbeat-based end-to-end classification of arrhythmias]. we propose a heartbeat-based end-to-end classification of arrhythmias to improve the classification performance for supraventricular ectopic beat sveb and ventricular ectopic beat veb .   \n",
       "26004                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    antibiotic treatment response in chronic lyme disease: why do some patients improve while others do not? there is considerable uncertainty regarding treatment of lyme disease patients who do not respond fully to initial short-term antibiotic therapy. choosing the best treatment approach and duration remains challenging because treatment response among these patients varies: some patients improve with treatment while others do not. a previous study examined treatment response variation in a sample of over 3500 patients enrolled in the mylymedata patient registry developed by lymedisease.org san ramon ca usa . that study used a validated global rating of change groc scale to identify three treatment response subgroups among lyme disease patients who remained ill: nonresponders low responders and high responders. the present study first characterizes the health status symptom severity and percentage of treatment response across these three patient subgroups together with a fourth subgroup patients who identify as well. we then employed machine learning techniques across these subgroups to determine features most closely associated with improved patient outcomes and we used traditional statistical techniques to examine how these features relate to treatment response of the four groups. high treatment response was most closely associated with 1 the use of antibiotics or a combination of antibiotics and alternative treatments 2 longer duration of treatment and 3 oversight by a clinician whose practice focused on the treatment of tick-borne diseases.   \n",
       "1244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   deephbv: a deep learning model to predict hepatitis b virus hbv integration sites. the hepatitis b virus hbv is one of the main causes of viral hepatitis and liver cancer. hbv integration is one of the key steps in the virus-promoted malignant transformation.   \n",
       "61442                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      risk stratification for short-term mortality at hospital admission for acute exacerbations of copd. exacerbations of chronic obstructive pulmonary disease ecopd are associated with increased in-hospital and short-term mortality. developing an easy-to-use model to predict adverse outcomes will be useful in daily clinical practice and will facilitate management decisions. we aimed to assess mortality rates and potential predictors for short-term mortality after severe ecopd. classification and regression tree cart model was used to identify predictors of adverse outcome.   \n",
       "139902                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  electrooculogram based system for computer control using a multiple feature classification model. this paper discusses the creation of a system for computer-aided communication through automated analysis and processing of electrooculogram signals. in situations of disease or trauma there may be an inability to communicate with others through standard means such as speech or typing. eye movement tends to be one of the last remaining active muscle capabilities for people with neurodegenerative disorders such as amyotrophic lateral sclerosis als also known as lou gehrig's disease. thus there is a need for eye movement based systems to enable communication. to meet this need the telepathix system was designed to accept eye movement commands denoted by looking to the left looking to the right and looking straight ahead to navigate a virtual keyboard. using a ternary virtual keyboard layout and a multiple feature classification model a typing speed of 6 letters per minute was achieved.   \n",
       "29323                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              predicting covid-19 pneumonia severity on chest x-ray with deep learning. introduction the need to streamline patient management for coronavirus disease-19 covid-19 has become more pressing than ever. chest x-rays cxrs provide a non-invasive potentially bedside tool to monitor the progression of the disease. in this study we present a severity score prediction model for covid-19 pneumonia for frontal chest x-ray images. such a tool can gauge the severity of covid-19 lung infections and pneumonia in general that can be used for escalation or de-escalation of care as well as monitoring treatment efficacy especially in the icu. methods images from a public covid-19 database were scored retrospectively by three blinded experts in terms of the extent of lung involvement as well as the degree of opacity. a neural network model that was pre-trained on large non-covid-19 chest x-ray datasets is used to construct features for covid-19 images which are predictive for our task. results this study finds that training a regression model on a subset of the outputs from this pre-trained chest x-ray model predicts our geographic extent score range 0-8 with 1.14 mean absolute error mae and our lung opacity score range 0-6 with 0.78 mae. conclusions these results indicate that our model's ability to gauge the severity of covid-19 lung infections could be used for escalation or de-escalation of care as well as monitoring treatment efficacy especially in the icu. to enable follow up work we make our code labels and data available online.   \n",
       "13910                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   evaluating performance of eeg data-driven machine learning for traumatic brain injury classification. big data analytics can potentially benefit the assessment and management of complex neurological conditions by extracting information that is difficult to identify manually. in this study we evaluated the performance of commonly used supervised machine learning algorithms in the classification of patients with traumatic brain injury tbi history from those with stroke history and/or normal eeg.   \n",
       "13923                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            deep learning whole-gland and zonal prostate segmentation on a public mri dataset. prostate volume as determined by magnetic resonance imaging mri is a useful biomarker both for distinguishing between benign and malignant pathology and can be used either alone or combined with other parameters such as prostate-specific antigen.   \n",
       "4321                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         serum raman spectroscopy combined with deep neural network for analysis and rapid screening of hyperthyroidism and hypothyroidism. hyperthyroidism and hypothyroidism may cause a series of clinical complications have a high incidence and early diagnosis is beneficial to treatment. based on raman spectroscopy and deep learning algorithms we propose a rapid screening method to distinguish serum samples of hyperthyroidism patients hypothyroidism patients and control subjects. we collected 99 serum samples including 38 cases from hyperthyroidism patients 32 cases from hypothyroidism patients and 29 cases from control subjects. by comparing and analyzing the raman spectra of the three we found differences in the peak intensity of the spectra indicating that raman spectra can be used for the subsequent identification of diseases. after collecting the spectral data vancouver raman algorithm vra was used to remove the fluorescence background of the data and kernel principal component analysis kpca was used to extract the spectral data features with a cumulative explained variance ratio of 0.9999. then five neural network models the adjusted alexnet lstm-cnn indrnncnn the adjusted googlenet and the adjusted resnet were constructed for classifications. the total accuracy was 91% 84% 82% 75% and 71% respectively. the results of our study show that it is feasible to use raman spectroscopy combined with deep learning to distinguish hyperthyroidism hypothyroidism and control subjects. after comparing the models we found that as the neural network deepens and the complexity of the model increases the classification effect of raman spectroscopy gradually deteriorates and we put forward three conjectures for this.   \n",
       "47901                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      prospective prediction of suicide attempts in community adolescents and young adults using regression methods and machine learning. the use of machine learning ml algorithms to study suicidality has recently been recommended. our aim was to explore whether ml approaches have the potential to improve the prediction of suicide attempt sa risk. using the epidemiological multiwave prospective-longitudinal early developmental stages of psychopathology edsp data set we compared four algorithms-logistic regression lasso ridge and random forest-in predicting a future sa in a community sample of adolescents and young adults.   \n",
       "18809                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 transfer learning for clinical sleep pose detection using a single 2d ir camera. sleep quality is an important determinant of human health and wellbeing. novel technologies that can quantify sleep quality at scale are required to enable the diagnosis and epidemiology of poor sleep. one important indicator of sleep quality is body posture. in this paper we present the design and implementation of a non-contact sleep monitoring system that analyses body posture and movement. supervised machine learning strategies applied to noncontact vision-based infrared camera data using a transfer learning approach successfully quantified sleep poses of participants covered by a blanket. this represents the first occasion that such a machine learning approach has been used to successfully detect four predefined poses and the empty bed state during 8-10 hour overnight sleep episodes representing a realistic domestic sleep situation. the methodology was evaluated against manually scored sleep poses and poses estimated using clinical polysomnography measurement technology. in a cohort of 12 healthy participants we find that a resnet-152 pre-trained network achieved the best performance compared with the standard de novo cnn network and other pre-trained networks. the performance of our approach was better than other video-based methods for sleep pose estimation and produced higher performance compared to the clinical standard for pose estimation using a polysomnography position sensor. it can be concluded that infrared video capture coupled with deep learning ai can be successfully used to quantify sleep poses as well as the transitions between poses in realistic nocturnal conditions and that this non-contact approach provides superior pose estimation compared to currently accepted clinical methods.   \n",
       "3483                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         realistic high-resolution lateral cephalometric radiography generated by progressive growing generative adversarial network and quality evaluations. realistic image generation is valuable in dental medicine but still challenging for generative adversarial networks gans which require large amounts of data to overcome the training instability. thus we generated lateral cephalogram x-ray images using a deep-learning-based progressive growing gan pggan . the quality of generated images was evaluated by three methods. first signal-to-noise ratios of real/synthesized images evaluated at the posterior arch region of the first cervical vertebra showed no statistically significant difference t-test p=0.211 . second the results of an image turing test conducted by non-orthodontists and orthodontists for 100 randomly chosen images indicated that they had difficulty in distinguishing whether the image was real or synthesized. third cephalometric tracing with 42 landmark points detection performed on real and synthesized images by two expert orthodontists showed consistency with mean difference of 2.08±1.02 mm. furthermore convolutional neural network-based classification tasks were used to classify skeletal patterns using a real dataset with class imbalance and a dataset balanced with synthesized images. the classification accuracy for the latter case was increased by 1.5%/3.3% at internal/external test sets respectively. thus the cephalometric images generated by pggan are sufficiently realistic and have potential to application in various fields of dental medicine.   \n",
       "73716                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     predicting depression among community residing older adults: a use of machine learning approch. the study demonstrated an application of machine learning techniques in building a depression prediction model. we used the nshap ii data 3377 subjects and 261 variables and built the models using a logistic regression with and without l1 regularization. depression prediction rates ranged 58.33% to 90.48% and 83.33% to 90.44% in the model with and without l1 regularization respectively. the moderate to high prediction rates imply that the machine learning algorithms built the prediction models successfully.   \n",
       "84733                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 personalized risk scoring for critical care prognosis using mixtures of gaussian processes. in this paper we develop a personalized real-time risk scoring algorithm that provides timely and granular assessments for the clinical acuity of ward patients based on their temporal lab tests and vital signs; the proposed risk scoring system ensures timely intensive care unit admissions for clinically deteriorating patients.   \n",
       "152438                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        sample classification from protein mass spectrometry by 'peak probability contrasts'. early cancer detection has always been a major research focus in solid tumor oncology. early tumor detection can theoretically result in lower stage tumors more treatable diseases and ultimately higher cure rates with less treatment-related morbidities. protein mass spectrometry is a potentially powerful tool for early cancer detection. we propose a novel method for sample classification from protein mass spectrometry data. when applied to spectra from both diseased and healthy patients the 'peak probability contrast' technique provides a list of all common peaks among the spectra their statistical significance and their relative importance in discriminating between the two groups. we illustrate the method on matrix-assisted laser desorption and ionization mass spectrometry data from a study of ovarian cancers.   \n",
       "44877                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       convolutional neural network based detection of atrial fibrillation combing r-r intervals and f-wave frequency spectrum. atrial fibrillation af is one of the arrhythmias that is common and serious in clinic. in this study a novel method of af classification with a convolutional neural network cnn was proposed and particularly two cardiac rhythm features of r-r intervals and f-wave frequency spectrum were combined into the cnn for a good applicability of mobile application. over 23 patients' ten-hours of electrocardiogram ecg records were collected from the mit-bih database and each of which was segmented into 10s-data fragments to train the designed cnn and evaluate the performance of the proposed method. specifically a total of 83461 fragments were collected 49952 fragments of which are the normal fragments type-n and the others are the af fragments. as results the obtained average accuracy of the proposed method combining the two proposed features is 97.3% which is shown a relative higher accuracy comparing with either that of the detection with the feature of r-r intervals 95.7% or that with the feature of f-wave frequency spectrum 93.9% . additionally the sensitivity and the specificity of the present method are both of a high level of 97.4% and 97.2% respectively. in conclusion the cnn based approach by combining the r-r interval series and the f-wave frequency spectrum would be effectively to improve the performance of af detection. moreover the proposed classification of af with 10s-data fragments also could be potentially useful for a wearable real-time monitoring application for a pre-hospital screening of af.   \n",
       "133419                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               feature extraction for analysis of ecg signals. the automated diagnostic systems employing diverse and composite features for electrocardiogram ecg signals were analyzed and their accuracies were determined. because of the importance of making the right decision classification procedures classifying the ecg signals with high accuracy were investigated. the classification accuracies of mixture of experts me trained on composite features and modified mixture of experts mme trained on diverse features were compared. the inputs of these automated diagnostic systems were composed of diverse or composite features power levels of the power spectral density estimates obtained by the eigenvector methods and were chosen according to the network structures. the conclusions of this study demonstrated that the mme trained on diverse features achieved accuracy rates which were higher than that of the me trained on composite features.   \n",
       "65431                                                                                                                                                                                                                                                                                                                                                                                                                                                                 cochlear implantation in postlingually deaf adults is time-sensitive towards positive outcome: prediction using advanced machine learning techniques. given our aging society and the prevalence of age-related hearing loss that often develops during adulthood hearing loss is a common public health issue affecting almost all older adults. moderate-to-moderately severe hearing loss can usually be corrected with hearing aids; however severe-to-profound hearing loss often requires a cochlear implant ci . however post-operative ci results vary and the performance of the previous prediction models is limited indicating that a new approach is needed. for postlingually deaf adults nde120 who received ci with full insertion we predicted ci outcomes using a random-forest regression rfr model and investigated the effect of preoperative factors on ci outcomes. postoperative word recognition scores wrs served as the dependent variable to predict. predictors included duration of deafness dod age at ci operation ageci duration of hearing-aid use doha preoperative hearing threshold and sentence recognition score. prediction accuracy was evaluated using mean absolute error mae and pearson's correlation coefficient r between the true wrs and predicted wrs. the fitting using a linear model resulted in prediction of wrs with r=0.7 and mae=15.6±9. rfr outperformed the linear model r=0.96 mae=6.1±4.7 p<0.00001 . cross-hospital data validation showed reliable performance using rfr r=0.91 mae=9.6±5.2 . the contribution of dod to prediction was the highest mae increase when omitted: 14.8 followed by ageci 8.9 and doha 7.5 . after ci patients with dod<10 years presented better wrss and smaller variations p<0.01 than those with longer dod. better wrs was also explained by younger age at ci and longer-term doha. machine learning demonstrated a robust prediction performance for ci outcomes in postlingually deaf adults across different institutes providing a reference value for counseling patients considering ci. health care providers should be aware that the patients with severe-to-profound hearing loss who cannot have benefit from hearing aids need to proceed with ci as soon as possible and should continue using hearing aids until after ci operation.   \n",
       "26463                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         aa comparison of dynamic modeling approaches for epileptic eeg detection and classification. electroencephalogram eeg has been intensively used as a diagnosis tool for epilepsy. the traditional diagnostic procedure relies on a recording of eeg from several days up to a few weeks and the recordings are visually inspected by trained medical professionals. this procedure is time consuming with a high misdiagnosis rate. in recent years computer-aided techniques have been proposed to automate the epilepsy diagnosis by using machine learning methods to analyze eeg data. considering the time-varying nature of eeg the goal of this work is to characterize dynamic changes of eeg patterns for the detection and classification of epilepsy. four different dynamic bayesian modeling methods were evaluated using multi-subject epileptic eeg data. experimental results show that an accuracy of 98.0% can be achieved by one of the four methods. the same method also provides an overall accuracy of 87.7% for the classification of seven different seizure types.   \n",
       "10662                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                an ai-powered blood test to detect cancer using nanodsf. glioblastoma is the most frequent and aggressive primary brain tumor. its diagnosis is based on resection or biopsy that could be especially difficult and dangerous in the case of deep location or patient comorbidities. monitoring disease evolution and progression also requires repeated biopsies that are often not feasible. therefore there is an urgent need to develop biomarkers to diagnose and follow glioblastoma evolution in a minimally invasive way. in the present study we described a novel cancer detection method based on plasma denaturation profiles obtained by a non-conventional use of differential scanning fluorimetry. using blood samples from 84 glioma patients and 63 healthy controls we showed that their denaturation profiles can be automatically distinguished with the help of machine learning algorithms with 92% accuracy. proposed high throughput workflow can be applied to any type of cancer and could become a powerful pan-cancer diagnostic and monitoring tool requiring only a simple blood test.   \n",
       "77895                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  prediction of activation patterns preceding hallucinations in patients with schizophrenia using machine learning with structured sparsity. despite significant progress in the field the detection of fmri signal changes during hallucinatory events remains difficult and time-consuming. this article first proposes a machine-learning algorithm to automatically identify resting-state fmri periods that precede hallucinations versus periods that do not. when applied to whole-brain fmri data state-of-the-art classification methods such as support vector machines svm yield dense solutions that are difficult to interpret. we proposed to extend the existing sparse classification methods by taking the spatial structure of brain images into account with structured sparsity using the total variation penalty. based on this approach we obtained reliable classifying performances associated with interpretable predictive patterns composed of two clearly identifiable clusters in speech-related brain regions. the variation in transition-to-hallucination functional patterns not only from one patient to another but also from one occurrence to the next e.g. also depending on the sensory modalities involved appeared to be the major difficulty when developing effective classifiers. consequently second this article aimed to characterize the variability within the prehallucination patterns using an extension of principal component analysis with spatial constraints. the principal components pcs and the associated basis patterns shed light on the intrinsic structures of the variability present in the dataset. such results are promising in the scope of innovative fmri-guided therapy for drug-resistant hallucinations such as fmri-based neurofeedback.   \n",
       "34682                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              risk factors for chronic diabetes patients. specific predictive models for diabetes polyneuropathy based on screening methods for example nerve conduction studies ncs can reach up to auc 65.8-84.7 % for the conditional diagnosis of dpn in primary care. prediction methods that utilize data from personal health records deal with large non-specific datasets with different prediction methods. it was demonstrated that the machine learning methods allow to achieve up to 0.7982 precision 0.8152 recall 0.8064 f1-score 0.8261 accuracy and 0.8988 auc using the neural network classifier.   \n",
       "19158                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   segmentation of chronic subdural hematomas using 3d convolutional neural networks. chronic subdural hematomas csdhs are an increasingly prevalent neurologic disease that often requires surgical intervention to alleviate compression of the brain. management of csdhs relies heavily on computed tomography ct imaging and serial imaging is frequently obtained to help direct management. the volume of hematoma provides critical information in guiding therapy and evaluating new methods of management. we set out to develop an automated program to compute the volume of hematoma on ct scans for both pre- and postoperative images.   \n",
       "6865                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               a novel deep autoencoder based survival analysis approach for microarray dataset. breast cancer is one of the major causes of mortality globally. therefore different machine learning ml techniques were deployed for computing survival and diagnosis. survival analysis methods are used to compute survival probability and the most important factors affecting that probability. most survival analysis methods are used to deal with clinical features up to hundreds hence applying survival analysis methods like cox regression on rnaseq microarray data with many features up to thousands is considered a major challenge.   \n",
       "106469                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  a new approach for clustered mcs classification with sparse features learning and twsvm. in digital mammograms an early sign of breast cancer is the existence of microcalcification clusters mcs which is very important to the early breast cancer detection. in this paper a new approach is proposed to classify and detect mcs. we formulate this classification problem as sparse feature learning based classification on behalf of the test samples with a set of training samples which are also known as a \"vocabulary\" of visual parts. a visual information-rich vocabulary of training samples is manually built up from a set of samples which include mcs parts and no-mcs parts. with the prior ground truth of mcs in mammograms the sparse feature learning is acquired by the l p -regularized least square approach with the interior-point method. then we designed the sparse feature learning based mcs classification algorithm using twin support vector machines twsvms . to investigate its performance the proposed method is applied to ddsm datasets and compared with support vector machines svms with the same dataset. experiments have shown that performance of the proposed method is more efficient or better than the state-of-art methods.   \n",
       "126748                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              an efficient automated algorithm to detect ocular surface temperature on sequence of thermograms using snake and target tracing function. functional infrared ir imaging is widely adopted in medical field nowadays with more emphasis on breast cancer and ocular abnormalities. in this article an algorithm is presented to accurately locate the eye and cornea in ocular thermographic sequences which were recorded utilizing functional infrared imaging. the localization is achieved by snake algorithm coupled with a newly proposed target tracing function. the target tracing function enables automated localization allows the absence of any manual assistance before the algorithm runs. genetic algorithm is used to perform the search for global minimum on the function to produce desired localization. on all the cases we have studied in average the region encircled by the algorithm covers 92% of the true ocular region. as for the non-ocular region covered it only accounts for less than 5% of the encircled region.   \n",
       "136647                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               identification of ischemic heart disease via machine learning analysis on magnetocardiograms. ischemic heart disease ihd is predominantly the leading cause of death worldwide. early detection of ihd may effectively prevent severity and reduce mortality rate. recently magnetocardiography mcg has been developed for the detection of heart malfunction. although mcg is capable of monitoring the abnormal patterns of magnetic field as emitted by physiologically defective heart data interpretation is time-consuming and requires highly trained professional. hence we propose an automatic method for the interpretation of ihd pattern of mcg recordings using machine learning approaches. two types of machine learning techniques namely back-propagation neural network bnn and direct kernel self-organizing map dk-som were applied to explore the ihd pattern recorded by mcg. data sets were obtained by sequential measurement of magnetic field emitted by cardiac muscle of 125 individuals. data were divided into training set and testing set of 74 cases and 51 cases respectively. predictive performance was obtained by both machine learning approaches. the bnn exhibited sensitivity of 89.7% specificity of 54.5% and accuracy of 74.5% while the dk-som provided relatively higher prediction performance with a sensitivity specificity and accuracy of 86.2% 72.7% and 80.4% respectively. this finding suggests a high potential of applying machine learning approaches for high-throughput detection of ihd from mcg data.   \n",
       "92278                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    a framework for the automatic detection and characterization of brain malformations: validation on the corpus callosum. in this paper we extend the one-class support vector machine svm and the regularized discriminative direction analysis to the multiple kernel mk framework providing an effective analysis pipeline for the detection and characterization of brain malformations in particular those affecting the corpus callosum. the detection of the brain malformations is currently performed by visual inspection of mri images making the diagnostic process sensible to the operator experience and subjectiveness. the method we propose addresses these problems by automatically reproducing the neuroradiologist's approach. one-class svms are appropriate to cope with heterogeneous brain abnormalities that are considered outliers. the mk framework allows to efficiently combine the different geometric features that can be used to describe brain structures. moreover the regularized discriminative direction analysis is exploited to highlight the specific malformative patterns for each patient. we performed two different experiments. firstly we tested the proposed method to detect the malformations of the corpus callosum on a 104 subject dataset. results showed that the proposed pipeline can classify the subjects with an accuracy larger than 90% and that the discriminative direction analysis can highlight a wide range of malformative patterns e.g. local diffuse and complex abnormalities . secondly we compared the diagnosis of four neuroradiologists on a dataset of 128 subjects. the diagnosis was performed both in blind condition and using the classifier and the discriminative direction outputs. results showed that the use of the proposed pipeline as an assisted diagnosis tool improves the inter-subject variability of the diagnosis. finally a graphical representation of the discriminative direction analysis was proposed to enhance the interpretability of the results and provide the neuroradiologist with a tool to fully and clearly characterize the patient malformations at single-subject level.   \n",
       "40051                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    primage project: predictive in silico multiscale analytics to support childhood cancer personalised evaluation empowered by imaging biomarkers. primage is one of the largest and more ambitious research projects dealing with medical imaging artificial intelligence and cancer treatment in children. it is a 4-year european commission-financed project that has 16 european partners in the consortium including the european society for paediatric oncology two imaging biobanks and three prominent european paediatric oncology units. the project is constructed as an observational in silico study involving high-quality anonymised datasets imaging clinical molecular and genetics for the training and validation of machine learning and multiscale algorithms. the open cloud-based platform will offer precise clinical assistance for phenotyping diagnosis treatment allocation prediction and patient endpoints prognosis based on the use of imaging biomarkers tumour growth simulation advanced visualisation of confidence scores and machine-learning approaches. the decision support prototype will be constructed and validated on two paediatric cancers: neuroblastoma and diffuse intrinsic pontine glioma. external validation will be performed on data recruited from independent collaborative centres. final results will be available for the scientific community at the end of the project and ready for translation to other malignant solid tumours.   \n",
       "26404                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     end-to-end deep learning model for cardiac cycle synchronization from multi-view angiographic sequences. dynamic reconstructions 3dt of coronary arteries could give important perfusion details to clinicians. temporal matching of the different views which may not be acquired simultaneously is a prerequisite for an accurate stereo-matching of the coronary segments. in this paper we show how a neural network can be trained from angiographic sequences to synchronize different views during the cardiac cycle using raw x-ray angiography videos exclusively. first we train a neural network model with angiographic sequences to extract features describing the progression of the cardiac cycle. then we compute the distance between the feature vectors of every frame from the first view with those from the second view to generate distance maps that display stripe patterns. using pathfinding we extract the best temporally coherent associations between each frame of both videos. finally we compare the synchronized frames of an evaluation set with the ecg signals to show an alignment with 96.04% accuracy.   \n",
       "49833                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              rapid muscle volume prediction using anthropometric measurements and population-derived statistical models. knowledge of subject-specific muscle volumes may be used as surrogates for evaluating muscle strength and power generated by 'fat-free' muscle mass. this study presents population-based statistical learning approaches for predicting 'fat-free' muscle volume from known anthropometric measurements. using computed tomography ct imaging data to obtain lower-limb muscle volumes from 50 men and women this study evaluated six statistical learning methods for predicting muscle volumes from anthropometric measurements: i stepwise regression ii linear support vector machine svm  iii 2nd-order polynomial svm iv linear partial least squares regression plsr  v quadratic plsr and vi 3rd-order spline fit plsr. these techniques have successfully been demonstrated in bioengineering applications and freely available in open-source toolkits. analysis revealed that separating a general population into sexes and/or cohorts based on adipose level may improve prediction accuracies. the most important measures that statistically influence muscle volume predictions were shank girth followed by sex and finally leg length as identified using stepwise regression. svm learning predicted muscle volume with an accuracy of 85±4% when using linear interpolation but performed poorly with an accuracy of 59±6% using polynomial interpolation. the simpler linear plsr exhibited muscle volume prediction accuracy of 87±2% while quadratic plsr was slightly reduced at 82±3%. for the spline fit plsr high accuracy was observed on the training data set ~99% but over-fitting a drawback of high-interpolation methods resulted in erroneous predictions on testing data and hence the model was deemed unsuitable. in conclusion use of linear plsr models with variables of sex leg length and shank girth is a useful tool for predicting 'fat-free' muscle volume.   \n",
       "79244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        artificial neural network: a method for prediction of surgery-related pressure injury in cardiovascular surgical patients. the aim of this study was to build an artificial neural network ann model for predicting surgery-related pressure injury srpi in cardiovascular surgical patients.   \n",
       "8453                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             fatty liver disease prediction model based on big data of electronic physical examination records. fatty liver disease fld is a common liver disease which poses a great threat to people's health but there is still no optimal method that can be used on a large-scale screening. this research is based on machine learning algorithms using electronic physical examination records in the health database as data support to a predictive model for fld. the model has shown good predictive ability on the test set with its auc reaching 0.89. since there are a large number of electronic physical examination records in most of health database this model might be used as a non-invasive diagnostic tool for fld for large-scale screening.   \n",
       "618                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          deepprog: an ensemble of deep-learning and machine-learning models for prognosis prediction using multi-omics data. multi-omics data are good resources for prognosis and survival prediction; however these are difficult to integrate computationally. we introduce deepprog a novel ensemble framework of deep-learning and machine-learning approaches that robustly predicts patient survival subtypes using multi-omics data. it identifies two optimal survival subtypes in most cancers and yields significantly better risk-stratification than other multi-omics integration methods. deepprog is highly predictive exemplified by two liver cancer c-index 0.73-0.80 and five breast cancer datasets c-index 0.68-0.73 . pan-cancer analysis associates common genomic signatures in poor survival subtypes with extracellular matrix modeling immune deregulation and mitosis processes. deepprog is freely available at https://github.com/lanagarmire/deepprog.   \n",
       "76598                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ensemble of shape functions and support vector machines for the estimation of discrete arm muscle activation from external biceps 3d point clouds. muscle activation level is currently being captured using impractical and expensive devices which make their use in telemedicine settings extremely difficult. to address this issue a prototype is presented of a non-invasive easy-to-install system for the estimation of a discrete level of muscle activation of the biceps muscle from 3d point clouds captured with rgb-d cameras.   \n",
       "64981                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  machine learning-based radiomic models to predict intensity-modulated radiation therapy response gleason score and stage in prostate cancer. to develop different radiomic models based on the magnetic resonance imaging mri radiomic features and machine learning methods to predict early intensity-modulated radiation therapy imrt response gleason scores gs and prostate cancer pca stages.   \n",
       "47354                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               computer-aided diagnosis of multiple sclerosis using a support vector machine and optical coherence tomography features. the purpose of this paper is to evaluate the feasibility of diagnosing multiple sclerosis ms using optical coherence tomography oct data and a support vector machine svm as an automatic classifier. forty-eight ms patients without symptoms of optic neuritis and forty-eight healthy control subjects were selected. swept-source optical coherence tomography ss-oct was performed using a dri deep-range imaging triton oct device topcon corp. tokyo japan . mean values right and left eye for macular thickness retinal and choroidal layers and peripapillary area retinal nerve fibre layer retinal ganglion cell layer-gcl and choroidal layers were compared between both groups. based on the analysis of the area under the receiver operator characteristic curve auc the 3 variables with the greatest discriminant capacity were selected to form the feature vector. a svm was used as an automatic classifier obtaining the confusion matrix using leave-one-out cross-validation. classification performance was assessed with matthew's correlation coefficient mcc and the aucclassifier. the most discriminant variables were found to be the total gcl thickness between inner limiting membrane to inner nuclear layer boundaries evaluated in the peripapillary area and macular retina thickness in the nasal quadrant of the outer and inner rings. using the svm classifier we obtained the following values: mcc = 0.81 sensitivity = 0.89 specificity = 0.92 accuracy = 0.91 and aucclassifier = 0.97. our findings suggest that it is possible to classify control subjects and ms patients without previous optic neuritis by applying machine-learning techniques to study the structural neurodegeneration in the retina.   \n",
       "98850                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             breast cancer detection with reduced feature set. this paper explores feature reduction properties of independent component analysis ica on breast cancer decision support system. wisconsin diagnostic breast cancer wdbc dataset is reduced to one-dimensional feature vector computing an independent component ic . the original data with 30 features and reduced one feature ic are used to evaluate diagnostic accuracy of the classifiers such as k-nearest neighbor k-nn artificial neural network ann radial basis function neural network rbfnn and support vector machine svm . the comparison of the proposed classification using the ic with original feature set is also tested on different validation 5/10-fold cross-validations and partitioning 20%-40% methods. these classifiers are evaluated how to effectively categorize tumors as benign and malignant in terms of specificity sensitivity accuracy f-score youden's index discriminant power and the receiver operating characteristic roc curve with its criterion values including area under curve auc and 95% confidential interval ci . this represents an improvement in diagnostic decision support system while reducing computational complexity.    \n",
       "59288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         deep learning in the prediction of ischaemic stroke thrombolysis functional outcomes: a pilot study. intravenous thrombolysis decision-making and obtaining of consent would be assisted by an individualized risk-benefit ratio. deep learning dl models may be able to assist with this patient selection.   \n",
       "3069                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          characterizing brain tumor regions using texture analysis in magnetic resonance imaging. to extract texture features from magnetic resonance imaging mri scans of patients with brain tumors and use them to train a classification model for supporting an early diagnosis.   \n",
       "33698                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   texture synthesis based thyroid nodule detection from medical ultrasound images: interpreting and suppressing the adversarial effect of in-place manual annotation. deep learning method have been offering promising solutions for medical image processing but failing to understand what features in the input image are captured and whether certain artifacts are mistakenly included in the model thus create crucial problems in generalizability of the model. we targeted a common issue of this kind caused by manual annotations appeared in medical image. these annotations are usually made by the doctors at the spot of medical interest and have adversarial effect on many computer vision ai tasks. we developed an inpainting algorithm to remove the annotations and recover the original images. besides we applied variational information bottleneck method in order to filter out the unwanted features and enhance the robustness of the model. our impaiting algorithm is extensively tested in object detection in thyroid ultrasound image data. the map mean average precision with iou = 0.3 is 27% without the annotation removal. the map is 83% if manually removed the annotations using photoshop and is enhanced to 90% using our inpainting algorithm. our work can be utilized in future development and evaluation of artificial intelligence models based on medical images with defects.   \n",
       "31508                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       psa-based machine learning model improves prostate cancer risk stratification in a screening population. the majority of prostate cancer diagnoses are facilitated by testing serum prostate specific antigen psa levels. despite this there are limitations to the diagnostic accuracy of psa. consideration of patient demographic factors and biochemical adjuncts to psa may improve prostate cancer risk stratification. we aimed to develop a contemporary accurate and cost-effective model based on objective measures to improve the accuracy of prostate cancer risk stratification.   \n",
       "32519                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             predictive value of the texture analysis of enhanced computed tomographic images for preoperative pancreatic carcinoma differentiation. to assess the utility of texture analysis for predicting the pathological degree of differentiation of pancreatic carcinoma pc .   \n",
       "14576                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           eliminating indefiniteness of clinical spectrum for better screening covid-19. the coronavirus disease 2019 covid-19 has swept all over the world. due to the limited detection facilities especially in developing countries a large number of suspected cases can only receive common clinical diagnosis rather than more effective detections like reverse transcription polymerase chain reaction rt-pcr tests or ct scans. this motivates us to develop a quick screening method via common clinical diagnosis results. however the diagnostic items of different patients may vary greatly and there is a huge variation in the dimension of the diagnosis data among different suspected patients it is hard to process these indefinite dimension data via classical classification algorithms. to resolve this problem we propose an indefiniteness elimination network ie-net to eliminate the influence of the varied dimensions and make predictions about the covid-19 cases. the ie-net is in an encoder-decoder framework fashion and an indefiniteness elimination operation is proposed to transfer the indefinite dimension feature into a fixed dimension feature. comprehensive experiments were conducted on the public available covid-19 clinical spectrum dataset. experimental results show that the proposed indefiniteness elimination operation greatly improves the classification performance the ie-net achieves 94.80% accuracy 92.79% recall 92.97% precision and 94.93% auc for distinguishing covid-19 cases from non-covid-19 cases with only common clinical diagnose data. we further compared our methods with 3 classical classification algorithms: random forest gradient boosting and multi-layer perceptron mlp . to explore each clinical test item's specificity we further analyzed the possible relationship between each clinical test item and covid-19.   \n",
       "14483                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   predicting cardiovascular risk using social media data: performance evaluation of machine-learning models. current atherosclerotic cardiovascular disease ascvd predictive models have limitations; thus efforts are underway to improve the discriminatory power of ascvd models.   \n",
       "78319                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         precision cohort finding with outcome-driven similarity analytics: a case study of patients with atrial fibrillation. dividing patients into similar groups plays a significant role in implementing personalized care. clinicians and researchers have been applying patient grouping techniques in disease phenotyping risk stratification and personalized medicine. however the current approaches are either based on pure domain knowledge where the underlying patient similarity cannot be precisely quantified or based on unsupervised clustering techniques which completely ignore the clinical context of measuring patient similarity. in the study we propose an outcome-driven approach to identify clinically similar patients which are grouped together as a precision cohort. the approach quantitatively measures the similarity between patients in terms of a particular clinical outcome of interest thus patients who have a similar clinical outcome tend to be grouped into the same group. we demonstrate the effectiveness of the approach in a real-world case study: from an atrial fibrillation patient cohort that is usually considered to be at high risk for ischemic stroke is according to current clinical guidelines. our approach successfully identified a precision cohort of patients with truly low risk of is.   \n",
       "11310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              deep convolutional neural network for the automated detection of subthalamic nucleus using mer signals. deep brain stimulation dbs surgery has been extensively conducted for treating advanced parkinson's disease pd patient's symptoms. dbs hinges on the localization of the subthalamic nucleus stn in which a permanent electrode should be accurately placed to produce electrical current. microelectrode recording mer signals are routinely recorded in the procedure of dbs surgery to validate the planned trajectories. however manual mer signals interpretation with the goal of detecting stn borders requires expertise and prone to inter-observer variability. therefore a computerized aided system would be beneficial to automatic detection of the dorsal and ventral borders of the stn in mer.   \n",
       "55642                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               wearable sensors for parkinson's disease: which data are worth collecting for training symptom detection models. machine learning algorithms that use data streams captured from soft wearable sensors have the potential to automatically detect pd symptoms and inform clinicians about the progression of disease. however these algorithms must be trained with annotated data from clinical experts who can recognize symptoms and collecting such data are costly. understanding how many sensors and how much labeled data are required is key to successfully deploying these models outside of the clinic. here we recorded movement data using 6 flexible wearable sensors in 20 individuals with pd over the course of multiple clinical assessments conducted on 1 day and repeated 2 weeks later. participants performed 13 common tasks such as walking or typing and a clinician rated the severity of symptoms bradykinesia and tremor . we then trained convolutional neural networks and statistical ensembles to detect whether a segment of movement showed signs of bradykinesia or tremor based on data from tasks performed by other individuals. our results show that a single wearable sensor on the back of the hand is sufficient for detecting bradykinesia and tremor in the upper extremities whereas using sensors on both sides does not improve performance. increasing the amount of training data by adding other individuals can lead to improved performance but repeating assessments with the same individuals-even at different medication states-does not substantially improve detection across days. our results suggest that pd symptoms can be detected during a variety of activities and are best modeled by a dataset incorporating many individuals.   \n",
       "5038                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           handheld briefcase optical coherence tomography with real-time machine learning classifier for middle ear infections. a middle ear infection is a prevalent inflammatory disease most common in the pediatric population and its financial burden remains substantial. current diagnostic methods are highly subjective relying on visual cues gathered by an otoscope. to address this shortcoming optical coherence tomography oct has been integrated into a handheld imaging probe. this system can non-invasively and quantitatively assess middle ear effusions and identify the presence of bacterial biofilms in the middle ear cavity during ear infections. furthermore the complete oct system is housed in a standard briefcase to maximize its portability as a diagnostic device. nonetheless interpreting oct images of the middle ear more often requires expertise in oct as well as middle ear infections making it difficult for an untrained user to operate the system as an accurate stand-alone diagnostic tool in clinical settings. here we present a briefcase oct system implemented with a real-time machine learning platform for middle ear infections. a random forest-based classifier can categorize images based on the presence of middle ear effusions and biofilms. this study demonstrates that our briefcase oct system coupled with machine learning can provide user-invariant classification results of middle ear conditions which may greatly improve the utility of this technology for the diagnosis and management of middle ear infections.   \n",
       "115260                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  neuroanatomical pattern classification in a population-based sample of first-episode schizophrenia. recent neuroanatomical pattern classification studies have attempted to individually classify cases with psychotic disorders using morphometric mri data in an automated fashion. however this approach has not been tested in population-based samples in which variable patterns of comorbidity and disease course are typically found. we aimed to evaluate the diagnostic accuracy da of the above technique to discriminate between incident cases of first-episode schizophrenia identified in a circumscribed geographical region over a limited period of time in comparison with next-door healthy controls. sixty-two cases of first-episode schizophrenia or schizophreniform disorder and 62 age gender and educationally-matched controls underwent 1.5 t mri scanning at baseline and were naturalistically followed-up over 1 year. t1-weighted images were used to train a high-dimensional multivariate classifier and to generate both spatial maps of the discriminative morphological patterns between groups and roc curves. the spatial map discriminating first-episode schizophrenia patients from healthy controls revealed a complex pattern of regional volumetric abnormalities in the former group affecting fronto-temporal-occipital gray and white matter regions bilaterally including the inferior fronto-occipital fasciculus as well as the third and lateral ventricles. however an overall modest da 73.4% was observed for the individual discrimination between first-episode schizophrenia patients and controls and the classifier failed to predict 1-year prognosis remitting versus non-remitting course of first-episode schizophrenia da=58.3% . in conclusion using a \"real world\" sample recruited with epidemiological methods the application of a neuroanatomical pattern classifier afforded only modest da to classify first-episode schizophrenia subjects and next-door healthy controls and poor discriminative power to predict the 1-year prognosis of first-episode schizophrenia.   \n",
       "122817                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               characterization of groups using composite kernels and multi-source fmri analysis data: application to schizophrenia. pattern classification of brain imaging data can enable the automatic detection of differences in cognitive processes of specific groups of interest. furthermore it can also give neuroanatomical information related to the regions of the brain that are most relevant to detect these differences by means of feature selection procedures which are also well-suited to deal with the high dimensionality of brain imaging data. this work proposes the application of recursive feature elimination using a machine learning algorithm based on composite kernels to the classification of healthy controls and patients with schizophrenia. this framework which evaluates nonlinear relationships between voxels analyzes whole-brain fmri data from an auditory task experiment that is segmented into anatomical regions and recursively eliminates the uninformative ones based on their relevance estimates thus yielding the set of most discriminative brain areas for group classification. the collected data was processed using two analysis methods: the general linear model glm and independent component analysis ica . glm spatial maps as well as ica temporal lobe and default mode component maps were then input to the classifier. a mean classification accuracy of up to 95% estimated with a leave-two-out cross-validation procedure was achieved by doing multi-source data classification. in addition it is shown that the classification accuracy rate obtained by using multi-source data surpasses that reached by using single-source data hence showing that this algorithm takes advantage of the complimentary nature of glm and ica.   \n",
       "145427                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              risk factor identification and mortality prediction in cardiac surgery using artificial neural networks. the artificial neural network model is a nonlinear technology useful for complex pattern recognition problems. this study aimed to develop a method to select risk variables and predict mortality after cardiac surgery by using artificial neural networks.   \n",
       "20564                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  hub gene identification and prognostic model construction for isocitrate dehydrogenase mutation in glioma. our study attempted to identify hub genes related to isocitrate dehydrogenase idh mutation in glioma and develop a prognostic model for idh-mutant glioma patients. in a first step ten hub genes significantly associated with the idh status were identified by weighted gene coexpression analysis wgcna . the functional enrichment analysis demonstrated that the most enriched terms of these hub genes were cadherin binding and glutathione metabolism. three of these hub genes were significantly linked with the survival of glioma patients. 328 samples of idh-mutant glioma were separated into two datasets: a training set n¯=¯228 and a test set n¯=¯100 . based on the training set we identified two idh-mutant subtypes with significantly different pathological features by using consensus clustering. a 31 gene-signature was identified by the least absolute shrinkage and selection operator lasso algorithm and used for establishing a differential prognostic model for idh-mutant patients. in addition the test set was employed for validating the prognostic model and the model was proven to be of high value in classifying prognostic information of samples. the functional annotation revealed that the genes related to the model were mainly enriched in nuclear division dna replication and cell cycle. collectively this study provided novel insights into the molecular mechanism of idh mutation in glioma and constructed a prognostic model which can be effective for predicting prognosis of glioma patients with idh-mutation which might promote the development of idh target agents in glioma therapies and contribute to accurate prognostication and management in idh-mutant glioma patients.   \n",
       "31644                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   deep learning-based classification of posttraumatic stress disorder and depression following trauma utilizing visual and auditory markers of arousal and mood. visual and auditory signs of patient functioning have long been used for clinical diagnosis treatment selection and prognosis. direct measurement and quantification of these signals can aim to improve the consistency sensitivity and scalability of clinical assessment. currently we investigate if machine learning-based computer vision cv semantic and acoustic analysis can capture clinical features from free speech responses to a brief interview 1 month post-trauma that accurately classify major depressive disorder mdd and posttraumatic stress disorder ptsd .   \n",
       "107242                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             detection of systolic ejection click using time growing neural network. in this paper we present a novel neural network for classification of short-duration heart sounds: the time growing neural network tgnn . the input to the network is the spectral power in adjacent frequency bands as computed in time windows of growing length. children with heart systolic ejection click sec and normal children are the two groups subjected to analysis. the performance of the tgnn is compared to that of a time delay neural network tdnn and a multi-layer perceptron mlp using training and test datasets of similar sizes with a total of 614 normal and abnormal cardiac cycles. from the test dataset the classification rate/sensitivity is found to be 97.0%/98.1% for the tgnn 85.1%/76.4% for the tdnn and 92.7%/85.7% for the mlp. the results show that the tgnn performs better than do tdnn and mlp when frequency band power is used as classifier input. the performance of tgnn is also found to exhibit better immunity to noise.    \n",
       "158091                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           automatic detection and classification of abnormalities for artificial hearts using a hierarchical self-organizing map. a hierarchical self-organizing map som has been developed for automatic detection and classification of abnormalities for artificial hearts. the hierarchical som has been applied to the monitoring and analysis of an aortic pressure aop signal measured from an adult goat equipped with a total artificial heart. the architecture of the network actually consists of 2 different soms. the first som clusters the aop beat patterns in an unsupervised way. afterward the outputs of the first som combined with the original time-domain features of beat-to-beat data are fed to the second som for final classification. each input vector of the second som is associated with a class vector. this class vector is assigned to every node in the second map as an output weight and learned according to kohonen's learning rule. some experimental results revealed that a certain abnormality caused by breakage of sensors could be identified and detected correctly and that the change in the state of the circulatory system could be recognized and predicted to some extent.   \n",
       "112982                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             functional activity maps based on significance measures and independent component analysis. the use of functional imaging has been proven very helpful for the process of diagnosis of neurodegenerative diseases such as alzheimer's disease ad . in many cases the analysis of these images is performed by manual reorientation and visual interpretation. therefore new statistical techniques to perform a more quantitative analysis are needed. in this work a new statistical approximation to the analysis of functional images based on significance measures and independent component analysis ica is presented. after the images preprocessing voxels that allow better separation of the two classes are extracted using significance measures such as the mann-whitney-wilcoxon u-test mww and relative entropy re . after this feature selection step the voxels vector is modelled by means of ica extracting a few independent components which will be used as an input to the classifier. naive bayes and support vector machine svm classifiers are used in this work. the proposed system has been applied to two different databases. a 96-subjects single photon emission computed tomography spect database from the \"virgen de las nieves\" hospital in granada spain and a 196-subjects positron emission tomography pet database from the alzheimer's disease neuroimaging initiative adni . values of accuracy up to 96.9% and 91.3% for spect and pet databases are achieved by the proposed system which has yielded many benefits over methods proposed on recent works.   \n",
       "19683                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             a tool for patient-specific prediction of delivery discrepancies in machine parameters using trajectory log files. multileaf collimator mlc delivery discrepancy between planned and actual delivered positions have detrimental effect on the accuracy of dose distributions for both imrt and vmat. in this study we evaluated the consistency of mlc delivery discrepancies over the course of treatment and over time to verify that a predictive machine learning model would be applicable throughout the course of treatment. next the mlc and gantry positions recorded in prior trajectory log files were analyzed to build a machine learning algorithm to predict mlc positional discrepancies during delivery for a new treatment plan. an open source tool was developed and released to predict the mlc positional discrepancies at treatment delivery for any given plan.   \n",
       "127417                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              co-morbidity analysis and decision support on transplanted patients using machine learning techniques. the a coruã±a university hospital complex is developing an expert system to improve the decision support for transplanted patients. the system will access the data collected during the monitoring of patients and generate a database of statistics that will aid health professionals in several stages of the transplant process. all historical data will be revised to give an estimation of the patient's parameters evolution depending on his medical record and his actual treatment. we will use two different machine learning techniques to do both clustering and classification.   \n",
       "11431                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 time-frequency time-space lstm for robust classification of physiological signals. automated analysis of physiological time series is utilized for many clinical applications in medicine and life sciences. long short-term memory lstm is a deep recurrent neural network architecture used for classification of time-series data. here time-frequency and time-space properties of time series are introduced as a robust tool for lstm processing of long sequential data in physiology. based on classification results obtained from two databases of sensor-induced physiological signals the proposed approach has the potential for 1 achieving very high classification accuracy 2 saving tremendous time for data learning and 3 being cost-effective and user-comfortable for clinical trials by reducing multiple wearable sensors for data recording.   \n",
       "102714                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 a combined segmenting and non-segmenting approach to signal quality estimation for ambulatory photoplethysmography. continuous cardiac monitoring of healthy and unhealthy patients can help us understand the progression of heart disease and enable early treatment. optical pulse sensing is an excellent candidate for continuous mobile monitoring of cardiovascular health indicators but optical pulse signals are susceptible to corruption from a number of noise sources including motion artifact. therefore before higher-level health indicators can be reliably computed corrupted data must be separated from valid data. this is an especially difficult task in the presence of artifact caused by ambulation e.g. walking or jogging which shares significant spectral energy with the true pulsatile signal. in this manuscript we present a machine-learning-based system for automated estimation of signal quality of optical pulse signals that performs well in the presence of periodic artifact. we hypothesized that signal processing methods that identified individual heart beats segmenting approaches would be more error-prone than methods that did not non-segmenting approaches when applied to data contaminated by periodic artifact. we further hypothesized that a fusion of segmenting and non-segmenting approaches would outperform either approach alone. therefore we developed a novel non-segmenting approach to signal quality estimation that we then utilized in combination with a traditional segmenting approach. using this system we were able to robustly detect differences in signal quality as labeled by expert human raters pearson's r = 0.9263 . we then validated our original hypotheses by demonstrating that our non-segmenting approach outperformed the segmenting approach in the presence of contaminated signal and that the combined system outperformed either individually. lastly as an example we demonstrated the utility of our signal quality estimation system in evaluating the trustworthiness of heart rate measurements derived from optical pulse signals.    \n",
       "29857                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      a combined deep cnn-lstm network for the detection of novel coronavirus covid-19 using x-ray images. nowadays automatic disease detection has become a crucial issue in medical science due to rapid population growth. an automatic disease detection framework assists doctors in the diagnosis of disease and provides exact consistent and fast results and reduces the death rate. coronavirus covid-19 has become one of the most severe and acute diseases in recent times and has spread globally. therefore an automated detection system as the fastest diagnostic option should be implemented to impede covid-19 from spreading. this paper aims to introduce a deep learning technique based on the combination of a convolutional neural network cnn and long short-term memory lstm to diagnose covid-19 automatically from x-ray images. in this system cnn is used for deep feature extraction and lstm is used for detection using the extracted feature. a collection of 4575 x-ray images including 1525 images of covid-19 were used as a dataset in this system. the experimental results show that our proposed system achieved an accuracy of 99.4% auc of 99.9% specificity of 99.2% sensitivity of 99.3% and f1-score of 98.9%. the system achieved desired results on the currently available dataset which can be further improved when more covid-19 images become available. the proposed system can help doctors to diagnose and treat covid-19 patients easily.   \n",
       "60729                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           early prediction of critical events for infants with single-ventricle physiology in critical care using routinely collected data. critical events are common and difficult to predict among infants with congenital heart disease and are associated with mortality and long-term sequelae. we aimed to achieve early prediction of critical events that is cardiopulmonary resuscitation emergency endotracheal intubation and extracorporeal membrane oxygenation in infants with single-ventricle physiology before second-stage surgery. we hypothesized that naã¯ve bayesian models learned from expert knowledge and clinical data can predict critical events early and accurately.   \n",
       "100709                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ultrasound-based characterization of prostate cancer using joint independent component analysis. this paper presents the results of a new approach for selection of rf time series features based on joint independent component analysis for in vivo characterization of prostate cancer.   \n",
       "13855                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   multiparametric mri-based radiomics approaches for preoperative prediction of egfr mutation status in spinal bone metastases in patients with lung adenocarcinoma. preoperative prediction of epidermal growth factor receptor egfr mutation status in patients with spinal bone metastases sbm from primary lung adenocarcinoma is potentially important for treatment decisions.   \n",
       "106809                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              disease prediction based on functional connectomes using a scalable and spatially-informed support vector machine. substantial evidence indicates that major psychiatric disorders are associated with distributed neural dysconnectivity leading to a strong interest in using neuroimaging methods to accurately predict disorder status. in this work we are specifically interested in a multivariate approach that uses features derived from whole-brain resting state functional connectomes. however functional connectomes reside in a high dimensional space which complicates model interpretation and introduces numerous statistical and computational challenges. traditional feature selection techniques are used to reduce data dimensionality but are blind to the spatial structure of the connectomes. we propose a regularization framework where the 6-d structure of the functional connectome defined by pairs of points in 3-d space is explicitly taken into account via the fused lasso or the graphnet regularizer. our method only restricts the loss function to be convex and margin-based allowing non-differentiable loss functions such as the hinge-loss to be used. using the fused lasso or graphnet regularizer with the hinge-loss leads to a structured sparse support vector machine svm with embedded feature selection. we introduce a novel efficient optimization algorithm based on the augmented lagrangian and the classical alternating direction method which can solve both fused lasso and graphnet regularized svm with very little modification. we also demonstrate that the inner subproblems of the algorithm can be solved efficiently in analytic form by coupling the variable splitting strategy with a data augmentation scheme. experiments on simulated data and resting state scans from a large schizophrenia dataset show that our proposed approach can identify predictive regions that are spatially contiguous in the 6-d \"connectome space\" offering an additional layer of interpretability that could provide new insights about various disease processes.    \n",
       "126596                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    movement deviation profile: a measure of distance from normality using a self-organizing neural network. we introduce the movement deviation profile mdp which is a single curve showing the deviation of an individual's movement from normality. joint angles recorded from typically developing children over one gait cycle were used to train a self-organizing map som which then generated mdp curves for patients with gait problems. the mean mdp over the gait cycle showed a high correlation r 2 = .927 with the gait deviation index gdi a statistically significant difference between groups of patients with a range of functional levels gillette functional assessment questionnaire walking scale 7-10 and a trend of increasing values for patients with cerebral palsy through hemiplegia i-iv diplegia triplegia and quadriplegia. the small difference between the mdp and gdi can be explained by the som's method of operation comparing biomechanical patterns to the nearest abstract reference pattern and its flexibility to compensate for temporal shifts in movement data. the mdp is an alternative method of processing complex biomechanical data potentially supporting clinical interpretation. the electronic addendum accompanying this article is a standalone program which can be used to calculate the mdp from gait data and can also be used in other applications where the deviation of multi-channel temporal data from a reference is required.   \n",
       "38305                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            an open-source computer vision tool for automated vocal fold tracking from videoendoscopy. contemporary clinical assessment of vocal fold adduction and abduction is qualitative and subjective. herein is described a novel computer vision tool for automated quantitative tracking of vocal fold motion from videolaryngoscopy. the potential of this software as a diagnostic aid in unilateral vocal fold paralysis is demonstrated.   \n",
       "39678                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  invertible network for classification and biomarker selection for asd. determining biomarkers for autism spectrum disorder asd is crucial to understanding its mechanisms. recently deep learning methods have achieved success in the classification task of asd using fmri data. however due to the black-box nature of most deep learning models it's hard to perform biomarker selection and interpret model decisions. the recently proposed invertible networks can accurately reconstruct the input from its output and have the potential to unravel the black-box representation. therefore we propose a novel method to classify asd and identify biomarkers for asd using the connectivity matrix calculated from fmri as the input. specifically with invertible networks we explicitly determine the decision boundary and the projection of data points onto the boundary. like linear classifiers the difference between a point and its projection onto the decision boundary can be viewed as the explanation. we then define the importance as the explanation weighted by the gradient of prediction w.r.t the input and identify biomarkers based on this importance measure. we perform a regression task to further validate our biomarker selection: compared to using all edges in the connectivity matrix using the top 10% important edges we generate a lower regression error on 6 different severity scores. our experiments show that the invertible network is both effective at asd classification and interpretable allowing for discovery of reliable biomarkers.   \n",
       "13011                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   a method for enhancing speech and warning signals based on parallel convolutional neural networks in a noisy environment. digital hearing aids are based on technology that amplifies sound and removes noise according to the frequency of hearing loss in hearing loss patients. however within the noise removed is a warning sound that alert the listener; the listener may be exposed to danger because the warning sound is not recognized.   \n",
       "6156                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      feature selection and machine learning methods for optimal identification and prediction of subtypes in parkinson's disease. the present work focuses on assessment of parkinson's disease pd including both pd subtype identification unsupervised task and prediction supervised task . we specifically investigate optimal feature selection and machine learning algorithms for these tasks.   \n",
       "16556                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              clinicopathological features of fibrosarcomatous dermatofibrosarcoma protuberans and the construction of a back-propagation neural network recognition model. fibrosarcomatous dermatofibrosarcoma protuberans fs-dfsp is a form of tumor progression of dermatofibrosarcoma protuberans dfsp with an increased risk of metastasis and recurrence. few studies have compared the clinicopathological features of fs-dfsp and conventional dfsp c-dfsp .   \n",
       "99096                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    recurrence quantification analysis and support vector machines for golf handicap and low back pain emg classification. the quantification of non-linear characteristics of electromyography emg must contain information allowing to discriminate neuromuscular strategies during dynamic skills. there are a lack of studies about muscle coordination under motor constrains during dynamic contractions. in golf both handicap hc and low back pain lbp are the main factors associated with the occurrence of injuries. the aim of this study was to analyze the accuracy of support vector machines svm on emg-based classification to discriminate hc low and high handicap and lbp with and without lpb in the main phases of golf swing. for this purpose recurrence quantification analysis rqa features of the trunk and the lower limb muscles were used to feed a svm classifier. recurrence rate rr and the ratio between determinism det and rr showed a high discriminant power. the hc accuracy for the swing backswing and downswing were 94.4±2.7% 97.1±2.3% and 95.3±2.6% respectively. for lbp the accuracy was 96.9±3.8% for the swing and 99.7±0.4% in the backswing. external oblique eo biceps femoris bf semitendinosus st and rectus femoris rf showed high accuracy depending on the laterality within the phase. rqa features and svm showed a high muscle discriminant capacity within swing phases by hc and by lbp. low back pain golfers showed different neuromuscular coordination strategies when compared with asymptomatic.    \n",
       "47915                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          prospective validation of a machine learning model that uses provider notes to identify candidates for resective epilepsy surgery. delay to resective epilepsy surgery results in avoidable disease burden and increased risk of mortality. the objective was to prospectively validate a natural language processing nlp application that uses provider notes to assign epilepsy surgery candidacy scores.   \n",
       "59936                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                binary tree-like network with two-path fusion attention feature for cervical cell nucleus segmentation. early detection of cervical lesion is of great significance in reducing mortality from cervical cancer and segmentation of cervical cell nuclei plays an important role in screening for cervical lesion. compared with traditional algorithms several deep learning methods can improve the segmentation; however due to blurred boundaries and complex gradients of medical images the segmentation remains unsatisfactory. in addition the existing datasets used by cervical cell nucleus segmentation research are lacking in terms of both quantity and diversity so methods based on those datasets cannot effectively cope with challenging cases. this paper releases a new cervical cell dataset and proposes a network named binary tree-like network with two-path fusion attention feature bttfa . the simplified diagram of bttfa is similar to a binary tree structure and combines resnext's last four layers of information by integrating adjacent pairs of layers each time; therefore the information of multilayers can be fully integrated and the information lost by the pooling layers can be recovered. bttfa also applies a two-path fusion attention to selectively utilize information close to the root nodes thereby taking full advantage of low-level detail and high-level semantic information and selectively emphasizing important features while suppressing less useful ones. meanwhile at some nodes of the binary tree-like network focal loss is imposed to calculate the loss between the ground truth and the feature map during the training process. experiments demonstrate that bttfa performs better than the existing technology on our dataset and another public dataset.   \n",
       "33766                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                prediction of inter-fractional radiotherapy dose plans with domain translation in spatiotemporal embeddings. external beam radiation therapy fractions have become extremely complex and tedious procedures to plan due to stringent requirements of delivering the highest radiation dose to the tumor while maximally avoiding organs at risk. however due to anatomic and/or biological changes between fractions dose re-optimization may be needed. re-optimization is a time-consuming task which is typically triggered based on subjective visual assessment by an experienced physician. to address limitations in this process we introduce a predictive framework which learns the evolution of tumor anatomy as well as inter-fractional dose delivery variations for head and neck cancers. first joint low-dimensional discriminant embeddings maximizing the separation between responsive and non-responsive groups to external beam radiotherapy plans are constructed from deep neural networks in order to capture patient-specific dose modulations with respect to anatomical variations. then latent representations are fed to a domain-level adversarial network to translate observed anatomical changes into dosimetric variations which aims to enforce local semantic consistency in the overall translation. dose distribution trajectories are represented in a group-average piecewise-geodesic setting to handle anatomical variations during therapy using a quadratic optimization to perform curve regression. at test time an annotated baseline ct is projected onto the latent space and translated to dose domain from which a spatiotemporal regression model is constructed using parallel transport trajectories defined from closest samples. this allows to predict dosimetry changes during the course of treatment. the model was trained on 337 cases and tested on 50 separate patients using sequential ct and associated dosimetry data with the probabilistic framework yielding a dice score of 92% and an overall dose difference of 1.2 gy in organs at risk and tumor volume over the course of multi-day treatment course with a 5% reduction in delivered fraction segments.   \n",
       "14150                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            machine learning-based decision model to distinguish between covid-19 and influenza: a retrospective two-centered diagnostic study. considering the current situation of the novel coronavirus disease covid-19 epidemic control it is highly likely that covid-19 and influenza may coincide during the approaching winter season. however there is no available tool that can rapidly and precisely distinguish between these two diseases in the absence of laboratory evidence of specific pathogens.   \n",
       "140094                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        spiculation-preserving polygonal modeling of contours of breast tumors. malignant breast tumors typically appear in mammograms with rough spiculated or microlobulated contours whereas most benign masses have smooth round oval or macrolobulated contours. several studies have shown that shape factors that incorporate differences as above can provide high accuracies in distinguishing between malignant tumors and benign masses based upon their contours only. however global measures of roughness such as compactness are less effective than specially designed features based upon spicularity and concavity. we propose a method to derive polygonal models of contours that preserve spicules and details of diagnostic importance. we show that an index of spiculation derived from the turning functions of the polygonal models obtained by the proposed method yields better classification accuracy than a similar measure derived using a previously published method. the methods were tested with a set of 111 contours of 65 benign masses and 46 malignant tumors. a high classification accuracy of 0.93 in terms of the area under the receiver operating characteristics curve was obtained.   \n",
       "30848                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    deep learning for risk prediction in patients with nasopharyngeal carcinoma using multi-parametric mris. magnetic resonance images mri is the main diagnostic tool for risk stratification and treatment decision in nasopharyngeal carcinoma npc . however the holistic feature information of multi-parametric mris has not been fully exploited by clinicians to accurately evaluate patients.   \n",
       "28475                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       automatic deep learning-based colorectal adenoma detection system and its similarities with pathologists. the microscopic evaluation of slides has been gradually moving towards all digital in recent years leading to the possibility for computer-aided diagnosis. it is worthwhile to know the similarities between deep learning models and pathologists before we put them into practical scenarios. the simple criteria of colorectal adenoma diagnosis make it to be a perfect testbed for this study.   \n",
       "19327                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  predicting the development of surgery-related pressure injury using a machine learning algorithm model. surgery-related pressure injury srpi is a serious problem in patients who undergo cardiovascular surgery. identifying patients at a high risk of srpi is important for clinicians to recognize and prevent it expeditiously. machine learning ml has been widely used in the field of healthcare and is well suited to predictive analysis.   \n",
       "58269                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              a new diagnostic approach for the identification of patients with neurodegenerative cognitive complaints. neurodegenerative diseases causing dementia are known to affect a person's speech and language. part of the expert assessment in memory clinics therefore routinely focuses on detecting such features. the current outpatient procedures examining patients' verbal and interactional abilities mainly focus on verbal recall word fluency and comprehension. by capturing neurodegeneration-associated characteristics in a person's voice the incorporation of novel methods based on the automatic analysis of speech signals may give us more information about a person's ability to interact which could contribute to the diagnostic process. in this proof-of-principle study we demonstrate that purely acoustic features extracted from recordings of patients' answers to a neurologist's questions in a specialist memory clinic can support the initial distinction between patients presenting with cognitive concerns attributable to progressive neurodegenerative disorders nd or functional memory disorder fmd i.e. subjective memory concerns unassociated with objective cognitive deficits or a risk of progression . the study involved 15 fmd and 15 nd patients where a total of 51 acoustic features were extracted from the recordings. feature selection was used to identify the most discriminating features which were then used to train five different machine learning classifiers to differentiate between the fmd/nd classes achieving a mean classification accuracy of 96.2%. the discriminative power of purely acoustic approaches could be integrated into diagnostic pathways for patients presenting with memory concerns and are computationally less demanding than methods focusing on linguistic elements of speech and language that require automatic speech recognition and understanding.   \n",
       "79418                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              functional brain dynamic analysis of adhd and control children using nonlinear dynamical features of eeg signals. attention deficit hyperactivity disorder is a neurodevelopmental condition associated with varying levels of hyperactivity inattention and impulsivity. this study investigates brain function in children with attention deficit hyperactivity disorder using measures of nonlinear dynamics in eeg signals during rest. during eyes-closed resting 19 channel eeg signals were recorded from 12 adhd and 12 normal age-matched children. we used the multifractal singularity spectrum the largest lyapunov exponent and approximate entropy to quantify the chaotic nonlinear dynamics of these eeg signals. as confirmed by wilcoxon rank sum test largest lyapunov exponent over left frontal-central cortex exhibited a significant difference between adhd and the age-matched control groups. further mean approximate entropy was significantly lower in adhd subjects in prefrontal cortex. the singularity spectrum was also considerably altered in adhd compared to control children. evaluation of these features was performed by two classifiers: a support vector machine and a radial basis function neural network. for better comparison subject classification based on frequency band power was assessed using the same types of classifiers. nonlinear features provided better discrimination between adhd and control than band power features. under four-fold cross validation testing support vector machine gave 83.33% accurate classification results.   \n",
       "113272                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         automatic generation of case-detection algorithms to identify children with asthma from large electronic health record databases. most electronic health record databases contain unstructured free-text narratives which cannot be easily analyzed. case-detection algorithms are usually created manually and often rely only on using coded information such as international classification of diseases version 9 codes. we applied a machine-learning approach to generate and evaluate an automated case-detection algorithm that uses both free-text and coded information to identify asthma cases.   \n",
       "94548                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          model comparison for breast cancer prognosis based on clinical data. we compared the performance of several prediction techniques for breast cancer prognosis based on au-roc performance area under roc for different prognosis periods. the analyzed dataset contained 1981 patients and from an initial 25 variables the 11 most common clinical predictors were retained. we compared eight models from a wide spectrum of predictive models namely; generalized linear model glm glm-net partial least square pls support vector machines svm random forests rf neural networks k-nearest neighbors k-nn and boosted trees. in order to compare these models paired t-test was applied on the model performance differences obtained from data resampling. random forests boosted trees partial least square and glmnet have superior overall performance however they are only slightly higher than the other models. the comparative analysis also allowed us to define a relative variable importance as the average of variable importance from the different models. two sets of variables are identified from this analysis. the first includes number of positive lymph nodes tumor size cancer grade and estrogen receptor all has an important influence on model predictability. the second set incudes variables related to histological parameters and treatment types. the short term vs long term contribution of the clinical variables are also analyzed from the comparative models. from the various cancer treatment plans the combination of chemo/radio therapy leads to the largest impact on cancer prognosis.    \n",
       "104960                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          a food recognition system for diabetic patients based on an optimized bag-of-features model. computer vision-based food recognition could be used to estimate a meal's carbohydrate content for diabetic patients. this study proposes a methodology for automatic food recognition based on the bag-of-features bof model. an extensive technical investigation was conducted for the identification and optimization of the best performing components involved in the bof architecture as well as the estimation of the corresponding parameters. for the design and evaluation of the prototype system a visual dataset with nearly 5000 food images was created and organized into 11 classes. the optimized system computes dense local features using the scale-invariant feature transform on the hsv color space builds a visual dictionary of 10000 visual words by using the hierarchical k-means clustering and finally classifies the food images with a linear support vector machine classifier. the system achieved classification accuracy of the order of 78% thus proving the feasibility of the proposed approach in a very challenging image dataset.   \n",
       "21600                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        accuracy of machine learning-based prediction of medication adherence in clinical research. medication non-adherence represents a significant barrier to treatment efficacy. remote real-time measurement of medication dosing can facilitate dynamic prediction of risk for medication non-adherence which in-turn allows for proactive clinical intervention to optimize health outcomes. we examine the accuracy of dynamic prediction of non-adherence using data from remote real-time measurements of medication dosing. participants across a large set of clinical trials n = 4182 were observed via a smartphone application that video records patients taking their prescribed medication. the patients' primary diagnosis demographics and prior indication of observed adherence/non-adherence were utilized to predict 1 adherence rates ¥ 80% across the clinical trial 2 adherence ¥ 80% for the subsequent week and 3 adherence the subsequent day using machine learning-based classification models. empirically observed adherence was demonstrated to be the strongest predictor of future adherence/non-adherence. collectively the classification models accurately predicted adherence across the trial auc = 0.83 the subsequent week auc = 0.87 and the subsequent day auc = 0.87 . real-time measurement of dosing can be utilized to dynamically predict medication adherence with high accuracy.   \n",
       "126118                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              automatic detection and segmentation of axillary lymph nodes. lymph node detection and measurement is a difficult and important part of cancer treatment. in this paper we present a robust and effective learning-based method for the automatic detection of solid lymph nodes from computed tomography data. the contributions of the paper are the following. first it presents a learning based approach to lymph node detection based on marginal space learning. second it presents an efficient mrf-based segmentation method for solid lymph nodes. third it presents two new sets of features one set self-aligning to the local gradients and another set based on the segmentation result. an extensive evaluation on 101 volumes containing 362 lymph nodes shows that this method obtains a 82.3% detection rate at 1 false positive per volume with an average running time of 5-20 seconds per volume.   \n",
       "84388                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            defining a multimodal signature of remote sports concussions. sports-related concussions lead to persistent anomalies of the brain structure and function that interact with the effects of normal ageing. although post-mortem investigations have proposed a bio-signature of remote concussions there is still no clear in vivo signature. in the current study we characterized white matter integrity in retired athletes with a history of remote concussions by conducting a full-brain diffusion-based connectivity analysis. next we combined mri diffusion markers with mr spectroscopic mri volumetric neurobehavioral and genetic markers to identify a multidimensional in vivo signature of remote concussions. machine learning classifiers trained to detect remote concussions using this signature achieved detection accuracies up to 90% sensitivity: 93% specificity: 87% . these automated classifiers identified white matter integrity as the hallmark of remote concussions and could provide following further validation a preliminary unbiased detection tool to help medical and legal experts rule out concussion history in patients presenting or complaining about late-life abnormal cognitive decline.   \n",
       "100344                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                multi-scale textural feature extraction and particle swarm optimization based model selection for false positive reduction in mammography. the high number of false positives and the resulting number of avoidable breast biopsies are the major problems faced by current mammography computer aided detection cad systems. false positive reduction is not only a requirement for mass but also for calcification cad systems which are currently deployed for clinical use. this paper tackles two problems related to reducing the number of false positives in the detection of all lesions and masses respectively. firstly textural patterns of breast tissue have been analyzed using several multi-scale textural descriptors based on wavelet and gray level co-occurrence matrix. the second problem addressed in this paper is the parameter selection and performance optimization. for this we adopt a model selection procedure based on particle swarm optimization pso for selecting the most discriminative textural features and for strengthening the generalization capacity of the supervised learning stage based on a support vector machine svm classifier. for evaluating the proposed methods two sets of suspicious mammogram regions have been used. the first one obtained from digital database for screening mammography ddsm contains 1494 regions 1000 normal and 494 abnormal samples . the second set of suspicious regions was obtained from database of mammographic image analysis society mini-mias and contains 315 207 normal and 108 abnormal samples. results from both datasets demonstrate the efficiency of using pso based model selection for optimizing both classifier hyper-parameters and parameters respectively. furthermore the obtained results indicate the promising performance of the proposed textural features and more specifically those based on co-occurrence matrix of wavelet image representation technique.    \n",
       "94794                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            feature extraction using time-frequency analysis for monophonic-polyphonic wheeze discrimination. the aim of this study is monophonic-polyphonic wheeze episode discrimination rather than the conventional wheeze versus non-wheeze episode detection. we used two different methods for feature extraction to discriminate monophonic and polyphonic wheeze episodes. one of the methods is based on frequency analysis and the other is based on time analysis. frequency analysis based method uses ratios of quartile frequencies to exploit the difference in the power spectrum. time analysis based method uses mean crossing irregularity to exploit the difference in periodicity in the time domain. both methods are applied on the data before and after an image processing based preprocessing step. calculated features are used in classification both individually and in combinations. support vector machine k-nearest neighbor and naive bayesian classifiers are adopted in leave-one-out scheme. a total of 121 monophonic and 110 polyphonic wheeze episodes are used in the experiments where the best classification performances are 71.45% for time domain based features 68.43% for frequency domain based features and 75.78% for a combination of selected best features.    \n",
       "13819                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               mass image synthesis in mammogram with contextual information based on gans. in medical imaging the scarcity of labeled lesion data has hindered the application of many deep learning algorithms. to overcome this problem the simulation of diverse lesions in medical images is proposed. however synthesizing labeled mass images in mammograms is still challenging due to the lack of consistent patterns in shape margin and contextual information. therefore we aim to generate various labeled medical images based on contextual information in mammograms.   \n",
       "139895                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     characterization of carotid atherosclerotic plaques using frequency-based texture analysis and bootstrap. texture analysis of b-mode ultrasound images of carotid atheromatous plaque can be valuable for the accurate diagnosis of atherosclerosis. in this paper two frequency-based texture analysis methods based on the fourier power spectrum and the wavelet transform were used to characterize atheromatous plaques. b-mode ultrasound images of 10 symptomatic and 9 asymptomatic plaques were interrogated. a total of 109 texture features were estimated for each plaque. the bootstrap method was used to compare the mean values of the texture features extracted from the two groups. after bootstrapping three features were found to be significantly different between the two types of plaques: the average value of the angular distribution corresponding to the wedge centered at 90 degrees the standard deviation at scale 1 derived from the horizontal detail image and the standard deviation at scale 2 derived from the horizontal detail image. it is concluded that frequency-based texture analysis in combination with a powerful statistical technique such as bootstrapping may provide valuable information about the plaque tissue type.   \n",
       "47655                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  application of preoperative artificial neural network based on blood biomarkers and clinicopathological parameters for predicting long-term survival of patients with gastric cancer. because of the powerful abilities of self-learning and handling complex biological information artificial neural network ann models have been widely applied to disease diagnosis imaging analysis and prognosis prediction. however there has been no trained preoperative ann preope-ann model to preoperatively predict the prognosis of patients with gastric cancer gc .   \n",
       "92009                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     diagnostic classification of adhd versus control: support vector machine classification using brief neuropsychological assessment. objective: common methods for clinical diagnosis include clinical interview behavioral questionnaires and neuropsychological assessment. these methods rely on clinical interpretation and have variable reliability sensitivity and specificity. the goal of this study was to evaluate the utility of machine learning in the prediction and classification of children with adhd-combined presentation adhd-c using brief neuropsychological measures d2 test of attention children with adhd-c and typically developing control children completed semi-structured clinical interviews and measures of attention/concentration and parents completed symptom severity questionnaires. method: we used a forward feature selection method to identify the most informative neuropsychological features for support vector machine svm classification and a decision tree model to derive a rule-based model. results: the svm model yielded excellent classification accuracy 100% of individual children with and without adhd 1.0 . decision tree algorithms identified individuals with and without adhd-c with 100% sensitivity and specificity. conclusion:this study observed highly accurate statistical diagnostic classification at the individual level in a sample of children with adhd-c. the findings suggest data-driven behavioral algorithms based on brief neuropsychological data may present an efficient and accurate diagnostic tool for clinicians.   \n",
       "15301                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              detection of lung cancer on computed tomography using artificial intelligence applications developed by deep learning methods and the contribution of deep learning to the classification of lung carcinoma. in every year lung cancer is an important cause of deaths in the world. early detection of lung cancer is important for treatment and non-invasive rapid methods are needed for diagnosis.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                num_plus  \\\n",
       "index                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "134590                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "121837                                                                                                                                                                                                                                                                                                                                                                                                                       [11 ms patients  , 256    ]   \n",
       "89006                                                                                                                                                                                                           [2 new measures preparation , 5 feature families graph shape, 19.7 percent to  , 48.6 percent of comparisons while, 4.2 percent to  , 4.6 percent   , 34 slides on  , 3 scanners demonstrated that haralick, 62 percent of comparisons ]   \n",
       "8982                                                                                                                                                                                                                                                                                                    [4 ss gene expression profile, 2 biomarkers sell l , 44 from   , 101 differentially expressed genes , 0.992 and verification set auc, 0.917    ]   \n",
       "14701                                                                                                                                                                                                                                                                                                                                                                                                                                 [1 pd   , 1 pd   ]   \n",
       "20454                                                                           [3927 covid   , 6 independent centers comprising , 33 different hospitals  , 3 validation cohorts  , 3062 patients has an observed, 26.84 percent   , 93 percent elevated levels of, 130 mg   , 18 mg   , 1.2 mg   , 0.90    , 95 percent ci  , 0.87    , 0.92    , 95 percent ci  , 0.88    , 0.87    , 95 percent ci  , 0.84    , 0.81    , 95 percent ci  , 0.76    ]   \n",
       "94867                                                                                                                                                                                                                                                                                                                                     [36 machine   , 6 amputees and  , 40 intact subjects performing , 40 movements   , 2 groups of amputees while]   \n",
       "39213                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "82669                                                                                                                                                                                                                                                                                                                                                               [3 d convolutions  , 3 visualization methods for the, 8 gradings and also visualize]   \n",
       "30146                                                                                                                                                                                                                                                                                                                                                                                                                                       [3 oct en  ]   \n",
       "72715                                                                                                                                                                                                                                                                                                                                                                                                         [2 different perceptual experiments which]   \n",
       "122198                                                                                                                                                                                                                                                                                                                                            [7 different areas within the, 2001    , 3 main children  , 3 different ann models were, 0    , 5    ]   \n",
       "24232                                                                                                                                                                                                                                                                                                                                                                                                              [90.74 percent accuracy in detecting]   \n",
       "60238                                                                                                                                                                                                                                                                                          [18 cancer types the driver, 36 percent of the patients, 92 percent accuracy with similar, 50 percentage points at , 20 percent fdr  , 6 major cancers  ]   \n",
       "123814                                                                                                                                                                                                                                                                                 [400 and   , 18 patients were used for, 532 patients for testing the, 95.8 percent and with image, 95.2 percent   , 87.9 percent and with image, 88.0 percent   ]   \n",
       "61636                                                                                                                                                                                                                                                                                                                                                                              [94.85    , 76.54    , 98.11 and   , 99.13 percent is obtained using]   \n",
       "29550                                                                                                                 [14 patients of head and, 38 enlarged lymph nodes and, 39 patients with head and, 39 enlarged lymph nodes confirmed, 10 days before biopsy or, 54 and testing set n, 23 in a ratio of, 7    , 7 features were screened out, 2 groups for all the, 0.759 to   , 0.915    , 0.970 in the training group, 0.977 in the testing group]   \n",
       "25257                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "56291                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "31541                                                                                                                                                             [4 layers of convolutional neural, 2 dense layers  , 3 realizing a cost , 110    , 4.33    , 0.29    , 0.5 to   , 100 hz with the noise, 2.2    , 374 subjects administrated by inhalational, 0.048 and   , 0.05 respectively   , 3 estimates the eegmac within, 20 ms which is about]   \n",
       "81580                                                                                                                                                                                                                                                                                                                   [2 groups of healthy volunteers, 2 different attentional tasks , 2 ways   , 93.08 and   , 79.79 percent respectively which were]   \n",
       "94910                                                                                                                                                                                                                                                                                                                                                                                                            [18 f   , 0.87 for rcmrglu compared to]   \n",
       "42824                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "143020                                                                                                                                                                                                                                                                                                                                                                                      [78 percent for diseased and, 77 percent for healthy miners]   \n",
       "78636                                                                                                                                                                                                                                                                                          [186 cognitively unimpaired cu subects, 336 mild cognitive impairment mci, 158 late mci and , 178 early mci and , 146 ad patients from alzheimer, 10    ]   \n",
       "68375                                                                                                          [4 of every  , 5 reported diagnostic errors in, 18 senior subspecialized orthopedic surgeons, 135409 radiographs   , 80.8 percent   , 95 percent ci  , 76.7    , 91.5 percent   , 95 percent ci  , 89.3    , 87.5 percent   , 95 ci   , 85.3    , 93.9 percent   , 95 percent ci  , 92.9    , 47.0 percent   , 95 percent ci  , 37.4    ]   \n",
       "11991                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "14404                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "54623                                                                                                                                                                                                                                                                                                                                                                                                                               [4 patient groups  ]   \n",
       "16619                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "29905                                                                                                                                                                                                                                                                                                                                                                                                                            [95 percent accuracy  ]   \n",
       "44932                                                                                                                                                                                                                                                                                                   [4 machine learning classifiers are, 2 subjects   , 97.5 percent while using a, 96.5 percent while using , 2 to   , 3 orders of magnitude fewer]   \n",
       "37654                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "143179                                                                [2 successive abnormal bone scans, 58 pairs of successive bone, 107    , 58 pairs based on the, 3 radiologists   , 7 steps i  , 16 image features for removing, 107 gold standard interval changes, 71 hot lesions uptake was, 36 cold lesions uptake was, 95.3 percent with  , 5.97 false positives per view, 83.2 percent with  , 6.02 respectively   , 2 images which also can]   \n",
       "56109                                                                                                                                                                                                                                         [2018 which highlighted that rts, 175 subjects of whom all, 17 years of instruction male, 4 groups   , 95 percent in detecting malingerers, 75 percent to  , 85 percent   , 55    , 70    , 90 percent   ]   \n",
       "35773                                                                                                                                                                  [355 asthma patients and , 1480 healthy individuals to ensure, 182 individuals based on the, 35 patients with asthma mts, 94.15 percent of patients , 97.20 percent of  , 147 healthy individuals were correctly, 7 routine blood biomarkers , 7 vital blood biomarker variables]   \n",
       "117887                                                                                                                         [5    , 18 years were eligible for, 6 h from the start, 24 h   , 411 patients   , 199 males and  , 212 females with spontaneous ich, 67.35 years   , 256    , 62.29 percent patients died during, 155    , 37.71 percent patients survived , 93.55 percent of patients compared, 79.32 percent of correct classification]   \n",
       "15168                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "48648                                                                                                                                                                                                                                                                                                                                                       [28 subjects   , 4 common entropy measures to, 0.9982 and auc of , 0.9926 based on a nested]   \n",
       "37039                                                                                                                                                                                                                                                                                                                                                                      [467 smoking events from , 40 participants under free , 78 percent in leave ]   \n",
       "104650                                                                                                                                                                                                                                                                                                                                                                              [2 cohorts each consisting of, 17 children with asds and, 17 age   ]   \n",
       "56998                                                                                                                                                                                                                                                                                                                                                                                                                             [17 mrnas and a mirna]   \n",
       "7057                                                               [22 patients with dermatomyositis dm, 14 with amyopathic dermatomyositis adm, 19 with polymyositis pm and, 19 with non  , 2 d manual segmentation , 93 original features as well, 93 local binary pattern lbp, 100 times   , 0.767 and   , 0.714 accuracy of  , 61.2 and   , 61.4 percent and macro , 61.9 and   , 59.8 percent in the lda, 0.646    , 0.692    , 71.5    , 65.8    ]   \n",
       "67625                     [1376756 patients from  , 2006 to   , 2015 were analyzed  , 292892 met inclusion criteria for, 38382 were classified as having, 1270 features reflecting demographics comorbidities, 175735 randomly selected patients were, 3 algorithms and from the, 95 percent confidence interval , 0.764    , 0.759    , 0.770 compared with  , 0.657    , 0.651    , 0.663 for the benchmark model, 2    , 2 antiepileptic drugs aeds ]   \n",
       "47003                                                                                                                                                                                                                                                                                                                                      [117 rcm mosaics collected by, 82 percent sensitivity and , 93 percent specificity  , 372 coregistered rcm  ]   \n",
       "71310   [28 normal and  , 29 tumor samples were obtained, 6806 normal and  , 3474 tumor images  , 5 modifications of the system, 2014 imagenet large scale visual, 2 experiments   , 82.50 percent   , 87.50 percent   , 87.50 percent   , 91.40 percent and  , 94.30 percent respectively  , 93.48 percent   , 0.4385    , 95.10 percent and  , 92.76 percent which equates to, 294 normal images out of, 309 and   , 667 tumor images out of, 719    ]   \n",
       "114768                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "37681                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "68343                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "47109                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "138233                                                                                                                                                                                                                                                                                                                                                                                                                       [2 stage learning process ]   \n",
       "48230                                                                                                                                                                                                                                                                                                                                                                                                                    [50000 patients that have been]   \n",
       "19333                                                                                                                                                                                                                 [25920 images and validation set, 16416 images   , 3 musculoskeletal radiologists reviewed , 88 knee mr studies in, 2 sessions the original proton, 0.01 was considered statistically significant, 0.05 for all other statistical]   \n",
       "91122                                                                                                                                                                                                                                                                                                                                      [140 chinese teenagers aged between, 11.0 and   , 19.0 years   , 2 elements was classified into, 5 grades   ]   \n",
       "50196                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "26004                                                                                                                                                                                                            [3500 patients enrolled in the, 3 treatment response subgroups among, 3 patient subgroups together with, 4 th subgroup patients who, 4 groups   , 1 the use of antibiotics, 2 longer duration of treatment, 3 oversight by a clinician]   \n",
       "1244                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "61442                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "139902                                                                                                                                                                                                                                                                                                                                                                                                                        [6 letters per minute was]   \n",
       "29323                                                                                                                                                                                                                                                                                                                                                              [3 blinded experts in terms, 0    , 1.14 mean absolute error mae, 0    , 0.78 mae   ]   \n",
       "13910                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "13923                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "4321                                                                                                                 [99 serum samples including , 38 cases from hyperthyroidism patients, 32 cases from hypothyroidism patients, 29 cases from control subjects, 3 we found differences in, 0.9999    , 5 neural network models the, 91 percent   , 84 percent   , 82 percent   , 75 percent and  , 71 percent respectively  , 3 conjectures for this ]   \n",
       "47901                                                                                                                                                                                                                                                                                                                                                                                                                                  [4 algorithms   ]   \n",
       "18809                                                                                                                                                                                                                                                                                                                                                               [2 d ir camera , 4 predefined poses and the, 8    , 12 healthy participants we find]   \n",
       "3483                                                                                                                                                                                                                                                                                   [3 methods   , 100 randomly chosen images indicated, 42 landmark points detection performed, 2 expert orthodontists showed consistency, 2.08    , 1.5 percent   ]   \n",
       "73716                                                                                                                                                                                                                                                                                                        [3377 subjects and  , 261 variables and built the, 58.33 percent to  , 90.48 percent and  , 83.33 percent to  , 90.44 percent in the model]   \n",
       "84733                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "152438                                                                                                                                                                                                                                                                                                                                                                                                                                     [2 groups   ]   \n",
       "44877                                                                                                                                                                 [2 cardiac rhythm features of, 23 patients   , 10 s   , 83461 fragments were collected , 49952 fragments of which are, 2 proposed features is , 97.3 percent which is shown, 95.7 percent or that with, 93.9 percent   , 97.4 percent and  , 97.2 percent respectively  , 10 s   ]   \n",
       "133419                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "65431                                                                                                                                                                                                                                                                                                                                                                                                 [14.8 followed by ageci , 8.9 and doha  , 7.5    ]   \n",
       "26463                                                                                                                                                                                                                                                                                               [4 different dynamic bayesian modeling, 98.0 percent can be achieved, 4 methods   , 87.7 percent for the classification, 7 different seizure types ]   \n",
       "10662                                                                                                                                                                                                                                                                                                                                                                    [84 glioma patients and , 63 healthy controls we showed, 92 percent accuracy  ]   \n",
       "77895                                                                                                                                                                                                                                                                                                                                                                                                               [2 clearly identifiable clusters in]   \n",
       "34682                                                                                                                                                                                                                                                                                                                                 [65.8    , 0.7982 precision   , 0.8152 recall   , 0.8064 f   , 0.8261 accuracy and  , 0.8988 auc using the neural]   \n",
       "19158                                                                                                                                                                                                                                                                                                                                                                                                                [3 d convolutional neural networks]   \n",
       "6865                                                                                                                                                                                                                                                                                                                                                                                  [100 hence applying survival analysis, 1000 is considered a major]   \n",
       "106469                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "126748                                                                                                                                                                                                                                                                                                                                                                                              [92 percent of the true, 5 percent of the encircled]   \n",
       "136647                                                                                                                                                                                               [2 types of machine learning, 125 individuals   , 74 cases and  , 51 cases respectively  , 89.7 percent specificity of , 54.5 percent and accuracy of, 74.5 percent while the dk, 86.2 percent   , 72.7 percent and  , 80.4 percent respectively  ]   \n",
       "92278                                                                                                                                                                                                                                                                                                                     [2 different experiments  , 104 subject dataset  , 90 percent and that the, 4 neuroradiologists on a dataset, 128 subjects   ]   \n",
       "40051                                                                                                                                                                                                                                                                                                                    [4    , 16 european partners in the, 2 imaging biobanks and , 3 prominent european paediatric oncology, 2 paediatric cancers  ]   \n",
       "26404                                                                                                                                                                                                                                                                                                                                                                                              [3 dt of coronary arteries, 96.04 percent accuracy  ]   \n",
       "49833                                                                                                                                                                                                                                                                                                                                      [50 men and women this, 6 statistical learning methods for, 2 nd   , 3 rd   , 85    , 59    , 87    , 82    ]   \n",
       "79244                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "8453                                                                                                                                                                                                                                                                                                                                                                                                                                          [0.89    ]   \n",
       "618                                                                                                                                                                                                                                                                                                                                                  [2 optimal survival subtypes in, 2 liver cancer c , 0.73    , 5 breast cancer datasets c, 0.68    ]   \n",
       "76598                                                                                                                                                                                                                                                                                                                                                                                                     [3 d point clouds , 3 d point clouds captured]   \n",
       "64981                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "47354                                                                                                                                                                                                                                                 [48 ms patients without symptoms, 48 healthy control subjects were, 3 variables with the greatest, 0.81 sensitivity   , 0.89 specificity   , 0.92 accuracy   , 0.91 and aucclassifier  , 0.97    ]   \n",
       "98850                                                                                                                                                                                                                                                                                                                                                           [30 features and reduced one, 5    , 20 percent   , 95 percent confidential interval ci]   \n",
       "59288                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "3069                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "33698                                                                                                                                                                                                                                                                                                                                    [0.3 is   , 27 percent without the annotation, 83 percent if manually removed, 90 percent using our inpainting]   \n",
       "31508                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "32519                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "14576                                                                                                                                                                                                                                                                      [2019 covid   , 94.80 percent accuracy  , 92.79 percent recall  , 92.97 percent precision and , 94.93 percent auc for distinguishing, 3 classical classification algorithms ]   \n",
       "14483                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "78319                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "11310                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "55642                                                                                                                                                                                                                                                                                                                       [6 flexible wearable sensors in, 20 individuals with pd over, 1 day and repeated , 2 weeks later  , 13 common tasks such as]   \n",
       "5038                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "115260                                                                                                                                                                                                                                                                                                              [62 cases of first , 62 age gender and educationally, 1.5 t mri scanning at, 1 year   , 73.4 percent was observed for, 1    , 1    ]   \n",
       "122817                                                                                                                                                                                                                                                                                                                                                                                               [2 analysis methods  , 95 percent estimated with a]   \n",
       "145427                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "20564                                                                                                                                                                                                                                                                                                                            [10 hub genes significantly associated, 3 of these hub genes, 328 samples of idh , 2 datasets   , 2 idh   , 31 gene   ]   \n",
       "31644                                                                                                                                                                                                                                                                                                                                                                                                                                   [1 month post  ]   \n",
       "107242                                                                                                                                                                                                                                                                                                                              [2 groups subjected to analysis, 614 normal and abnormal cardiac, 97.0 percent   , 85.1 percent   , 92.7 percent   ]   \n",
       "158091                                                                                                                                                                                                                                                                                                                                                                                                                              [2 different soms  ]   \n",
       "112982                                                                                                                                                                                                                                                                                                                         [2 classes are extracted using, 2 different databases  , 96    , 196    , 96.9 percent and  , 91.3 percent for spect and]   \n",
       "19683                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "127417                                                                                                                                                                                                                                                                                                                                                                                                         [2 different machine learning techniques]   \n",
       "11431                                                                                                                                                                                                                                                                                                                                       [2 databases of sensor , 1 achieving very high classification, 2 saving tremendous time for, 3 being cost  ]   \n",
       "102714                                                                                                                                                                                                                                                                                                                                                                                                                                      [0.9263    ]   \n",
       "29857                                                                                                                                                                                                                                                                                         [4575 x   , 1525 images of covid , 99.4 percent auc of , 99.9 percent specificity of , 99.2 percent sensitivity of , 99.3 percent and f , 98.9 percent   ]   \n",
       "60729                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "100709                                                                                                                                                                                                                                                                                                                                                                                                                                                []   \n",
       "13855                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "106809                                                                                                                                                                                                                                                                                                                                                                                                                             [6    , 3    , 6    ]   \n",
       "126596                                                                                                                                                                                                                                                                                                                                                                                                      [2    , .927 with the gait deviation, 7    ]   \n",
       "38305                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "39678                                                                                                                                                                                                                                                                                                                                                                                      [10 percent important edges we, 6 different severity scores ]   \n",
       "13011                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "6156                                                                                                                                                                                                                                                                                                                                                                                                                                                  []   \n",
       "16556                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "99096                                                                                                                                                                                                                                                                                                                                                                                                 [94.4    , 97.1    , 95.3    , 96.9    , 99.7    ]   \n",
       "47915                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "59936                                                                                                                                                                                                                                                                                                                                                                                                                       [4 layers of information by]   \n",
       "33766                                                                                                                                                                                                                                                                                                 [337 cases and tested on, 50 separate patients using sequential, 92 percent and an overall, 1.2 gy in organs at, 5 percent reduction in delivered]   \n",
       "14150                                                                                                                                                                                                                                                                                                                                                                                                                        [2 diseases in the absence]   \n",
       "140094                                                                                                                                                                                                                                                                                                                                                           [111 contours of  , 65 benign masses and , 46 malignant tumors  , 0.93 in terms of the]   \n",
       "30848                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "28475                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "19327                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "58269                                                                                                                                                                                                                                                                                                             [15 fmd and  , 15 nd patients where a, 51 acoustic features were extracted, 5 different machine learning classifiers, 96.2 percent   ]   \n",
       "79418                                                                                                                                                                                                                                                                                                                     [19 channel eeg signals were, 12 adhd and  , 12 normal age  , 2 classifiers   , 83.33 percent accurate classification results]   \n",
       "113272                                                                                                                                                                                                                                                                                                                                                                                                                                      [9 codes   ]   \n",
       "94548                                                                                                                                                                                                                                                                                                                 [1981 patients and from an, 25 variables the  , 11 most common clinical predictors, 8 models from a wide, 2 sets of variables are]   \n",
       "104960                                                                                                                                                                                                                                                                                                                                           [5000 food images was created, 11 classes   , 10000 visual words by using, 78 percent thus proving the]   \n",
       "21600                                                                                                                                                                                                                [4182 were observed via a, 1 adherence rates  , 80 percent across the clinical, 2 adherence   , 80 percent for the subsequent, 3 adherence the subsequent day, 0.83 the subsequent week auc, 0.87 and the subsequent day, 0.87    ]   \n",
       "126118                                                                                                                                                                                                                                                                                                [2 new sets of features, 101 volumes containing  , 362 lymph nodes shows that, 82.3 percent detection rate at, 1 false positive per volume, 5    ]   \n",
       "84388                                                                                                                                                                                                                                                                                                                                                                                [90 percent sensitivity  , 93 percent specificity  , 87 percent   ]   \n",
       "100344                                                                                                                                                                                                                                                                   [2 problems related to reducing, 2 sets of suspicious mammogram, 1494 regions   , 1000 normal and  , 494 abnormal samples  , 315    , 207 normal and  , 108 abnormal samples  ]   \n",
       "94794                                                                                                                                                                                                                                                    [2 different methods for feature, 121 monophonic and  , 110 polyphonic wheeze episodes are, 71.45 percent for time domain, 68.43 percent for frequency domain, 75.78 percent for a combination]   \n",
       "13819                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "139895                                                                                                                                                                [2 frequency   , 10 symptomatic and  , 9 asymptomatic plaques were interrogated, 109 texture features were estimated, 2 groups   , 3 features were found to, 2 types of plaques , 90 degrees the standard deviation, 1 derived from the horizontal, 2 derived from the horizontal]   \n",
       "47655                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "92009                                                                                                                                                                                                                                                                                                                                                             [100 percent of individual children, 1.0    , 100 percent sensitivity and specificity]   \n",
       "15301                                                                                                                                                                                                                                                                                                                                                                                                                                                 []   \n",
       "\n",
       "                                                                                                                                                                                                            num_minus  \\\n",
       "index                                                                                                                                                                                                                   \n",
       "134590                                                                                                                                                                                                             []   \n",
       "121837                                                                                                                                                                                 [set of 11, resolution of 256]   \n",
       "89006                                                                                                    [we present 2, found that 5, datasets in 19.7, variation were 4.2, the same 34, slides on 3, unstable in 62]   \n",
       "8982                                                                                                                                                               [we used 4, to screen 2, auc = 0.992, auc = 0.917]   \n",
       "14701                                                                                                                                                                                               [death protein 1]   \n",
       "20454                                [obtained for 3927, patients from 6, centers comprising 33, evaluated on 3, cohort of 3062, rate of 26.84, aucs of 0.90, aucs of 0.92, seville patients 0.87, patients and 0.81]   \n",
       "94867                                                                                                                                          [applied on 6, amputees and 40, subjects performing 40, between the 2]   \n",
       "39213                                                                                                                                                                                                              []   \n",
       "82669                                                                                                                                                                 [including using 3, we compare 3, across the 8]   \n",
       "30146                                                                                                                                                                                                      [use of 3]   \n",
       "72715                                                                                                                                                                                        [subjectively through 2]   \n",
       "122198                                                                                                                                                       [data from 7, the period 2001, of the 3, subgroups of 0]   \n",
       "24232                                                                                                                                                                                           [have achieved 90.74]   \n",
       "60238                                                                                                                                       [of distinguishing 18, so at 92, patients by 50, points at 20, site of 6]   \n",
       "123814                                                                                                                         [training and 532, image data 95.8, data alone 95.2, image data 87.9, data alone 88.0]   \n",
       "61636                                                                                                                                                                                           [validation of 94.85]   \n",
       "29550                                 [analysis of 14, total of 38, nodes and 39, total of 39, cect within 10, n = 54, n = 23, ratio of 7, between the 2, ranging from 0.759, performance was 0.970, group and 0.977]   \n",
       "25257                                                                                                                                                                                                              []   \n",
       "56291                                                                                                                                                                                                              []   \n",
       "31541                            [consists of 4, network and 2, raspberry pi 3, fabricated in 110, afe consumes 4.33, noise of 0.29, factor of 2.2, data from 374, errors of 0.048, raspberry pi 3, eegmac within 20]   \n",
       "81580                                                                                                                                        [is classifying 2, were doing 2, analyzed in 2, performances were 93.08]   \n",
       "94910                                                                                                                                                                                              [measures of 0.87]   \n",
       "42824                                                                                                                                                                                                              []   \n",
       "143020                                                                                                                                                                          [reliability was 78, diseased and 77]   \n",
       "78636                                                                                                                [subjects including 186, cu subects 336, subjects with 158, mci and 178, mci and 146, with a 10]   \n",
       "68375                                                  [upward of 4, of every 5, expertise of 18, them annotate 135409, sensitivity was 80.8, unaided and 91.5, specificity was 87.5, unaided and 93.9, rate of 47.0]   \n",
       "11991                                                                                                                                                                                                              []   \n",
       "14404                                                                                                                                                                                                              []   \n",
       "54623                                                                                                                                                                                                 [approach in 4]   \n",
       "16619                                                                                                                                                                                                              []   \n",
       "29905                                                                                                                                                                                                    [high as 95]   \n",
       "44932                                                                                                                           [this paper 4, the other 2, of accuracy 97.5, excellent accuracy 96.5, while using 2]   \n",
       "37654                                                                                                                                                                                                              []   \n",
       "143179         [changes between 2, carried out 58, we determined 107, among the 58, consensus of 3, consisted of 7, use of 16, changes included 71, scan and 36, methods were 95.3, view and 83.2, changes between 2]   \n",
       "56109                                                              [composed of 175, at least 17, assigned to 4, accuracies around 95, ranging from 75, pressure accuracies 55, useful accuracies 70, higher than 90]   \n",
       "35773                                                                      [data from 355, patients and 1480, system on 182, out of 35, correctly classified 94.15, in addition 97.20, system isolated 7, based on 7]   \n",
       "117887                 [ich over 5, older than 18, presented within 6, tomography within 24, have analyzed 411, males and 212, age of 67.35, from them 256, treatment and 155, outcome in 93.55, compared with 79.32]   \n",
       "15168                                                                                                                                                                                                              []   \n",
       "48648                                                                                                                                               [state from 28, and employs 4, accuracy of 0.9982, auc of 0.9926]   \n",
       "37039                                                                                                                                                                        [dataset containing 467, events from 40]   \n",
       "104650                                                                                                                                                                   [data from 2, consisting of 17, asds and 17]   \n",
       "56998                                                                                                                                                                                                              []   \n",
       "7057                             [dermatomyositis dm 14, dermatomyositis adm 19, pm and 19, manual segmentation 93, well as 93, values of 0.767, accuracy of 61.2, recall of 61.9, values of 0.646, accuracy of 71.5]   \n",
       "67625   [claims from 1376756, patients from 2006, epilepsy and 38382, characterized using 1270, data from 175735, to train 3, characteristic curve 95, compared with 0.657, resistance approximately 2, had failed 2]   \n",
       "47003                                                                                                                                                   [model on 117, areas with 82, sensitivity and 93, set of 372]   \n",
       "71310      [images of 28, normal and 29, cropped into 6806, normal and 3474, we developed 5, in the 2014, them in 2, accuracies of 82.50, respectively were 93.48, correctly classifying 294, out of 309, out of 719]   \n",
       "114768                                                                                                                                                                                                             []   \n",
       "37681                                                                                                                                                                                                              []   \n",
       "68343                                                                                                                                                                                                              []   \n",
       "47109                                                                                                                                                                                                              []   \n",
       "138233                                                                                                                                                                                                       [in a 2]   \n",
       "48230                                                                                                                                                                                                 [of over 50000]   \n",
       "19333                                                                                                            [set of 25920, set of 16416, radiologists reviewed 88, studies in 2, less than 0.01, less than 0.05]   \n",
       "91122                                                                                                                                            [collected from 140, aged between 11.0, of the 2, classified into 5]   \n",
       "50196                                                                                                                                                                                                              []   \n",
       "26004                                                                                 [of over 3500, to identify 3, across these 3, with a 4, of the 4, associated with 1, alternative treatments 2, treatment and 3]   \n",
       "1244                                                                                                                                                                                                               []   \n",
       "61442                                                                                                                                                                                                              []   \n",
       "139902                                                                                                                                                                                                   [speed of 6]   \n",
       "29323                                                                                                                                                            [retrospectively by 3, score range 0, score range 0]   \n",
       "13910                                                                                                                                                                                                              []   \n",
       "13923                                                                                                                                                                                                              []   \n",
       "4321                                                                 [we collected 99, samples including 38, hyperthyroidism patients 32, patients and 29, of the 3, ratio of 0.9999, accuracy was 91, put forward 3]   \n",
       "47901                                                                                                                                                                                                 [we compared 4]   \n",
       "18809                                                                                                                                               [a single 2, successfully detect 4, state during 8, cohort of 12]   \n",
       "3483                                                                                                      [evaluated by 3, orthodontists for 100, tracing with 42, images by 2, difference of 2.08, increased by 1.5]   \n",
       "73716                                                                                                                                                            [ii data 3377, subjects and 261, rates ranged 58.33]   \n",
       "84733                                                                                                                                                                                                              []   \n",
       "152438                                                                                                                                                                                                [between the 2]   \n",
       "44877                                            [and particularly 2, segmented into 10, total of 83461, were collected 49952, combining the 2, features is 97.3, frequency spectrum 93.9, level of 97.4, af with 10]   \n",
       "133419                                                                                                                                                                                                             []   \n",
       "65431                                                                                                                                                                                    [by ageci 8.9, and doha 7.5]   \n",
       "26463                                                                                                                                             [accuracy of 98.0, of the 4, accuracy of 87.7, classification of 7]   \n",
       "10662                                                                                                                                                          [samples from 84, patients and 63, algorithms with 92]   \n",
       "77895                                                                                                                                                                                                 [composed of 2]   \n",
       "34682                                                                                                                                                                [to auc 65.8, up to 0.7982, accuracy and 0.8988]   \n",
       "19158                                                                                                                                                                                             [hematomas using 3]   \n",
       "6865                                                                                                                                                                                          [up to 100, up to 1000]   \n",
       "106469                                                                                                                                                                                                             []   \n",
       "126748                                                                                                                                                                             [algorithm covers 92, less than 5]   \n",
       "136647                                                                                         [muscle of 125, set of 74, cases and 51, sensitivity of 89.7, specificity of 54.5, accuracy of 74.5, accuracy of 86.2]   \n",
       "92278                                                                                                                                      [we performed 2, on a 104, larger than 90, diagnosis of 4, dataset of 128]   \n",
       "40051                                                                                                                                    [is a 4, that has 16, paediatric oncology 2, biobanks and 3, validated on 2]   \n",
       "26404                                                                                                                                                               [dynamic reconstructions 3, alignment with 96.04]   \n",
       "49833                                                                                        [volumes from 50, study evaluated 6, svm iii 2, and vi 3, accuracy of 85, accuracy of 59, accuracy of 87, reduced at 82]   \n",
       "79244                                                                                                                                                                                                              []   \n",
       "8453                                                                                                                                                                                              [auc reaching 0.89]   \n",
       "618                                                                                                                                                                               [it identifies 2, exemplified by 2]   \n",
       "76598                                                                                                                                                                              [external biceps 3, muscle from 3]   \n",
       "64981                                                                                                                                                                                                              []   \n",
       "47354                                                                                         [neuritis and 48, auc the 3, mcc = 0.81, sensitivity = 0.89, specificity = 0.92, accuracy = 0.91, aucclassifier = 0.97]   \n",
       "98850                                                                                                                                         [data with 30, different validation 5, and partitioning 20, auc and 95]   \n",
       "59288                                                                                                                                                                                                              []   \n",
       "3069                                                                                                                                                                                                               []   \n",
       "33698                                                                                                                                                                          [iou = 0.3, map is 83, enhanced to 90]   \n",
       "31508                                                                                                                                                                                                              []   \n",
       "32519                                                                                                                                                                                                              []   \n",
       "14576                                                                                                                                                 [coronavirus disease 2019, precision and 94.93, methods with 3]   \n",
       "14483                                                                                                                                                                                                              []   \n",
       "78319                                                                                                                                                                                                              []   \n",
       "11310                                                                                                                                                                                                              []   \n",
       "55642                                                                                                                        [data using 6, sensors in 20, conducted on 1, and repeated 2, participants performed 13]   \n",
       "5038                                                                                                                                                                                                               []   \n",
       "115260                                                                                                                         [disorder and 62, controls underwent 1.5, modest da 73.4, to predict 1, predict the 1]   \n",
       "122817                                                                                                                                                                                  [processed using 2, up to 95]   \n",
       "145427                                                                                                                                                                                                             []   \n",
       "20564                                                                                                                                                              [first step 10, separated into 2, we identified 2]   \n",
       "31644                                                                                                                                                                                             [brief interview 1]   \n",
       "107242                                                                                                                                            [are the 2, total of 614, to be 97.0, the tgnn 85.1, tdnn and 92.7]   \n",
       "158091                                                                                                                                                                                                [consists of 2]   \n",
       "112982                                                                                                                                                                [of the 2, applied to 2, and a 196, up to 96.9]   \n",
       "19683                                                                                                                                                                                                              []   \n",
       "127417                                                                                                                                                                                                   [will use 2]   \n",
       "11431                                                                                                                                   [obtained from 2, potential for 1, classification accuracy 2, learning and 3]   \n",
       "102714                                                                                                                                                                                                   [r = 0.9263]   \n",
       "29857                                                                                            [collection of 4575, images including 1525, accuracy of 99.4, auc of 99.9, specificity of 99.2, sensitivity of 99.3]   \n",
       "60729                                                                                                                                                                                                              []   \n",
       "100709                                                                                                                                                                                                             []   \n",
       "13855                                                                                                                                                                                                              []   \n",
       "106809                                                                                                                                                                           [where the 6, points in 3, in the 6]   \n",
       "126596                                                                                                                                                                             [correlation r 2, walking scale 7]   \n",
       "38305                                                                                                                                                                                                              []   \n",
       "39678                                                                                                                                                                                        [the top 10, error on 6]   \n",
       "13011                                                                                                                                                                                                              []   \n",
       "6156                                                                                                                                                                                                               []   \n",
       "16556                                                                                                                                                                                                              []   \n",
       "99096                                                                                                                                                        [downswing were 94.4, accuracy was 96.9, swing and 99.7]   \n",
       "47915                                                                                                                                                                                                              []   \n",
       "59936                                                                                                                                                                                                              []   \n",
       "33766                                                                                                                                        [trained on 337, tested on 50, score of 92, difference of 1.2, with a 5]   \n",
       "14150                                                                                                                                                                                               [between these 2]   \n",
       "140094                                                                                                                                                  [set of 111, contours of 65, masses and 46, accuracy of 0.93]   \n",
       "30848                                                                                                                                                                                                              []   \n",
       "28475                                                                                                                                                                                                              []   \n",
       "19327                                                                                                                                                                                                              []   \n",
       "58269                                                                                                                                      [study involved 15, fmd and 15, total of 51, to train 5, accuracy of 96.2]   \n",
       "79418                                                                                                                                             [recorded from 12, adhd and 12, performed by 2, machine gave 83.33]   \n",
       "113272                                                                                                                                                                                           [diseases version 9]   \n",
       "94548                                                                                                                                        [dataset contained 1981, an initial 25, variables the 11, we compared 8]   \n",
       "104960                                                                                                                                        [with nearly 5000, organized into 11, dictionary of 10000, order of 78]   \n",
       "21600                                                                                                                      [n = 4182, to predict 1, clinical trial 2, week and 3, auc = 0.83, auc = 0.87, auc = 0.87]   \n",
       "126118                                                                                                               [it presents 2, evaluation on 101, volumes containing 362, obtains a 82.3, rate at 1, time of 5]   \n",
       "84388                                                                                                                                                                                                      [up to 90]   \n",
       "100344                                                                                                    [paper tackles 2, proposed methods 2, ddsm contains 1494, normal and 494, and contains 315, normal and 108]   \n",
       "94794                                                                                                 [we used 2, total of 121, monophonic and 110, performances are 71.45, based features 68.43, features and 75.78]   \n",
       "13819                                                                                                                                                                                                              []   \n",
       "139895                                                        [this paper 2, images of 10, symptomatic and 9, total of 109, from the 2, after bootstrapping 3, between the 2, centered at 90, at scale 1, at scale 2]   \n",
       "47655                                                                                                                                                                                                              []   \n",
       "92009                                                                                                                                                                 [classification accuracy 100, without adhd 1.0]   \n",
       "15301                                                                                                                                                                                                              []   \n",
       "\n",
       "                                                                                                                                                                                                                         patient_terms  \\\n",
       "index                                                                                                                                                                                                                                    \n",
       "134590                                                                                                                                                                                                                              []   \n",
       "121837                                                                                                                                                                                                              [11 ms patients  ]   \n",
       "89006                                                                                                                                                                                                                               []   \n",
       "8982                                                                                                                                                                                                                                []   \n",
       "14701                                                                                                                                                                                                                               []   \n",
       "20454                                                                                                                                                                                                  [3062 patients has an observed]   \n",
       "94867                                                                                                                                                                                                 [40 intact subjects performing ]   \n",
       "39213                                                                                                                                                                                                                               []   \n",
       "82669                                                                                                                                                                                                                               []   \n",
       "30146                                                                                                                                                                                                                               []   \n",
       "72715                                                                                                                                                                                                                               []   \n",
       "122198                                                                                                                                                                                                             [3 main children  ]   \n",
       "24232                                                                                                                                                                                                                               []   \n",
       "60238                                                                                                                                                                                                                               []   \n",
       "123814                                                                                                                                                                       [18 patients were used for, 532 patients for testing the]   \n",
       "61636                                                                                                                                                                                                                               []   \n",
       "29550                                                                                                                                                                             [14 patients of head and, 39 patients with head and]   \n",
       "25257                                                                                                                                                                                                                               []   \n",
       "56291                                                                                                                                                                                                                               []   \n",
       "31541                                                                                                                                                                                     [374 subjects administrated by inhalational]   \n",
       "81580                                                                                                                                                                                                 [2 groups of healthy volunteers]   \n",
       "94910                                                                                                                                                                                                                               []   \n",
       "42824                                                                                                                                                                                                                               []   \n",
       "143020                                                                                                                                                                                                                              []   \n",
       "78636                                                                                                                                                                                                 [146 ad patients from alzheimer]   \n",
       "68375                                                                                                                                                                                                                               []   \n",
       "11991                                                                                                                                                                                                                               []   \n",
       "14404                                                                                                                                                                                                                               []   \n",
       "54623                                                                                                                                                                                                             [4 patient groups  ]   \n",
       "16619                                                                                                                                                                                                                               []   \n",
       "29905                                                                                                                                                                                                                               []   \n",
       "44932                                                                                                                                                                                                                  [2 subjects   ]   \n",
       "37654                                                                                                                                                                                                                               []   \n",
       "143179                                                                                                                                                                                                                              []   \n",
       "56109                                                                                                                                                                         [175 subjects of whom all, 17 years of instruction male]   \n",
       "35773                                                                [355 asthma patients and , 1480 healthy individuals to ensure, 182 individuals based on the, 35 patients with asthma mts, 147 healthy individuals were correctly]   \n",
       "117887                                                                                                                                                            [411 patients   , 199 males and  , 212 females with spontaneous ich]   \n",
       "15168                                                                                                                                                                                                                               []   \n",
       "48648                                                                                                                                                                                                                 [28 subjects   ]   \n",
       "37039                                                                                                                                                                                                    [40 participants under free ]   \n",
       "104650                                                                                                                                                                                                     [17 children with asds and]   \n",
       "56998                                                                                                                                                                                                                               []   \n",
       "7057                                                                                                                                                                                             [22 patients with dermatomyositis dm]   \n",
       "67625                                                                                                                                                                [1376756 patients from  , 175735 randomly selected patients were]   \n",
       "47003                                                                                                                                                                                                                               []   \n",
       "71310                                                                                                                                                                                                                               []   \n",
       "114768                                                                                                                                                                                                                              []   \n",
       "37681                                                                                                                                                                                                                               []   \n",
       "68343                                                                                                                                                                                                                               []   \n",
       "47109                                                                                                                                                                                                                               []   \n",
       "138233                                                                                                                                                                                                                              []   \n",
       "48230                                                                                                                                                                                                  [50000 patients that have been]   \n",
       "19333                                                                                                                                                                                                                               []   \n",
       "91122                                                                                                                                                                                             [140 chinese teenagers aged between]   \n",
       "50196                                                                                                                                                                                                                               []   \n",
       "26004                                                                                                                                   [3500 patients enrolled in the, 3 patient subgroups together with, 4 th subgroup patients who]   \n",
       "1244                                                                                                                                                                                                                                []   \n",
       "61442                                                                                                                                                                                                                               []   \n",
       "139902                                                                                                                                                                                                                              []   \n",
       "29323                                                                                                                                                                                                                               []   \n",
       "13910                                                                                                                                                                                                                               []   \n",
       "13923                                                                                                                                                                                                                               []   \n",
       "4321    [38 cases from hyperthyroidism patients, 38 cases from hyperthyroidism patients, 32 cases from hypothyroidism patients, 32 cases from hypothyroidism patients, 29 cases from control subjects, 29 cases from control subjects]   \n",
       "47901                                                                                                                                                                                                                               []   \n",
       "18809                                                                                                                                                                                                [12 healthy participants we find]   \n",
       "3483                                                                                                                                                                                                                                []   \n",
       "73716                                                                                                                                                                                                            [3377 subjects and  ]   \n",
       "84733                                                                                                                                                                                                                               []   \n",
       "152438                                                                                                                                                                                                                              []   \n",
       "44877                                                                                                                                                                                                                 [23 patients   ]   \n",
       "133419                                                                                                                                                                                                                              []   \n",
       "65431                                                                                                                                                                                                                               []   \n",
       "26463                                                                                                                                                                                                                               []   \n",
       "10662                                                                                                                                                                                                        [84 glioma patients and ]   \n",
       "77895                                                                                                                                                                                                                               []   \n",
       "34682                                                                                                                                                                                                                               []   \n",
       "19158                                                                                                                                                                                                                               []   \n",
       "6865                                                                                                                                                                                                                                []   \n",
       "106469                                                                                                                                                                                                                              []   \n",
       "126748                                                                                                                                                                                                                              []   \n",
       "136647                                                                                                                                                                   [125 individuals   , 74 cases and  , 51 cases respectively  ]   \n",
       "92278                                                                                                                                                                                         [104 subject dataset  , 128 subjects   ]   \n",
       "40051                                                                                                                                                                                                                               []   \n",
       "26404                                                                                                                                                                                                                               []   \n",
       "49833                                                                                                                                                                                   [50 men and women this, 50 men and women this]   \n",
       "79244                                                                                                                                                                                                                               []   \n",
       "8453                                                                                                                                                                                                                                []   \n",
       "618                                                                                                                                                                                                                                 []   \n",
       "76598                                                                                                                                                                                                                               []   \n",
       "64981                                                                                                                                                                                                                               []   \n",
       "47354                                                                                                                                                              [48 ms patients without symptoms, 48 healthy control subjects were]   \n",
       "98850                                                                                                                                                                                                                               []   \n",
       "59288                                                                                                                                                                                                                               []   \n",
       "3069                                                                                                                                                                                                                                []   \n",
       "33698                                                                                                                                                                                                                               []   \n",
       "31508                                                                                                                                                                                                                               []   \n",
       "32519                                                                                                                                                                                                                               []   \n",
       "14576                                                                                                                                                                                                                               []   \n",
       "14483                                                                                                                                                                                                                               []   \n",
       "78319                                                                                                                                                                                                                               []   \n",
       "11310                                                                                                                                                                                                                               []   \n",
       "55642                                                                                                                                                                                                    [20 individuals with pd over]   \n",
       "5038                                                                                                                                                                                                                                []   \n",
       "115260                                                                                                                                                                                                            [62 cases of first ]   \n",
       "122817                                                                                                                                                                                                                              []   \n",
       "145427                                                                                                                                                                                                                              []   \n",
       "20564                                                                                                                                                                                                                               []   \n",
       "31644                                                                                                                                                                                                                               []   \n",
       "107242                                                                                                                                                                                                [2 groups subjected to analysis]   \n",
       "158091                                                                                                                                                                                                                              []   \n",
       "112982                                                                                                                                                                                                                              []   \n",
       "19683                                                                                                                                                                                                                               []   \n",
       "127417                                                                                                                                                                                                                              []   \n",
       "11431                                                                                                                                                                                                                               []   \n",
       "102714                                                                                                                                                                                                                              []   \n",
       "29857                                                                                                                                                                                                                               []   \n",
       "60729                                                                                                                                                                                                                               []   \n",
       "100709                                                                                                                                                                                                                              []   \n",
       "13855                                                                                                                                                                                                                               []   \n",
       "106809                                                                                                                                                                                                                              []   \n",
       "126596                                                                                                                                                                                                                              []   \n",
       "38305                                                                                                                                                                                                                               []   \n",
       "39678                                                                                                                                                                                                                               []   \n",
       "13011                                                                                                                                                                                                                               []   \n",
       "6156                                                                                                                                                                                                                                []   \n",
       "16556                                                                                                                                                                                                                               []   \n",
       "99096                                                                                                                                                                                                                               []   \n",
       "47915                                                                                                                                                                                                                               []   \n",
       "59936                                                                                                                                                                                                                               []   \n",
       "33766                                                                                                                                                                 [337 cases and tested on, 50 separate patients using sequential]   \n",
       "14150                                                                                                                                                                                                                               []   \n",
       "140094                                                                                                                                                                                                                              []   \n",
       "30848                                                                                                                                                                                                                               []   \n",
       "28475                                                                                                                                                                                                                               []   \n",
       "19327                                                                                                                                                                                                                               []   \n",
       "58269                                                                                                                                                                                                         [15 nd patients where a]   \n",
       "79418                                                                                                                                                                                                                               []   \n",
       "113272                                                                                                                                                                                                                              []   \n",
       "94548                                                                                                                                                                                                      [1981 patients and from an]   \n",
       "104960                                                                                                                                                                                                                              []   \n",
       "21600                                                                                                                                                                                                                               []   \n",
       "126118                                                                                                                                                                                                                              []   \n",
       "84388                                                                                                                                                                                                                               []   \n",
       "100344                                                                                                                                                                                                                              []   \n",
       "94794                                                                                                                                                                                                                               []   \n",
       "13819                                                                                                                                                                                                                               []   \n",
       "139895                                                                                                                                                                                                                              []   \n",
       "47655                                                                                                                                                                                                                               []   \n",
       "92009                                                                                                                                                                                                                               []   \n",
       "15301                                                                                                                                                                                                                               []   \n",
       "\n",
       "                                 patient_num  patient_size  \\\n",
       "index                                                        \n",
       "134590                                    []           0.0   \n",
       "121837                                [11.0]          11.0   \n",
       "89006                                     []           0.0   \n",
       "8982                                      []           0.0   \n",
       "14701                                     []           0.0   \n",
       "20454                               [3062.0]        3062.0   \n",
       "94867                                 [40.0]          40.0   \n",
       "39213                                     []           0.0   \n",
       "82669                                     []           0.0   \n",
       "30146                                     []           0.0   \n",
       "72715                                     []           0.0   \n",
       "122198                                 [3.0]           3.0   \n",
       "24232                                     []           0.0   \n",
       "60238                                     []           0.0   \n",
       "123814                         [18.0, 532.0]         532.0   \n",
       "61636                                     []           0.0   \n",
       "29550                           [14.0, 39.0]          39.0   \n",
       "25257                                     []           0.0   \n",
       "56291                                     []           0.0   \n",
       "31541                                [374.0]         374.0   \n",
       "81580                                  [2.0]           2.0   \n",
       "94910                                     []           0.0   \n",
       "42824                                     []           0.0   \n",
       "143020                                    []           0.0   \n",
       "78636                                [146.0]         146.0   \n",
       "68375                                     []           0.0   \n",
       "11991                                     []           0.0   \n",
       "14404                                     []           0.0   \n",
       "54623                                  [4.0]           4.0   \n",
       "16619                                     []           0.0   \n",
       "29905                                     []           0.0   \n",
       "44932                                  [2.0]           2.0   \n",
       "37654                                     []           0.0   \n",
       "143179                                    []           0.0   \n",
       "56109                          [175.0, 17.0]         175.0   \n",
       "35773    [355.0, 1480.0, 182.0, 35.0, 147.0]        1480.0   \n",
       "117887                 [411.0, 199.0, 212.0]         411.0   \n",
       "15168                                     []           0.0   \n",
       "48648                                 [28.0]          28.0   \n",
       "37039                                 [40.0]          40.0   \n",
       "104650                                [17.0]          17.0   \n",
       "56998                                     []           0.0   \n",
       "7057                                  [22.0]          22.0   \n",
       "67625                  [1376756.0, 175735.0]     1376756.0   \n",
       "47003                                     []           0.0   \n",
       "71310                                     []           0.0   \n",
       "114768                                    []           0.0   \n",
       "37681                                     []           0.0   \n",
       "68343                                     []           0.0   \n",
       "47109                                     []           0.0   \n",
       "138233                                    []           0.0   \n",
       "48230                              [50000.0]       50000.0   \n",
       "19333                                     []           0.0   \n",
       "91122                                [140.0]         140.0   \n",
       "50196                                     []           0.0   \n",
       "26004                     [3500.0, 3.0, 4.0]        3500.0   \n",
       "1244                                      []           0.0   \n",
       "61442                                     []           0.0   \n",
       "139902                                    []           0.0   \n",
       "29323                                     []           0.0   \n",
       "13910                                     []           0.0   \n",
       "13923                                     []           0.0   \n",
       "4321    [38.0, 38.0, 32.0, 32.0, 29.0, 29.0]          38.0   \n",
       "47901                                     []           0.0   \n",
       "18809                                 [12.0]          12.0   \n",
       "3483                                      []           0.0   \n",
       "73716                               [3377.0]        3377.0   \n",
       "84733                                     []           0.0   \n",
       "152438                                    []           0.0   \n",
       "44877                                 [23.0]          23.0   \n",
       "133419                                    []           0.0   \n",
       "65431                                     []           0.0   \n",
       "26463                                     []           0.0   \n",
       "10662                                 [84.0]          84.0   \n",
       "77895                                     []           0.0   \n",
       "34682                                     []           0.0   \n",
       "19158                                     []           0.0   \n",
       "6865                                      []           0.0   \n",
       "106469                                    []           0.0   \n",
       "126748                                    []           0.0   \n",
       "136647                   [125.0, 74.0, 51.0]         125.0   \n",
       "92278                         [104.0, 128.0]         128.0   \n",
       "40051                                     []           0.0   \n",
       "26404                                     []           0.0   \n",
       "49833                           [50.0, 50.0]          50.0   \n",
       "79244                                     []           0.0   \n",
       "8453                                      []           0.0   \n",
       "618                                       []           0.0   \n",
       "76598                                     []           0.0   \n",
       "64981                                     []           0.0   \n",
       "47354                           [48.0, 48.0]          48.0   \n",
       "98850                                     []           0.0   \n",
       "59288                                     []           0.0   \n",
       "3069                                      []           0.0   \n",
       "33698                                     []           0.0   \n",
       "31508                                     []           0.0   \n",
       "32519                                     []           0.0   \n",
       "14576                                     []           0.0   \n",
       "14483                                     []           0.0   \n",
       "78319                                     []           0.0   \n",
       "11310                                     []           0.0   \n",
       "55642                                 [20.0]          20.0   \n",
       "5038                                      []           0.0   \n",
       "115260                                [62.0]          62.0   \n",
       "122817                                    []           0.0   \n",
       "145427                                    []           0.0   \n",
       "20564                                     []           0.0   \n",
       "31644                                     []           0.0   \n",
       "107242                                 [2.0]           2.0   \n",
       "158091                                    []           0.0   \n",
       "112982                                    []           0.0   \n",
       "19683                                     []           0.0   \n",
       "127417                                    []           0.0   \n",
       "11431                                     []           0.0   \n",
       "102714                                    []           0.0   \n",
       "29857                                     []           0.0   \n",
       "60729                                     []           0.0   \n",
       "100709                                    []           0.0   \n",
       "13855                                     []           0.0   \n",
       "106809                                    []           0.0   \n",
       "126596                                    []           0.0   \n",
       "38305                                     []           0.0   \n",
       "39678                                     []           0.0   \n",
       "13011                                     []           0.0   \n",
       "6156                                      []           0.0   \n",
       "16556                                     []           0.0   \n",
       "99096                                     []           0.0   \n",
       "47915                                     []           0.0   \n",
       "59936                                     []           0.0   \n",
       "33766                          [337.0, 50.0]         337.0   \n",
       "14150                                     []           0.0   \n",
       "140094                                    []           0.0   \n",
       "30848                                     []           0.0   \n",
       "28475                                     []           0.0   \n",
       "19327                                     []           0.0   \n",
       "58269                                 [15.0]          15.0   \n",
       "79418                                     []           0.0   \n",
       "113272                                    []           0.0   \n",
       "94548                               [1981.0]        1981.0   \n",
       "104960                                    []           0.0   \n",
       "21600                                     []           0.0   \n",
       "126118                                    []           0.0   \n",
       "84388                                     []           0.0   \n",
       "100344                                    []           0.0   \n",
       "94794                                     []           0.0   \n",
       "13819                                     []           0.0   \n",
       "139895                                    []           0.0   \n",
       "47655                                     []           0.0   \n",
       "92009                                     []           0.0   \n",
       "15301                                     []           0.0   \n",
       "\n",
       "                                                                                                                                                                       feature_terms  \\\n",
       "index                                                                                                                                                                                  \n",
       "134590                                                                                                                                                                            []   \n",
       "121837                                                                                                                                                                            []   \n",
       "89006                                                                                                                                        [3 scanners demonstrated that haralick]   \n",
       "8982                                                                                                             [4 ss gene expression profile, 101 differentially expressed genes ]   \n",
       "14701                                                                                                                                                                             []   \n",
       "20454                                                                                                                                                                             []   \n",
       "94867                                                                                                                                               [40 intact subjects performing ]   \n",
       "39213                                                                                                                                                                             []   \n",
       "82669                                                                                                                                                                             []   \n",
       "30146                                                                                                                                                       [3 oct en  , 3 oct en  ]   \n",
       "72715                                                                                                                                                                             []   \n",
       "122198                                                                                                                                                                            []   \n",
       "24232                                                                                                                                                                             []   \n",
       "60238                                                                                                                                                                             []   \n",
       "123814                                                                                                                                                                            []   \n",
       "61636                                                                                                                                                                             []   \n",
       "29550                                                                                                                                                                             []   \n",
       "25257                                                                                                                                                                             []   \n",
       "56291                                                                                                                                                                             []   \n",
       "31541                                                                                                                                                [3 estimates the eegmac within]   \n",
       "81580                                                                                                                                                                             []   \n",
       "94910                                                                                                                                                                             []   \n",
       "42824                                                                                                                                                                             []   \n",
       "143020                                                                                                                                                                            []   \n",
       "78636                                                                                                                                                                             []   \n",
       "68375                                                                                                                                                        [135409 radiographs   ]   \n",
       "11991                                                                                                                                                                             []   \n",
       "14404                                                                                                                                                                             []   \n",
       "54623                                                                                                                                                                             []   \n",
       "16619                                                                                                                                                                             []   \n",
       "29905                                                                                                                                                                             []   \n",
       "44932                                                                                                                                                                             []   \n",
       "37654                                                                                                                                                                             []   \n",
       "143179                                                                [2 successive abnormal bone scans, 3 radiologists   , 16 image features for removing, 2 images which also can]   \n",
       "56109                                                                                                                                                                             []   \n",
       "35773                                                                                                                                                                             []   \n",
       "117887                                                                                                                                            [212 females with spontaneous ich]   \n",
       "15168                                                                                                                                                                             []   \n",
       "48648                                                                                                                                                                             []   \n",
       "37039                                                                                                                                                                             []   \n",
       "104650                                                                                                                                                                            []   \n",
       "56998                                                                                                                                                                             []   \n",
       "7057                                                                                                                                        [14 with amyopathic dermatomyositis adm]   \n",
       "67625                                                                                                                                                                             []   \n",
       "47003                                                                                                                                                                             []   \n",
       "71310   [29 tumor samples were obtained, 3474 tumor images  , 2014 imagenet large scale visual, 2014 imagenet large scale visual, 294 normal images out of, 667 tumor images out of]   \n",
       "114768                                                                                                                                                                            []   \n",
       "37681                                                                                                                                                                             []   \n",
       "68343                                                                                                                                                                             []   \n",
       "47109                                                                                                                                                                             []   \n",
       "138233                                                                                                                                                                            []   \n",
       "48230                                                                                                                                                                             []   \n",
       "19333                                                                                   [25920 images and validation set, 16416 images   , 3 musculoskeletal radiologists reviewed ]   \n",
       "91122                                                                                                                                                                             []   \n",
       "50196                                                                                                                                                                             []   \n",
       "26004                                                                                                                                                                             []   \n",
       "1244                                                                                                                                                                              []   \n",
       "61442                                                                                                                                                                             []   \n",
       "139902                                                                                                                                                                            []   \n",
       "29323                                                                                                                                                                             []   \n",
       "13910                                                                                                                                                                             []   \n",
       "13923                                                                                                                                                                             []   \n",
       "4321                                                                                                                                                   [99 serum samples including ]   \n",
       "47901                                                                                                                                                                             []   \n",
       "18809                                                                                                                                                                             []   \n",
       "3483                                                                                                                                          [100 randomly chosen images indicated]   \n",
       "73716                                                                                                                                                                             []   \n",
       "84733                                                                                                                                                                             []   \n",
       "152438                                                                                                                                                                            []   \n",
       "44877                                                                                                                                                                             []   \n",
       "133419                                                                                                                                                                            []   \n",
       "65431                                                                                                                                                                             []   \n",
       "26463                                                                                                                                                                             []   \n",
       "10662                                                                                                                                                                             []   \n",
       "77895                                                                                                                                                                             []   \n",
       "34682                                                                                                                                                                             []   \n",
       "19158                                                                                                                                                                             []   \n",
       "6865                                                                                                                                                                              []   \n",
       "106469                                                                                                                                                                            []   \n",
       "126748                                                                                                                                                                            []   \n",
       "136647                                                                                                                                                                            []   \n",
       "92278                                                                                                                      [104 subject dataset  , 4 neuroradiologists on a dataset]   \n",
       "40051                                                                                                                                                      [2 imaging biobanks and ]   \n",
       "26404                                                                                                                                                                             []   \n",
       "49833                                                                                                                                                                             []   \n",
       "79244                                                                                                                                                                             []   \n",
       "8453                                                                                                                                                                              []   \n",
       "618                                                                                                                                                                               []   \n",
       "76598                                                                                                                                                                             []   \n",
       "64981                                                                                                                                                                             []   \n",
       "47354                                                                                                                                                                             []   \n",
       "98850                                                                                                                                                                             []   \n",
       "59288                                                                                                                                                                             []   \n",
       "3069                                                                                                                                                                              []   \n",
       "33698                                                                                                                                                                             []   \n",
       "31508                                                                                                                                                                             []   \n",
       "32519                                                                                                                                                                             []   \n",
       "14576                                                                                                                                                                             []   \n",
       "14483                                                                                                                                                                             []   \n",
       "78319                                                                                                                                                                             []   \n",
       "11310                                                                                                                                                                             []   \n",
       "55642                                                                                                                                                                             []   \n",
       "5038                                                                                                                                                                              []   \n",
       "115260                                                                                               [62 age gender and educationally, 1.5 t mri scanning at, 1.5 t mri scanning at]   \n",
       "122817                                                                                                                                                                            []   \n",
       "145427                                                                                                                                                                            []   \n",
       "20564                                                                                 [10 hub genes significantly associated, 3 of these hub genes, 328 samples of idh , 31 gene   ]   \n",
       "31644                                                                                                                                                                             []   \n",
       "107242                                                                                                                                                                            []   \n",
       "158091                                                                                                                                                                            []   \n",
       "112982                                                                                                                                                                            []   \n",
       "19683                                                                                                                                                                             []   \n",
       "127417                                                                                                                                                                            []   \n",
       "11431                                                                                                                   [2 saving tremendous time for, 2 saving tremendous time for]   \n",
       "102714                                                                                                                                                                            []   \n",
       "29857                                                                                                                                                        [1525 images of covid ]   \n",
       "60729                                                                                                                                                                             []   \n",
       "100709                                                                                                                                                                            []   \n",
       "13855                                                                                                                                                                             []   \n",
       "106809                                                                                                                                                                            []   \n",
       "126596                                                                                                                                                                            []   \n",
       "38305                                                                                                                                                                             []   \n",
       "39678                                                                                                                                                                             []   \n",
       "13011                                                                                                                                                                             []   \n",
       "6156                                                                                                                                                                              []   \n",
       "16556                                                                                                                                                                             []   \n",
       "99096                                                                                                                                                                             []   \n",
       "47915                                                                                                                                                                             []   \n",
       "59936                                                                                                                                                                             []   \n",
       "33766                                                                                                                                                                             []   \n",
       "14150                                                                                                                                                                             []   \n",
       "140094                                                                                                                                                                            []   \n",
       "30848                                                                                                                                                                             []   \n",
       "28475                                                                                                                                                                             []   \n",
       "19327                                                                                                                                                                             []   \n",
       "58269                                                                                                                                                                             []   \n",
       "79418                                                                                                                                                  [19 channel eeg signals were]   \n",
       "113272                                                                                                                                                                            []   \n",
       "94548                                                                                                                                                                             []   \n",
       "104960                                                                                                                                                [5000 food images was created]   \n",
       "21600                                                                                                                                                                             []   \n",
       "126118                                                                                                                                                                            []   \n",
       "84388                                                                                                                                                                             []   \n",
       "100344                                                              [2 sets of suspicious mammogram, 2 sets of suspicious mammogram, 494 abnormal samples  , 108 abnormal samples  ]   \n",
       "94794                                                                                                                                                                             []   \n",
       "13819                                                                                                                                                                             []   \n",
       "139895                                                                                                                                                                            []   \n",
       "47655                                                                                                                                                                             []   \n",
       "92009                                                                                                                                                                             []   \n",
       "15301                                                                                                                                                                             []   \n",
       "\n",
       "                                         feature_num  feature_size  \\\n",
       "index                                                                \n",
       "134590                                            []           0.0   \n",
       "121837                                            []           0.0   \n",
       "89006                                          [3.0]           3.0   \n",
       "8982                                    [4.0, 101.0]         101.0   \n",
       "14701                                             []           0.0   \n",
       "20454                                             []           0.0   \n",
       "94867                                         [40.0]          40.0   \n",
       "39213                                             []           0.0   \n",
       "82669                                             []           0.0   \n",
       "30146                                     [3.0, 3.0]           3.0   \n",
       "72715                                             []           0.0   \n",
       "122198                                            []           0.0   \n",
       "24232                                             []           0.0   \n",
       "60238                                             []           0.0   \n",
       "123814                                            []           0.0   \n",
       "61636                                             []           0.0   \n",
       "29550                                             []           0.0   \n",
       "25257                                             []           0.0   \n",
       "56291                                             []           0.0   \n",
       "31541                                          [3.0]           3.0   \n",
       "81580                                             []           0.0   \n",
       "94910                                             []           0.0   \n",
       "42824                                             []           0.0   \n",
       "143020                                            []           0.0   \n",
       "78636                                             []           0.0   \n",
       "68375                                     [135409.0]      135409.0   \n",
       "11991                                             []           0.0   \n",
       "14404                                             []           0.0   \n",
       "54623                                             []           0.0   \n",
       "16619                                             []           0.0   \n",
       "29905                                             []           0.0   \n",
       "44932                                             []           0.0   \n",
       "37654                                             []           0.0   \n",
       "143179                         [2.0, 3.0, 16.0, 2.0]          16.0   \n",
       "56109                                             []           0.0   \n",
       "35773                                             []           0.0   \n",
       "117887                                       [212.0]         212.0   \n",
       "15168                                             []           0.0   \n",
       "48648                                             []           0.0   \n",
       "37039                                             []           0.0   \n",
       "104650                                            []           0.0   \n",
       "56998                                             []           0.0   \n",
       "7057                                          [14.0]          14.0   \n",
       "67625                                             []           0.0   \n",
       "47003                                             []           0.0   \n",
       "71310   [29.0, 3474.0, 2014.0, 2014.0, 294.0, 667.0]        3474.0   \n",
       "114768                                            []           0.0   \n",
       "37681                                             []           0.0   \n",
       "68343                                             []           0.0   \n",
       "47109                                             []           0.0   \n",
       "138233                                            []           0.0   \n",
       "48230                                             []           0.0   \n",
       "19333                        [25920.0, 16416.0, 3.0]       25920.0   \n",
       "91122                                             []           0.0   \n",
       "50196                                             []           0.0   \n",
       "26004                                             []           0.0   \n",
       "1244                                              []           0.0   \n",
       "61442                                             []           0.0   \n",
       "139902                                            []           0.0   \n",
       "29323                                             []           0.0   \n",
       "13910                                             []           0.0   \n",
       "13923                                             []           0.0   \n",
       "4321                                          [99.0]          99.0   \n",
       "47901                                             []           0.0   \n",
       "18809                                             []           0.0   \n",
       "3483                                         [100.0]         100.0   \n",
       "73716                                             []           0.0   \n",
       "84733                                             []           0.0   \n",
       "152438                                            []           0.0   \n",
       "44877                                             []           0.0   \n",
       "133419                                            []           0.0   \n",
       "65431                                             []           0.0   \n",
       "26463                                             []           0.0   \n",
       "10662                                             []           0.0   \n",
       "77895                                             []           0.0   \n",
       "34682                                             []           0.0   \n",
       "19158                                             []           0.0   \n",
       "6865                                              []           0.0   \n",
       "106469                                            []           0.0   \n",
       "126748                                            []           0.0   \n",
       "136647                                            []           0.0   \n",
       "92278                                   [104.0, 4.0]         104.0   \n",
       "40051                                          [2.0]           2.0   \n",
       "26404                                             []           0.0   \n",
       "49833                                             []           0.0   \n",
       "79244                                             []           0.0   \n",
       "8453                                              []           0.0   \n",
       "618                                               []           0.0   \n",
       "76598                                             []           0.0   \n",
       "64981                                             []           0.0   \n",
       "47354                                             []           0.0   \n",
       "98850                                             []           0.0   \n",
       "59288                                             []           0.0   \n",
       "3069                                              []           0.0   \n",
       "33698                                             []           0.0   \n",
       "31508                                             []           0.0   \n",
       "32519                                             []           0.0   \n",
       "14576                                             []           0.0   \n",
       "14483                                             []           0.0   \n",
       "78319                                             []           0.0   \n",
       "11310                                             []           0.0   \n",
       "55642                                             []           0.0   \n",
       "5038                                              []           0.0   \n",
       "115260                              [62.0, 1.5, 1.5]          62.0   \n",
       "122817                                            []           0.0   \n",
       "145427                                            []           0.0   \n",
       "20564                       [10.0, 3.0, 328.0, 31.0]         328.0   \n",
       "31644                                             []           0.0   \n",
       "107242                                            []           0.0   \n",
       "158091                                            []           0.0   \n",
       "112982                                            []           0.0   \n",
       "19683                                             []           0.0   \n",
       "127417                                            []           0.0   \n",
       "11431                                     [2.0, 2.0]           2.0   \n",
       "102714                                            []           0.0   \n",
       "29857                                       [1525.0]        1525.0   \n",
       "60729                                             []           0.0   \n",
       "100709                                            []           0.0   \n",
       "13855                                             []           0.0   \n",
       "106809                                            []           0.0   \n",
       "126596                                            []           0.0   \n",
       "38305                                             []           0.0   \n",
       "39678                                             []           0.0   \n",
       "13011                                             []           0.0   \n",
       "6156                                              []           0.0   \n",
       "16556                                             []           0.0   \n",
       "99096                                             []           0.0   \n",
       "47915                                             []           0.0   \n",
       "59936                                             []           0.0   \n",
       "33766                                             []           0.0   \n",
       "14150                                             []           0.0   \n",
       "140094                                            []           0.0   \n",
       "30848                                             []           0.0   \n",
       "28475                                             []           0.0   \n",
       "19327                                             []           0.0   \n",
       "58269                                             []           0.0   \n",
       "79418                                         [19.0]          19.0   \n",
       "113272                                            []           0.0   \n",
       "94548                                             []           0.0   \n",
       "104960                                      [5000.0]        5000.0   \n",
       "21600                                             []           0.0   \n",
       "126118                                            []           0.0   \n",
       "84388                                             []           0.0   \n",
       "100344                      [2.0, 2.0, 494.0, 108.0]         494.0   \n",
       "94794                                             []           0.0   \n",
       "13819                                             []           0.0   \n",
       "139895                                            []           0.0   \n",
       "47655                                             []           0.0   \n",
       "92009                                             []           0.0   \n",
       "15301                                             []           0.0   \n",
       "\n",
       "                      n=         n_num  n_size  \n",
       "index                                           \n",
       "134590                []            []     0.0  \n",
       "121837                []            []     0.0  \n",
       "89006                 []            []     0.0  \n",
       "8982                  []            []     0.0  \n",
       "14701                 []            []     0.0  \n",
       "20454                 []            []     0.0  \n",
       "94867                 []            []     0.0  \n",
       "39213                 []            []     0.0  \n",
       "82669                 []            []     0.0  \n",
       "30146                 []            []     0.0  \n",
       "72715                 []            []     0.0  \n",
       "122198                []            []     0.0  \n",
       "24232                 []            []     0.0  \n",
       "60238                 []            []     0.0  \n",
       "123814                []            []     0.0  \n",
       "61636                 []            []     0.0  \n",
       "29550   [n = 54, n = 23]  [54.0, 23.0]    54.0  \n",
       "25257                 []            []     0.0  \n",
       "56291                 []            []     0.0  \n",
       "31541                 []            []     0.0  \n",
       "81580                 []            []     0.0  \n",
       "94910                 []            []     0.0  \n",
       "42824                 []            []     0.0  \n",
       "143020                []            []     0.0  \n",
       "78636                 []            []     0.0  \n",
       "68375                 []            []     0.0  \n",
       "11991                 []            []     0.0  \n",
       "14404                 []            []     0.0  \n",
       "54623                 []            []     0.0  \n",
       "16619                 []            []     0.0  \n",
       "29905                 []            []     0.0  \n",
       "44932                 []            []     0.0  \n",
       "37654                 []            []     0.0  \n",
       "143179                []            []     0.0  \n",
       "56109                 []            []     0.0  \n",
       "35773                 []            []     0.0  \n",
       "117887                []            []     0.0  \n",
       "15168                 []            []     0.0  \n",
       "48648                 []            []     0.0  \n",
       "37039                 []            []     0.0  \n",
       "104650                []            []     0.0  \n",
       "56998                 []            []     0.0  \n",
       "7057                  []            []     0.0  \n",
       "67625                 []            []     0.0  \n",
       "47003                 []            []     0.0  \n",
       "71310                 []            []     0.0  \n",
       "114768                []            []     0.0  \n",
       "37681                 []            []     0.0  \n",
       "68343                 []            []     0.0  \n",
       "47109                 []            []     0.0  \n",
       "138233                []            []     0.0  \n",
       "48230                 []            []     0.0  \n",
       "19333                 []            []     0.0  \n",
       "91122                 []            []     0.0  \n",
       "50196                 []            []     0.0  \n",
       "26004                 []            []     0.0  \n",
       "1244                  []            []     0.0  \n",
       "61442                 []            []     0.0  \n",
       "139902                []            []     0.0  \n",
       "29323                 []            []     0.0  \n",
       "13910                 []            []     0.0  \n",
       "13923                 []            []     0.0  \n",
       "4321                  []            []     0.0  \n",
       "47901                 []            []     0.0  \n",
       "18809                 []            []     0.0  \n",
       "3483                  []            []     0.0  \n",
       "73716                 []            []     0.0  \n",
       "84733                 []            []     0.0  \n",
       "152438                []            []     0.0  \n",
       "44877                 []            []     0.0  \n",
       "133419                []            []     0.0  \n",
       "65431                 []            []     0.0  \n",
       "26463                 []            []     0.0  \n",
       "10662                 []            []     0.0  \n",
       "77895                 []            []     0.0  \n",
       "34682                 []            []     0.0  \n",
       "19158                 []            []     0.0  \n",
       "6865                  []            []     0.0  \n",
       "106469                []            []     0.0  \n",
       "126748                []            []     0.0  \n",
       "136647                []            []     0.0  \n",
       "92278                 []            []     0.0  \n",
       "40051                 []            []     0.0  \n",
       "26404                 []            []     0.0  \n",
       "49833                 []            []     0.0  \n",
       "79244                 []            []     0.0  \n",
       "8453                  []            []     0.0  \n",
       "618                   []            []     0.0  \n",
       "76598                 []            []     0.0  \n",
       "64981                 []            []     0.0  \n",
       "47354                 []            []     0.0  \n",
       "98850                 []            []     0.0  \n",
       "59288                 []            []     0.0  \n",
       "3069                  []            []     0.0  \n",
       "33698                 []            []     0.0  \n",
       "31508                 []            []     0.0  \n",
       "32519                 []            []     0.0  \n",
       "14576                 []            []     0.0  \n",
       "14483                 []            []     0.0  \n",
       "78319                 []            []     0.0  \n",
       "11310                 []            []     0.0  \n",
       "55642                 []            []     0.0  \n",
       "5038                  []            []     0.0  \n",
       "115260                []            []     0.0  \n",
       "122817                []            []     0.0  \n",
       "145427                []            []     0.0  \n",
       "20564                 []            []     0.0  \n",
       "31644                 []            []     0.0  \n",
       "107242                []            []     0.0  \n",
       "158091                []            []     0.0  \n",
       "112982                []            []     0.0  \n",
       "19683                 []            []     0.0  \n",
       "127417                []            []     0.0  \n",
       "11431                 []            []     0.0  \n",
       "102714                []            []     0.0  \n",
       "29857                 []            []     0.0  \n",
       "60729                 []            []     0.0  \n",
       "100709                []            []     0.0  \n",
       "13855                 []            []     0.0  \n",
       "106809                []            []     0.0  \n",
       "126596                []            []     0.0  \n",
       "38305                 []            []     0.0  \n",
       "39678                 []            []     0.0  \n",
       "13011                 []            []     0.0  \n",
       "6156                  []            []     0.0  \n",
       "16556                 []            []     0.0  \n",
       "99096                 []            []     0.0  \n",
       "47915                 []            []     0.0  \n",
       "59936                 []            []     0.0  \n",
       "33766                 []            []     0.0  \n",
       "14150                 []            []     0.0  \n",
       "140094                []            []     0.0  \n",
       "30848                 []            []     0.0  \n",
       "28475                 []            []     0.0  \n",
       "19327                 []            []     0.0  \n",
       "58269                 []            []     0.0  \n",
       "79418                 []            []     0.0  \n",
       "113272                []            []     0.0  \n",
       "94548                 []            []     0.0  \n",
       "104960                []            []     0.0  \n",
       "21600         [n = 4182]      [4182.0]  4182.0  \n",
       "126118                []            []     0.0  \n",
       "84388                 []            []     0.0  \n",
       "100344                []            []     0.0  \n",
       "94794                 []            []     0.0  \n",
       "13819                 []            []     0.0  \n",
       "139895                []            []     0.0  \n",
       "47655                 []            []     0.0  \n",
       "92009                 []            []     0.0  \n",
       "15301                 []            []     0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelleddf.sample(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcf3f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelleddf.to_csv('output/initial_labelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cb7d8",
   "metadata": {},
   "source": [
    "## Final set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fe657f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizedf = labelleddf[['text', 'patient_size', 'feature_size', 'n_size']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25b0c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizedf['concat_size'] = sizedf.max(axis=1)\n",
    "sizedf['ptdata_size'] = sizedf[['patient_size', 'n_size']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6af48394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sizedf['patient_size'] = sizedf['patient_size'].replace(0, np.nan)\n",
    "sizedf['feature_size'] = sizedf['feature_size'].replace(0, np.nan)\n",
    "sizedf['n_size'] = sizedf['n_size'].replace(0, np.nan)\n",
    "sizedf['ptdata_size'] = sizedf['ptdata_size'].replace(0, np.nan)\n",
    "sizedf['concat_size'] = sizedf['concat_size'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0bde2ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 32474 entries, 0 to 161524\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   text          32473 non-null  object \n",
      " 1   patient_size  7838 non-null   float64\n",
      " 2   feature_size  5702 non-null   float64\n",
      " 3   n_size        600 non-null    float64\n",
      " 4   concat_size   11227 non-null  float64\n",
      " 5   ptdata_size   8113 non-null   float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "sizedf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8ec80f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizedf.to_csv('output/final_sizes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becb127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
